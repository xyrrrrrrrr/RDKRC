import torch
import torch.nn.functional as F
import torch.nn as nn
from typing import Tuple, Optional
from rdkrc.utils.matrix_utils import compute_controllability_matrix
from rdkrc.utils.data_utils import compute_knn_neighbors

def compute_L1_loss(
    z_prev: torch.Tensor,
    z_next: torch.Tensor,
    A: torch.Tensor,
    B: torch.Tensor,
    u_prev: torch.Tensor,
    u0: torch.Tensor
) -> torch.Tensor:
    """
    è®¡ç®—L1æŸå¤±ï¼ˆæ–‡æ¡£Algorithm 1æ­¥éª¤2 + Equation 7ï¼‰ï¼š
    ç¡®ä¿é«˜ç»´çº¿æ€§ç³»ç»Ÿçš„é¢„æµ‹è¯¯å·®æœ€å°åŒ–ï¼Œæ ¸å¿ƒå…¬å¼ä¸ºï¼š
    L1(Î¸) = (1/L) Â· Î£||z_{t+1} - A z_t - B(u_t - u0)||_F 
    ï¼ˆLä¸ºæ‰¹é‡å¤§å°ï¼Œå¯¹åº”æ–‡æ¡£â€œt=0åˆ°L-1æ±‚å’Œâ€ï¼ŒL = æ‰¹é‡æ ·æœ¬æ•°ï¼‰
    
    æ–‡æ¡£ä¾æ®ï¼š
    - Algorithm 1æ­¥éª¤2ï¼šL1(Î¸) = (1/(L-1))Â·Î£||z(x_{t+1}) - KÂ·z(x_t)||ï¼ˆKä¸ºKoopmanç®—å­åˆæ­¥è¿‘ä¼¼ï¼‰
    - Section II Equation 7ï¼šL = Î£||z_{t+1} - A z_t - B(u - u0)||_Fï¼ˆæœ€ç»ˆçº¿æ€§æ¨¡å‹è¯¯å·®ï¼‰
    æ­¤å¤„èåˆä¸¤è€…ï¼šç”¨å½“å‰è¿­ä»£çš„A/Bæ›¿ä»£Kï¼ŒåŠ å…¥u0é¡¹ï¼Œç¡®ä¿çº¿æ€§æ¨¡å‹ç²¾åº¦ã€‚

    Args:
        z_prev (torch.Tensor): tæ—¶åˆ»é«˜ç»´çŠ¶æ€z(x_t)ï¼Œå½¢çŠ¶[batch_size, N]ï¼ˆN=åŸºå‡½æ•°ç»´åº¦ï¼Œå¦‚128ï¼‰
        z_next (torch.Tensor): t+1æ—¶åˆ»é«˜ç»´çŠ¶æ€z(x_{t+1})ï¼Œå½¢çŠ¶[batch_size, N]
        A (torch.Tensor): å½“å‰è¿­ä»£çš„KoopmançŸ©é˜µï¼Œå½¢çŠ¶[N, N]ï¼ˆæ¥è‡ª`matrix_utils.update_A_B`ï¼‰
        B (torch.Tensor): å½“å‰è¿­ä»£çš„æ§åˆ¶çŸ©é˜µï¼Œå½¢çŠ¶[N, m]ï¼ˆm=æ§åˆ¶ç»´åº¦ï¼Œå¦‚å€’ç«‹æ‘†m=1ï¼‰
        u_prev (torch.Tensor): tæ—¶åˆ»æ§åˆ¶è¾“å…¥ï¼Œå½¢çŠ¶[batch_size, m]ï¼ˆä¸`matrix_utils.update_A_B`è¾“å…¥ä¸€è‡´ï¼‰
        u0 (torch.Tensor): æ§åˆ¶å›ºå®šç‚¹ï¼ˆæ¥è‡ªPsiMLP.forward_u0ï¼‰ï¼Œå½¢çŠ¶[batch_size, m]

    Returns:
        torch.Tensor: æ‰¹é‡å¹³å‡åçš„L1æŸå¤±ï¼ˆæ ‡é‡ï¼‰
    """
    # 1. è®¾å¤‡ä¸€è‡´æ€§ç¡®ä¿ï¼ˆé¿å…CPU/GPUæ··åˆè®¡ç®—é”™è¯¯ï¼‰
    device = z_prev.device
    A, B, u_prev, u0 = A.to(device), B.to(device), u_prev.to(device), u0.to(device)
    
    # 2. è®¡ç®—å˜æ¢åæ§åˆ¶è¾“å…¥v_t = u_t - u0ï¼ˆæ–‡æ¡£Equation 4ï¼‰
    v_prev = u_prev - u0  # å½¢çŠ¶[batch_size, m]
    
    # 3. é«˜ç»´çº¿æ€§æ¨¡å‹é¢„æµ‹z_nextï¼ˆæ–‡æ¡£Equation 5ï¼šz_{t+1} = A z_t + B v_tï¼‰
    # æ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼šz_prev [B,N] Ã— A.T [N,N] â†’ [B,N]ï¼›v_prev [B,m] Ã— B.T [m,N] â†’ [B,N]
    z_next_pred = torch.matmul(z_prev, A.T) + torch.matmul(v_prev, B.T)  # å½¢çŠ¶[batch_size, N]
    
    # 4. è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„FèŒƒæ•°è¯¯å·®ï¼ˆæ–‡æ¡£Equation 7çš„||Â·||_Fï¼‰
    # dim=1ï¼šå¯¹æ¯ä¸ªæ ·æœ¬çš„Nç»´ç‰¹å¾è®¡ç®—FèŒƒæ•°ï¼ˆç­‰ä»·äºL2èŒƒæ•°ï¼‰
    sample_errors = torch.norm(z_next - z_next_pred, p='fro', dim=1)  # å½¢çŠ¶[batch_size]
    
    # 5. æ‰¹é‡å¹³å‡ï¼ˆæ–‡æ¡£Algorithm 1æ­¥éª¤2çš„1/(L-1)ï¼Œæ­¤å¤„L=batch_sizeï¼Œå› æ‰¹é‡ä¸ºt=0åˆ°L-1çš„Lä¸ªæ ·æœ¬ï¼‰
    total_L1 = sample_errors.mean()  # ç­‰ä»·äºsum(sample_errors) / batch_size
    
    return total_L1


def compute_L2_loss(
    A: torch.Tensor,
    B: torch.Tensor,
    lambda_rank: float = 0.8,
    lambda_A: float = 0.1,
    lambda_B: float = 0.1
) -> torch.Tensor:
    """
    è®¡ç®—L2æŸå¤±ï¼ˆæ–‡æ¡£Algorithm 1æ­¥éª¤3ï¼‰ï¼š
    ç¡®ä¿ç³»ç»Ÿèƒ½æ§æ€§ä¸çŸ©é˜µå‚æ•°æ­£åˆ™åŒ–ï¼Œæ ¸å¿ƒå…¬å¼ä¸ºï¼š
    L2(Î¸) = (N - rank(Cont(A,B))) + ||A||â‚ + ||B||â‚
    å…¶ä¸­Cont(A,B)ä¸ºèƒ½æ§æ€§çŸ©é˜µï¼ˆç”±`matrix_utils.compute_controllability_matrix`è®¡ç®—ï¼‰ã€‚

    æ–‡æ¡£ä¾æ®ï¼š
    - Algorithm 1æ­¥éª¤3ï¼šL2(Î¸) = (N - rank(controllability(A,B))) + ||A||â‚ + ||B||â‚
    - æ³¨ï¼šlambda_rank/A/Bä¸ºè¶…å‚æ•°ï¼Œæ–‡æ¡£æœªæŒ‡å®šæƒé‡ï¼Œé»˜è®¤è®¾ä¸º1.0ä»¥å¯¹é½åŸæ–‡ç»“æ„ï¼Œå¯æŒ‰éœ€è°ƒæ•´ã€‚

    Args:
        A (torch.Tensor): KoopmançŸ©é˜µï¼Œå½¢çŠ¶[N, N]
        B (torch.Tensor): æ§åˆ¶çŸ©é˜µï¼Œå½¢çŠ¶[N, m]
        lambda_rank (float): èƒ½æ§æ€§ç§©æƒ©ç½šæƒé‡ï¼ˆé»˜è®¤1.0ï¼Œå¯¹é½åŸæ–‡ï¼‰
        lambda_A (float): AçŸ©é˜µ1èŒƒæ•°æƒ©ç½šæƒé‡ï¼ˆé»˜è®¤1.0ï¼Œå¯¹é½åŸæ–‡ï¼‰
        lambda_B (float): BçŸ©é˜µ1èŒƒæ•°æƒ©ç½šæƒé‡ï¼ˆé»˜è®¤1.0ï¼Œå¯¹é½åŸæ–‡ï¼‰

    Returns:
        torch.Tensor: L2æŸå¤±ï¼ˆæ ‡é‡ï¼‰
    """
    # 1. è®¾å¤‡ä¸€è‡´æ€§ç¡®ä¿
    device = A.device
    B = B.to(device)
    
    # 2. è®¡ç®—èƒ½æ§æ€§çŸ©é˜µï¼ˆè°ƒç”¨`matrix_utils`çš„è¾…åŠ©å‡½æ•°ï¼Œä¸¥æ ¼å¯¹é½æ–‡æ¡£å®šä¹‰ï¼‰
    controllability_mat = compute_controllability_matrix(A, B)  # å½¢çŠ¶[N, NÃ—m]
    
    # 3. è®¡ç®—èƒ½æ§æ€§çŸ©é˜µçš„ç§©ï¼ˆå¥‡å¼‚å€¼>1e-5è§†ä¸ºæœ‰æ•ˆç§©ï¼Œé¿å…æ•°å€¼è¯¯å·®ï¼‰
    _, singular_vals, _ = torch.svd(controllability_mat)
    rank = (singular_vals > 1e-5).sum().item()  # æœ‰æ•ˆç§©
    N = A.shape[0]
    rank_penalty = lambda_rank * (N - rank) / N  # å½’ä¸€åŒ–ç§©æƒ©ç½šï¼Œé¿å…éšNå˜åŒ–è¿‡å¤§
    
    # 4. è®¡ç®—A/Bçš„1èŒƒæ•°ï¼ˆæ–‡æ¡£Algorithm 1æ­¥éª¤3çš„æ­£åˆ™åŒ–é¡¹ï¼‰
    A_l1 = lambda_A * torch.norm(A, p=1)  # AçŸ©é˜µ1èŒƒæ•°
    B_l1 = lambda_B * torch.norm(B, p=1)  # BçŸ©é˜µ1èŒƒæ•°
    
    # 5. æ€»L2æŸå¤±ï¼ˆæ–‡æ¡£å®šä¹‰çš„ä¸‰é¡¹ä¹‹å’Œï¼‰
    total_L2 = rank_penalty + A_l1 + B_l1
    
    return total_L2


def compute_total_loss(
    z_prev: torch.Tensor,
    z_next: torch.Tensor,
    A: torch.Tensor,
    B: torch.Tensor,
    u_prev: torch.Tensor,
    u0: torch.Tensor,
    lambda_L1: float = 1.0,
    lambda_L2: float = 1.0,
    **kwargs
) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    è®¡ç®—DKRCæ€»æŸå¤±ï¼ˆæ–‡æ¡£Algorithm 1æ­¥éª¤4ï¼‰ï¼š
    æ€»æŸå¤± = Î»_L1Â·L1 + Î»_L2Â·L2ï¼ˆÎ»_L1/Î»_L2ä¸ºæŸå¤±å¹³è¡¡è¶…å‚æ•°ï¼Œé»˜è®¤1.0ï¼‰

    æ–‡æ¡£ä¾æ®ï¼š
    - Algorithm 1æ­¥éª¤4ï¼šL(Î¸) = L1(Î¸) + L2(Î¸)ï¼ˆæ­¤å¤„ä¿ç•™Î»_L1/Î»_L2ä»¥æ”¯æŒçµæ´»è°ƒå‚ï¼Œé»˜è®¤å¯¹é½åŸæ–‡ï¼‰

    Args:
        z_prev (torch.Tensor): tæ—¶åˆ»é«˜ç»´çŠ¶æ€ï¼Œå½¢çŠ¶[batch_size, N]
        z_next (torch.Tensor): t+1æ—¶åˆ»é«˜ç»´çŠ¶æ€ï¼Œå½¢çŠ¶[batch_size, N]
        A (torch.Tensor): KoopmançŸ©é˜µï¼Œå½¢çŠ¶[N, N]
        B (torch.Tensor): æ§åˆ¶çŸ©é˜µï¼Œå½¢çŠ¶[N, m]
        u_prev (torch.Tensor): tæ—¶åˆ»æ§åˆ¶è¾“å…¥ï¼Œå½¢çŠ¶[batch_size, m]
        u0 (torch.Tensor): æ§åˆ¶å›ºå®šç‚¹ï¼Œå½¢çŠ¶[batch_size, m]
        lambda_L1 (float): L1æŸå¤±æƒé‡ï¼ˆé»˜è®¤1.0ï¼Œå¯¹é½åŸæ–‡ï¼‰
        lambda_L2 (float): L2æŸå¤±æƒé‡ï¼ˆé»˜è®¤1.0ï¼Œå¯¹é½åŸæ–‡ï¼‰
        version (str): æŸå¤±ç‰ˆæœ¬ï¼ˆ"v1"æˆ–"v2"ï¼‰
        **kwargs: ä¼ é€’ç»™`compute_L2_loss`çš„é¢å¤–å‚æ•°ï¼ˆå¦‚lambda_rankï¼‰

    Returns:
        Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
            total_loss: æ€»æŸå¤±ï¼ˆæ ‡é‡ï¼‰
            L1: L1æŸå¤±ï¼ˆæ ‡é‡ï¼‰
            L2: L2æŸå¤±ï¼ˆæ ‡é‡ï¼‰
    """
    # 1. è®¡ç®—L1æŸå¤±ï¼ˆä¼ å…¥A/B/u_prev/u0ï¼Œå¯¹é½çº¿æ€§æ¨¡å‹è¯¯å·®ï¼‰
    L1 = compute_L1_loss(z_prev, z_next, A, B, u_prev, u0)
    
    # 2. è®¡ç®—L2æŸå¤±ï¼ˆè°ƒç”¨`compute_L2_loss`ï¼Œæ”¯æŒé¢å¤–è¶…å‚æ•°ï¼‰
    L2 = compute_L2_loss(A, B, **kwargs)
 
    # 3. è®¡ç®—æ€»æŸå¤±ï¼ˆæ–‡æ¡£Algorithm 1æ­¥éª¤4ï¼‰
    total_loss = lambda_L1 * L1 + lambda_L2 * L2
        
    return total_loss, L1, L2

# ä¿®æ”¹åçš„ManifoldEmbLossç±»ç¤ºä¾‹ï¼ˆéœ€æ›¿æ¢ä½ åŸæœ‰ä»£ç ï¼‰
class ManifoldEmbLoss(nn.Module):
    def __init__(self, k=10):
        super().__init__()
        self.k = k  # Kè¿‘é‚»æ•°é‡
        self.neighbor_indices = None  # ä¸å†é¢„å­˜å…¨å±€ç´¢å¼•ï¼Œæ”¹ä¸ºbatchå†…ä¸´æ—¶å­˜å‚¨
        self.GraphMatchingLoss = GraphMatchingLoss()

    def compute_knn(self, X):
        """é’ˆå¯¹å•ä¸ªbatchçš„Xï¼Œè®¡ç®—æ¯ä¸ªæ ·æœ¬çš„Kè¿‘é‚»ç´¢å¼•ï¼ˆä»…åœ¨å½“å‰batchå†…ï¼‰"""
        # è®¡ç®—Xçš„ pairwise è·ç¦»ï¼ˆæ¬§æ°è·ç¦»ï¼‰
        n = X.shape[0]
        dist_matrix = torch.cdist(X, X, p=2)  # shape=[n, n]
        # å–æ¯ä¸ªæ ·æœ¬çš„å‰k+1ä¸ªè¿‘é‚»ï¼ˆæ’é™¤è‡ªèº«ï¼Œæ‰€ä»¥k+1ï¼‰ï¼Œå†å»æ‰ç¬¬0ä¸ªï¼ˆè‡ªèº«ï¼‰
        _, indices = torch.topk(dist_matrix, k=self.k+1, largest=False, dim=1)
        self.neighbor_indices = indices[:, 1:]  # shape=[n, k]ï¼Œæ¯ä¸ªæ ·æœ¬çš„kä¸ªé‚»å±…ç´¢å¼•
        return self.neighbor_indices

    def forward(self, z, X):
        """
        z: å½“å‰batchçš„åµŒå…¥å¼ é‡ï¼Œshape=[batch*T, manifold_dim]
        X: å½“å‰batchçš„åŸçŠ¶æ€å¼ é‡ï¼Œshape=[batch*T, x_dim]
        """
        # ç¬¬ä¸€æ­¥ï¼šé’ˆå¯¹å½“å‰batchçš„Xï¼ŒåŠ¨æ€è®¡ç®—Kè¿‘é‚»ç´¢å¼•
        self.compute_knn(X)
        # ç¬¬äºŒæ­¥ï¼šæ ¹æ®é‚»å±…ç´¢å¼•ï¼Œæå–zå’ŒXçš„é‚»å±…æ ·æœ¬
        n = z.shape[0]
        # ç¡®ä¿ç´¢å¼•åœ¨åˆæ³•èŒƒå›´å†…ï¼ˆåŒé‡ä¿é™©ï¼‰
        self.neighbor_indices = torch.clamp(self.neighbor_indices, 0, n-1)
        
        # æå–æ¯ä¸ªæ ·æœ¬çš„é‚»å±…ï¼ˆshape=[n, k, dim]ï¼‰
        z_neighbors = z[self.neighbor_indices]  # [n, k, manifold_dim]
        x_neighbors = X[self.neighbor_indices]  # [n, k, x_dim]
        
        # è®¡ç®—åŸçŠ¶æ€ä¸é‚»å±…çš„è·ç¦»ã€åµŒå…¥åä¸é‚»å±…çš„è·ç¦»
        x_dist = torch.cdist(X.unsqueeze(1), x_neighbors, p=2).squeeze(1) 
        z_dist = torch.cdist(z.unsqueeze(1), z_neighbors, p=2).squeeze(1) 

        x_dist_max = torch.max(x_dist, dim=1, keepdim=True)[0]
        x_dist_max = torch.clamp(x_dist_max, min=1e-8)  # é˜²æ­¢è¿‡å°å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸
        x_dist = x_dist / x_dist_max  # å½’ä¸€åŒ–ï¼Œé¿å…å°ºåº¦
        z_dist_max = torch.max(z_dist, dim=1, keepdim=True)[0]
        z_dist_max = torch.clamp(z_dist_max, min=1e-8)  # é˜²æ­¢è¿‡å°å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸
        z_dist = z_dist / z_dist_max  # å½’ä¸€åŒ–ï¼Œé¿å…å°ºåº¦

        # # è®¡ç®—dij, dzij
        # dij = torch.cdist(x_neighbors, x_neighbors, p=2)  # [n, k, k]
        # d_zij = torch.cdist(z_neighbors, z_neighbors, p=2)  # [n, k, k]
        
        # # è®¡ç®—æµå½¢æŸå¤±ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
        loss1 = torch.mean(torch.abs(z_dist - x_dist))
        # loss2 = self.GraphMatchingLoss(dij, d_zij)
        # return loss1 + loss2

        return loss1

class GraphMatchingLoss(nn.Module):
    """
    å›¾åŒ¹é…æŸå¤±ï¼ˆPyTorchç‰ˆï¼‰ï¼šå¯¹é½æ–‡æ¡£ğŸ”¶2-59èŠ‚å›¾åŒ¹é…æŸå¤±å…¬å¼
    åŠŸèƒ½ï¼šè®¡ç®—åŸç©ºé—´è·ç¦»çŸ©é˜µdijä¸æ½œç©ºé—´è·ç¦»çŸ©é˜µd_zijçš„"è·ç¦»å·®ä¸€è‡´æ€§"æŸå¤±ï¼Œ
          é€šè¿‡å…¨å±€æœ€å¤§è·ç¦»å·®å½’ä¸€åŒ–ï¼Œé¿å…å°ºåº¦å·®å¼‚å½±å“è®­ç»ƒï¼ˆæ–‡æ¡£éšå«è¦æ±‚ï¼ŒğŸ”¶2-60èŠ‚ï¼‰
    """
    def __init__(self):
        super().__init__()
        # ç»§æ‰¿ManifoldEmbLossçš„ç®€æ´åˆå§‹åŒ–é£æ ¼ï¼Œæ— é¢å¤–è¶…å‚ï¼ˆæ ¸å¿ƒå‚æ•°ç”±forwardä¼ å…¥ï¼‰

    def forward(
        self, 
        dij: torch.Tensor, 
        d_zij: torch.Tensor, 
    ) -> torch.Tensor:
        """
        Args:
            dij: åŸç©ºé—´æµ‹åœ°çº¿è·ç¦»çŸ©é˜µï¼ˆæ–‡æ¡£ğŸ”¶2-33èŠ‚d_D(xi,xj)ï¼‰ï¼Œshape=[B, B]ï¼ˆBä¸ºæ ·æœ¬æ•°ï¼‰
            d_zij: æ½œç©ºé—´è·ç¦»çŸ©é˜µï¼ˆæ–‡æ¡£ğŸ”¶2-33èŠ‚d_M(Ï†(xi),Ï†(xj))ï¼‰ï¼Œshape=[B, B]
            dij_diff_max: åŸç©ºé—´è·ç¦»å·®çš„å…¨å±€æœ€å¤§å€¼ï¼ˆæ–‡æ¡£ğŸ”¶2-59èŠ‚å½’ä¸€åŒ–å› å­ï¼‰ï¼Œæ ‡é‡ï¼›
                          è‹¥ä¸ºNoneï¼Œè‡ªåŠ¨è®¡ç®—ï¼ˆé€‚é…æ— é¢„è®¡ç®—åœºæ™¯ï¼‰
        
        Returns:
            gm_loss: å›¾åŒ¹é…æŸå¤±ï¼ˆæ ‡é‡ï¼‰ï¼Œç¬¦åˆæ–‡æ¡£ğŸ”¶2-59èŠ‚å…¬å¼å®šä¹‰
        """

        diff_dij_temp = dij.unsqueeze(1) - dij.unsqueeze(0)  # [B, B, B]
        dij_diff_max = torch.max(torch.abs(diff_dij_temp))  # æ ‡é‡
        
        # 2. æ•°å€¼ç¨³å®šæ€§å¤„ç†ï¼ˆå‚è€ƒManifoldEmbLossçš„1e-8ç­–ç•¥ï¼Œé¿å…é™¤ä»¥é›¶ï¼‰
        dij_diff_max = torch.clamp(dij_diff_max, min=1e-8)  # é˜²æ­¢dij_diff_maxè¿‡å°å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸
        
        # 3. è®¡ç®—è·ç¦»å·®ï¼ˆå¯¹é½JAXåŸé€»è¾‘ï¼šdij[:,newaxis]-dij[newaxis]ï¼‰
        # æ–‡æ¡£ä¾æ®ï¼šğŸ”¶2-55èŠ‚å›¾åŒ¹é…æŸå¤±éœ€è®¡ç®—"æ¯ä¸ªæ ·æœ¬å¯¹(i,j)ç›¸å¯¹äºæ‰€æœ‰kçš„è·ç¦»å·®"
        diff_dij = dij.unsqueeze(1) - dij.unsqueeze(0)  # [B, B, B]ï¼šdiff_dij[i,j,k] = dij[i,k] - dij[j,k]
        diff_d_z_ij = d_zij.unsqueeze(1) - d_zij.unsqueeze(0)  # [B, B, B]ï¼šæ½œç©ºé—´å¯¹åº”è·ç¦»å·®
        
        # 4. è®¡ç®—å›¾åŒ¹é…æŸå¤±ï¼ˆæ–‡æ¡£ğŸ”¶2-59èŠ‚å…¬å¼ï¼šå½’ä¸€åŒ–å¹³æ–¹æŸå¤±çš„å‡å€¼ï¼‰
        gm_loss = torch.mean(((diff_dij - diff_d_z_ij) / dij_diff_max) ** 2)
        
        return gm_loss

class ManifoldCtrlLoss(nn.Module):
    def __init__(self):
        super().__init__()
        self.mse_loss = nn.MSELoss()

    def forward(self, A: nn.Linear, B: nn.Linear, z_t: torch.Tensor, z_t1: torch.Tensor, g_phi: torch.Tensor, u:torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—çº¿æ€§æ¼”åŒ–ä¸€è‡´æ€§æŸå¤±
        A, B: Koopmanç®—å­ï¼ˆnn.Linearå±‚ï¼Œæ— åç½®ï¼‰
        z_t: tæ—¶åˆ»åµŒå…¥å‘é‡ [batch, n+d]
        z_t1: t+1æ—¶åˆ»åµŒå…¥å‘é‡ [batch, n+d]
        g_phi: æ§åˆ¶ç½‘ç»œè¾“å‡º [batch, m]ï¼ˆmä¸ºæ§åˆ¶ç»´åº¦ï¼‰
        """
        # è®¡ç®—ç†è®ºæ§åˆ¶åµŒå…¥ï¼šg_phi_theo = B^+ (z_t1 - A z_t)
        A_z_t = A(z_t)  # [batch, n+d]
        z_diff = z_t1 - A_z_t  # [batch, n+d]
        
        # è®¡ç®—Bçš„ä¼ªé€†ï¼ˆB.weight: [n+d, m]ï¼‰
        B_weight = B.weight  # [out_dim= n+d, in_dim= m]
        B_pinv = torch.linalg.pinv(B_weight)  # [m, n+d]
        
        # ç†è®ºæ§åˆ¶åµŒå…¥ï¼š[batch, m] = [batch, n+d] @ [n+d, m]
        g_phi_theo = z_diff @ B_pinv.T
        
        # ä¸€è‡´æ€§æŸå¤±
        loss1 = self.mse_loss(g_phi * u, g_phi_theo)

        return loss1
    
class ManifoldCtrlInvLoss(nn.Module):
    def __init__(self, k):
        super().__init__()
        self.k = k
        self.mse_loss = nn.MSELoss()

    def compute_knn(self, X):
        """é’ˆå¯¹å•ä¸ªbatchçš„Xï¼Œè®¡ç®—æ¯ä¸ªæ ·æœ¬çš„Kè¿‘é‚»ç´¢å¼•ï¼ˆä»…åœ¨å½“å‰batchå†…ï¼‰"""
        # è®¡ç®—Xçš„ pairwise è·ç¦»ï¼ˆæ¬§æ°è·ç¦»ï¼‰
        n = X.shape[0]
        dist_matrix = torch.cdist(X, X, p=2)  # shape=[n, n]
        # å–æ¯ä¸ªæ ·æœ¬çš„å‰k+1ä¸ªè¿‘é‚»ï¼ˆæ’é™¤è‡ªèº«ï¼Œæ‰€ä»¥k+1ï¼‰ï¼Œå†å»æ‰ç¬¬0ä¸ªï¼ˆè‡ªèº«ï¼‰
        _, indices = torch.topk(dist_matrix, k=self.k+1, largest=False, dim=1)
        self.neighbor_indices = indices[:, 1:]  # shape=[n, k]ï¼Œæ¯ä¸ªæ ·æœ¬çš„kä¸ªé‚»å±…ç´¢å¼•
        return self.neighbor_indices

    def forward(self, U_recover: torch.Tensor, U_real: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—çº¿æ€§æ¼”åŒ–ä¸€è‡´æ€§æŸå¤±
        A, B: Koopmanç®—å­ï¼ˆnn.Linearå±‚ï¼Œæ— åç½®ï¼‰
        z_t: tæ—¶åˆ»åµŒå…¥å‘é‡ [batch, n+d]
        z_t1: t+1æ—¶åˆ»åµŒå…¥å‘é‡ [batch, n+d]
        g_phi: æ§åˆ¶ç½‘ç»œè¾“å‡º [batch, m]ï¼ˆmä¸ºæ§åˆ¶ç»´åº¦ï¼‰
        """
        # å·®è·æŸå¤±
        loss1 = self.mse_loss(U_recover, U_real)

        # return loss1
         # ç¬¬ä¸€æ­¥ï¼šé’ˆå¯¹å½“å‰batchçš„Xï¼ŒåŠ¨æ€è®¡ç®—Kè¿‘é‚»ç´¢å¼•
        self.compute_knn(U_real)
        # ç¬¬äºŒæ­¥ï¼šæ ¹æ®é‚»å±…ç´¢å¼•ï¼Œæå–zå’ŒXçš„é‚»å±…æ ·æœ¬
        n = U_real.shape[0]
        # ç¡®ä¿ç´¢å¼•åœ¨åˆæ³•èŒƒå›´å†…ï¼ˆåŒé‡ä¿é™©ï¼‰
        self.neighbor_indices = torch.clamp(self.neighbor_indices, 0, n-1)
        
        # æå–æ¯ä¸ªæ ·æœ¬çš„é‚»å±…ï¼ˆshape=[n, k, dim]ï¼‰
        U_real_neighbors = U_real[self.neighbor_indices]  # [n, k, manifold_dim]
        U_recover_neighbors = U_recover[self.neighbor_indices]  # [n, k, x_dim]
        
        # è®¡ç®—åŸçŠ¶æ€ä¸é‚»å±…çš„è·ç¦»ã€åµŒå…¥åä¸é‚»å±…çš„è·ç¦»
        U_real_dist = torch.cdist(U_real.unsqueeze(1), U_real_neighbors, p=2).squeeze(1) 
        U_recover_dist = torch.cdist(U_recover.unsqueeze(1), U_recover_neighbors, p=2).squeeze(1) 

        U_real_dist_max = torch.max(U_real_dist, dim=1, keepdim=True)[0] + 1e-8
        U_real_dist = U_real_dist / U_real_dist_max  # å½’ä¸€åŒ–ï¼Œé¿å…å°ºåº¦
        U_recover_dist_max = torch.max(U_recover_dist, dim=1, keepdim=True)[0] + 1e-8
        U_recover_dist = U_recover_dist / U_recover_dist_max  # å½’ä¸€åŒ–ï¼Œé¿å…å°ºåº¦

        # è®¡ç®—æµå½¢æŸå¤±ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
        loss2 = torch.mean(torch.abs(U_real_dist - U_recover_dist))


        return loss1 + loss2
