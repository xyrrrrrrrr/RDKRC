import torch
import os
import gym
import torch.optim as optim
import numpy as np
import argparse
import math
import torch.nn as nn
import matplotlib.pyplot as plt
from tqdm import trange
from typing import Tuple, List
from torch.utils.data import TensorDataset, DataLoader
from rdkrc.utils.data_utils import generate_lunar_lander_data_ksteps
from rdkrc.models.psi_mlp import PsiMLP, PsiMLP_v2, PsiMLP_v3
from rdkrc.models.MCDKN import DKN_MC
from rdkrc.trainer.loss_functions import compute_total_loss, ManifoldCtrlLoss, ManifoldEmbLoss
from rdkrc.utils.matrix_utils import compute_C_matrix, update_A_B
from rdkrc.controller.lqr_controller import solve_discrete_lqr, solve_discrete_lqr_v2
from rdkrc.controller.mpc_controller import DKRCMPCController


def test_lander_lqr(
    psi: PsiMLP,
    K_lqr: np.ndarray,
    x_star: torch.Tensor,
    num_episodes: int = 10,
    max_steps: int = 500,
    version: str = "MCDKN",
    seed: int = 2
) -> List[float]:
    """
    æœˆçƒç€é™†å™¨LQRæ§åˆ¶æµ‹è¯•ï¼ˆå«è½åœ°ä½ç½®å‡å€¼/æ–¹å·®ç»Ÿè®¡ä¸è½¨è¿¹æ±‡æ€»å›¾ï¼‰
    ä¾æ®æ–‡æ¡£IV.DèŠ‚ï¼šé€šè¿‡10æ¬¡ç‹¬ç«‹æµ‹è¯•éªŒè¯DKRCé²æ£’æ€§ï¼Œæ–°å¢è½åœ°ä½ç½®ç»Ÿè®¡ä»¥é‡åŒ–ç€é™†ç²¾åº¦ï¼ˆğŸ”¶1-83ã€ğŸ”¶1-87ï¼‰ã€‚
    
    Args:
        psi: è®­ç»ƒå¥½çš„PsiMLPç½‘ç»œï¼ˆå«uâ‚€å‚æ•°ï¼Œæ–‡æ¡£II.36èŠ‚ï¼‰
        K_lqr: LQRæ§åˆ¶å¢ç›Šï¼Œshape=[2, 256]ï¼ˆæ–‡æ¡£IIIèŠ‚ç¦»æ•£LQRæ±‚è§£ï¼‰
        x_star: ç›®æ ‡çŠ¶æ€ï¼ˆç€é™†åŒºï¼Œæ–‡æ¡£IV.DèŠ‚å®šä¹‰ï¼šxã€yå¯¹åº”ç€é™†ä½ç½®ï¼‰ï¼Œshape=[6]
        num_episodes: æµ‹è¯•å›åˆæ•°ï¼ˆæ–‡æ¡£æŒ‡å®š10æ¬¡ï¼Œç¡®ä¿ç»Ÿè®¡é²æ£’æ€§ï¼‰
        max_steps: æ¯å›åˆæœ€å¤§æ­¥æ•°ï¼ˆé¿å…æ— é™å¾ªç¯ï¼Œæ–‡æ¡£æœªæŒ‡å®šæ—¶é»˜è®¤500ï¼‰
        version: PsiMLPç‰ˆæœ¬æ ‡è¯†ï¼ˆç”¨äºåŒºåˆ†ç»“æœæ–‡ä»¶ï¼Œä¸å½±å“ç®—æ³•é€»è¾‘ï¼‰
        seed: éšæœºç§å­ï¼ˆç¡®ä¿ç»“æœå¯å¤ç°ï¼Œæ–‡æ¡£IV.DèŠ‚éšå«è¦æ±‚ï¼‰
    Returns:
        episode_scores: æ¯å›åˆå¾—åˆ†åˆ—è¡¨
    """

    env = gym.make("LunarLanderContinuous-v2")
    env.seed(seed)
    device = next(psi.parameters()).device
    episode_scores: List[float] = []
    all_trajectories: List[List[Tuple[float, float]]] = []  # å­˜å‚¨æ‰€æœ‰episodeçš„x-yè½¨è¿¹ï¼ˆæ–‡æ¡£æ ¸å¿ƒä½ç½®ç»´åº¦ï¼ŒğŸ”¶1-80ï¼‰
    landing_positions: List[Tuple[float, float]] = []  # æ–°å¢ï¼šå­˜å‚¨æ‰€æœ‰episodeçš„è½åœ°ä½ç½®ï¼ˆæœ€ç»ˆx-yåæ ‡ï¼‰
    success_count = 0  # æˆåŠŸç€é™†è®¡æ•°ï¼ˆæ–‡æ¡£IV.DèŠ‚éšå«è¯„ä¼°æ ‡å‡†ï¼šxâˆˆ[-0.5,0.5]ä¸”yâˆˆ[0,0.1]ï¼‰
    psi.eval()  # æ¨ç†æ¨¡å¼ï¼ˆç¦ç”¨æ¢¯åº¦ï¼Œæ–‡æ¡£æµ‹è¯•é˜¶æ®µè¦æ±‚ï¼ŒğŸ”¶1-28ï¼‰
    with torch.no_grad():
        for ep in range(num_episodes):
            # åˆå§‹åŒ–ç¯å¢ƒï¼ˆæ–‡æ¡£IV.DèŠ‚ï¼šéšæœºåˆå§‹æ‰°åŠ¨ï¼Œç¡®ä¿æµ‹è¯•é²æ£’æ€§ï¼‰
            x_prev = env.reset()
            x_prev = x_prev[0:6]  # å–æ–‡æ¡£å®šä¹‰çš„6ç»´çŠ¶æ€ï¼ˆx,y,Î¸,áº‹,áº,Î¸Ì‡ï¼‰ï¼Œä»…x-yç”¨äºè½¨è¿¹ä¸è½åœ°ç»Ÿè®¡ï¼ˆğŸ”¶1-80ï¼‰
            done = False
            total_score = 0.0
            step = 0
            trajectory = []  # è®°å½•å½“å‰episodeçš„x-yè½¨è¿¹ï¼ˆæ–‡æ¡£å›¾8æ ¸å¿ƒç»´åº¦ï¼ŒğŸ”¶1-87ï¼‰

            while not done and step < max_steps:
                # è®°å½•å½“å‰ä½ç½®ï¼ˆä»…ä¿ç•™æ–‡æ¡£å…³æ³¨çš„x-yç»´åº¦ï¼ŒğŸ”¶1-80ã€ğŸ”¶1-87ï¼‰
                trajectory.append((x_prev[0], x_prev[1]))
                # 1. è®¡ç®—é«˜ç»´çº¿æ€§çŠ¶æ€zï¼ˆæ–‡æ¡£Equation 4ï¼šz=Î¨(x)-Î¨(x*)ï¼Œæ ¸å¿ƒçº¿æ€§åŒ–æ­¥éª¤ï¼‰
                x_prev_tensor = torch.tensor(x_prev, device=device, dtype=torch.float32)
                z_prev = psi.embed(x_prev_tensor) - psi.embed(x_star)
                z_prev_np = z_prev.cpu().detach().numpy()

                # 2. è®¡ç®—LQRæ§åˆ¶è¾“å…¥ï¼ˆæ–‡æ¡£IIIèŠ‚ï¼šv_t=-K_lqr z_tï¼Œu_t=v_t+uâ‚€ï¼Œæ§åˆ¶å¾‹è®¾è®¡ï¼‰
                u_t_ = -K_lqr @ z_prev_np.T  # å˜æ¢åæ§åˆ¶è¾“å…¥ï¼ˆé€‚é…é«˜ç»´çº¿æ€§æ¨¡å‹ï¼‰
                u_t_ = torch.tensor(u_t_.T, device=device, dtype=torch.float32)
                # u_t = psi.decode_control(u_t_)[6: ].cpu().detach().numpy()
                u_t = psi.forward_inv_control(x_prev_tensor, u_t_).squeeze(0).cpu().detach().numpy()
                u_t = np.clip(u_t, env.action_space.low, env.action_space.high)  # æ–‡æ¡£éšå«æ§åˆ¶çº¦æŸï¼ˆç‰©ç†æ‰§è¡Œå™¨é™åˆ¶ï¼‰
                # 3. ç¯å¢ƒäº¤äº’ï¼ˆæ–‡æ¡£IV.DèŠ‚ï¼šè·å–ä¸‹ä¸€çŠ¶æ€ä¸å¥–åŠ±ï¼Œå®ŒæˆçŠ¶æ€è¿­ä»£ï¼‰
                x_next, reward, done, _ = env.step(u_t)
                total_score += reward
                x_prev = x_next[0:6]
                step += 1

            # è®°å½•å½“å‰episodeçš„è½åœ°ä½ç½®ï¼ˆæœ€ç»ˆx-yåæ ‡ï¼Œæ–‡æ¡£å…³æ³¨çš„ç€é™†ç²¾åº¦æ ¸å¿ƒæŒ‡æ ‡ï¼‰
            landing_x = x_prev[0]
            landing_y = x_prev[1]
            landing_positions.append((landing_x, landing_y))
            # è®°å½•æœ€ç»ˆä½ç½®ä»¥å®Œå–„è½¨è¿¹ï¼ˆç¡®ä¿â€œåˆå§‹â†’è½åœ°â€å®Œæ•´è·¯å¾„ï¼Œæ–‡æ¡£å›¾8è¦æ±‚ï¼ŒğŸ”¶1-87ï¼‰
            trajectory.append((landing_x, landing_y))
            all_trajectories.append(trajectory)
            episode_scores.append(total_score)

            # æˆåŠŸç€é™†åˆ¤æ–­ï¼ˆæ–‡æ¡£IV.DèŠ‚éšå«è¯„ä¼°æ ‡å‡†ï¼šè½åœ°ä½ç½®åœ¨ç€é™†åŒºé™„è¿‘ï¼‰
            if abs(landing_x) <= 0.5 and -0.2 <= landing_y <= 0.2:
                success_count += 1
            print(f"æµ‹è¯•å›åˆ {ep+1:2d}/{num_episodes} | å¾—åˆ†ï¼š{total_score:5.1f} | æ­¥æ•°ï¼š{step:3d} | è½åœ°ä½ç½®ï¼š(x={landing_x:.3f}, y={landing_y:.3f})")

    env.close()
    # -------------------------- æ–°å¢ï¼šè½åœ°ä½ç½®å‡å€¼/æ–¹å·®è®¡ç®—ï¼ˆæ–‡æ¡£IV.DèŠ‚é‡åŒ–è¯„ä¼°å»¶ä¼¸ï¼‰ --------------------------
    # æå–è½åœ°ä½ç½®çš„xã€yåæ ‡æ•°ç»„
    landing_xs = np.array([pos[0] for pos in landing_positions], dtype=np.float32)
    landing_ys = np.array([pos[1] for pos in landing_positions], dtype=np.float32)
    # è®¡ç®—å‡å€¼ï¼ˆåæ˜ è½åœ°ä½ç½®çš„é›†ä¸­è¶‹åŠ¿ï¼Œé‡åŒ–ç€é™†ç²¾åº¦ï¼‰
    mean_x = np.mean(landing_xs)
    mean_y = np.mean(landing_ys)
    # è®¡ç®—æ–¹å·®ï¼ˆåæ˜ è½åœ°ä½ç½®çš„ç¦»æ•£ç¨‹åº¦ï¼Œé‡åŒ–DKRCé²æ£’æ€§ï¼Œæ–‡æ¡£IV.DèŠ‚â€œå¤šå›åˆä¸€è‡´æ€§â€è¦æ±‚ï¼‰
    var_x = np.var(landing_xs, ddof=1)  # ddof=1ï¼šæ ·æœ¬æ–¹å·®ï¼ˆé€‚é…æœ‰é™æµ‹è¯•å›åˆï¼Œæ›´è´´åˆæ–‡æ¡£10æ¬¡æµ‹è¯•åœºæ™¯ï¼‰
    var_y = np.var(landing_ys, ddof=1)
    # è®¡ç®—æ ‡å‡†å·®ï¼ˆä¾¿äºå›¾è¡¨æ ‡æ³¨ï¼Œç›´è§‚åæ˜ ç¦»æ•£èŒƒå›´ï¼‰
    std_x = np.sqrt(var_x)
    std_y = np.sqrt(var_y)

    # -------------------------- æ–°å¢ï¼šè½åœ°ä½ç½®ç»Ÿè®¡ç»“æœæ‰“å°ï¼ˆå¯¹é½æ–‡æ¡£è¯„ä¼°æŠ¥å‘Šé£æ ¼ï¼‰ --------------------------
    x_star_np = x_star.cpu().numpy()  # ç›®æ ‡çŠ¶æ€ï¼ˆæ–‡æ¡£IV.DèŠ‚ç€é™†åŒºï¼ŒğŸ”¶1-80ï¼‰
    print(f"\n=== è½åœ°ä½ç½®ç»Ÿè®¡ç»“æœï¼ˆæ–‡æ¡£IV.DèŠ‚é‡åŒ–è¯„ä¼°ï¼‰ ===")
    print(f"ç›®æ ‡ç€é™†ä½ç½®ï¼ˆx_starï¼‰ï¼š(x={x_star_np[0]:.3f}, y={x_star_np[1]:.3f})")
    print(f"å®é™…è½åœ°ä½ç½®å‡å€¼ï¼š(x={mean_x:.3f}, y={mean_y:.3f})")
    print(f"å®é™…è½åœ°ä½ç½®æ–¹å·®ï¼ˆæ ·æœ¬æ–¹å·®ï¼‰ï¼švar_x={var_x:.6f}, var_y={var_y:.6f}")
    print(f"å®é™…è½åœ°ä½ç½®æ ‡å‡†å·®ï¼šstd_x={std_x:.3f}, std_y={std_y:.3f}")
    print(f"è½åœ°ä½ç½®ç›¸å¯¹äºç›®æ ‡çš„åç§»ï¼šÎ”x={mean_x - x_star_np[0]:.3f}, Î”y={mean_y - x_star_np[1]:.3f}")

    # -------------------------- è½¨è¿¹æ±‡æ€»å›¾ç»˜åˆ¶ï¼ˆå«è½åœ°ä½ç½®å‡å€¼/æ–¹å·®æ ‡æ³¨ï¼Œä¸¥æ ¼å¯¹é½æ–‡æ¡£å›¾8ï¼‰ --------------------------
    plt.figure(figsize=(10, 8))
    colors = plt.cm.tab10.colors  # å¤šè½¨è¿¹é¢œè‰²åŒºåˆ†ï¼ˆé¿å…é‡å é®æŒ¡ï¼Œæ–‡æ¡£å›¾8é£æ ¼ï¼ŒğŸ”¶1-87ï¼‰

    # 1. ç»˜åˆ¶æ‰€æœ‰episodeçš„è½¨è¿¹ï¼ˆæ–‡æ¡£å›¾8æ ¸å¿ƒå†…å®¹ï¼‰
    for ep, trajectory in enumerate(all_trajectories):
        x_coords = [p[0] for p in trajectory]
        y_coords = [p[1] for p in trajectory]
        color = colors[ep % len(colors)]  # å¾ªç¯åˆ†é…é¢œè‰²ï¼Œé€‚é…æ–‡æ¡£10æ¬¡æµ‹è¯•å›åˆ
        plt.plot(x_coords, y_coords, color=color, alpha=0.7)

    # 2. æ ‡æ³¨ç›®æ ‡ç€é™†ä½ç½®ï¼ˆæ–‡æ¡£IV.DèŠ‚å®šä¹‰çš„ç€é™†åŒºï¼ŒğŸ”¶1-80ï¼‰
    plt.scatter(
        x_star_np[0], x_star_np[1], 
        color="red", marker="s", s=80, edgecolor="black", 
        label=f"Target Landing Pos (x={x_star_np[0]:.1f}, y={x_star_np[1]:.1f})"
    )

    # 3. æ–°å¢ï¼šæ ‡æ³¨è½åœ°ä½ç½®å‡å€¼ï¼ˆåæ˜ é›†ä¸­è¶‹åŠ¿ï¼Œæ–‡æ¡£é‡åŒ–è¯„ä¼°å¯è§†åŒ–ï¼‰
    plt.scatter(
        mean_x, mean_y, 
        color="blue", marker="o", s=100, edgecolor="black", 
        label=f"Landing Mean (x={mean_x:.3f}, y={mean_y:.3f})"
    )

    # 4. æ–°å¢ï¼šæ ‡æ³¨è½åœ°ä½ç½®æ–¹å·®èŒƒå›´ï¼ˆç”¨çŸ©å½¢æ¡†è¡¨ç¤ºÂ±1å€æ ‡å‡†å·®ï¼Œç›´è§‚åæ˜ ç¦»æ•£ç¨‹åº¦ï¼‰
    # xæ–¹å‘èŒƒå›´ï¼šmean_x Â± std_xï¼Œyæ–¹å‘èŒƒå›´ï¼šmean_y Â± std_y
    plt.gca().add_patch(
        plt.Rectangle(
            (mean_x - std_x, mean_y - std_y),  # çŸ©å½¢å·¦ä¸‹è§’
            2 * std_x, 2 * std_y,  # çŸ©å½¢å®½ï¼ˆ2*std_xï¼‰ã€é«˜ï¼ˆ2*std_yï¼‰
            color="blue", alpha=0.2, edgecolor="blue", linestyle="--",
            label=f"Landing Std Range (Â±1Ïƒ)"
        )
    )

    # 5. æ ‡æ³¨ç€é™†åŒºï¼ˆæ–‡æ¡£IV.DèŠ‚ï¼šç€é™†å¹³å°ä½ç½®ï¼Œyå¯¹åº”ç›®æ ‡é«˜åº¦ï¼ŒğŸ”¶1-82ï¼‰
    plt.axhline(y=0, color="black", linestyle="--", alpha=0.8, label="Landing Pad (y=0)")

    # 6. åæ ‡è½´è®¾ç½®ï¼ˆåŒ¹é…æ–‡æ¡£çŠ¶æ€ç©ºé—´ï¼šxâˆˆ[-1.5,1.5]ï¼Œyâˆˆ[0,1.5]ï¼ŒğŸ”¶1-80ï¼‰
    plt.xlim(-1.5, 1.5)
    plt.ylim(0, 1.5)

    # 7. æ ‡ç­¾ä¸æ ‡é¢˜ï¼ˆæ–‡æ¡£å›¾8è§„èŒƒï¼šæ˜ç¡®ä½ç½®ç»´åº¦ä¸å®éªŒå¯¹è±¡ï¼ŒğŸ”¶1-87ï¼‰
    plt.xlabel("X Position (Horizontal)", fontsize=12)
    plt.ylabel("Y Position (Altitude)", fontsize=12)
    if version == "v1":
        plt.title("Lunar Lander Trajectory Summary (DKRC + LQR) with Landing Stats", fontsize=14)
    elif version == "v2":
        plt.title("Lunar Lander Trajectory Summary (RDKRC + LQR) with Landing Stats", fontsize=14)
    elif version == "v3":
        plt.title("Lunar Lander Trajectory Summary (RRDKRC + LQR) with Landing Stats", fontsize=14)

    # 8. å›¾ä¾‹ï¼ˆé¿å…é®æŒ¡è½¨è¿¹ï¼Œæ–‡æ¡£å›¾8å³ä¾§å¸ƒå±€ï¼ŒåŒ…å«æ–°å¢çš„å‡å€¼/æ–¹å·®æ ‡æ³¨ï¼‰
    plt.legend(loc="upper right", bbox_to_anchor=(1.3, 1), fontsize=10)
    plt.grid(True, alpha=0.5)

    # 9. ä¿å­˜æ±‡æ€»å›¾ï¼ˆç¡®ä¿å®Œæ•´æ˜¾ç¤ºå›¾ä¾‹ï¼Œç¬¦åˆæ–‡æ¡£å®éªŒç»“æœä¿å­˜è¦æ±‚ï¼ŒğŸ”¶1-87ï¼‰
    plt.savefig(f"./fig/lunar_lander_trajectory_summary_{version}_with_stats.png", bbox_inches="tight", dpi=300)
    plt.close()

    # -------------------------- æµ‹è¯•ç»“æœæ€»ç»Ÿè®¡ï¼ˆæ–‡æ¡£IV.DèŠ‚è¯„ä¼°æ ‡å‡†ï¼Œè¡¥å……å‡å€¼/æ–¹å·®ä¿¡æ¯ï¼‰ --------------------------
    avg_score = np.mean(episode_scores)
    std_score = np.std(episode_scores)
    print(f"\n=== æµ‹è¯•æ€»æ€»ç»“ï¼ˆæ–‡æ¡£IV.DèŠ‚è¯„ä¼°æ¡†æ¶ï¼‰ ===")
    print(f"å¹³å‡å¾—åˆ†ï¼š{avg_score:.1f}Â±{std_score:.1f} | æˆåŠŸç€é™†ï¼š{success_count}/{num_episodes} æ¬¡")
    print(f"è½åœ°ä½ç½®å‡å€¼ï¼š(x={mean_x:.3f}, y={mean_y:.3f}) | è½åœ°ä½ç½®æ ‡å‡†å·®ï¼š(x={std_x:.3f}, y={std_y:.3f})")

    return episode_scores


def test_lander_mpc(
    psi: PsiMLP,
    mpc_controller: "DKRCMPCController",  # MPCæ§åˆ¶å™¨å®ä¾‹ï¼ˆæ›¿æ¢LQRçš„å¢ç›ŠçŸ©é˜µK_lqrï¼‰
    x_star: torch.Tensor,
    num_episodes: int = 10,
    max_steps: int = 500,
    version: str = "v1",
    seed: int = 2
) -> List[float]:
    """
    æœˆçƒç€é™†å™¨MPCæ§åˆ¶æµ‹è¯•ï¼ˆå«è½åœ°ä½ç½®å‡å€¼/æ–¹å·®ç»Ÿè®¡ä¸è½¨è¿¹æ±‡æ€»å›¾ï¼‰
    ä¾æ®æ–‡æ¡£IIIèŠ‚â€œKoopman-based MPCâ€ä¸IV.DèŠ‚ï¼šé€šè¿‡10æ¬¡ç‹¬ç«‹æµ‹è¯•éªŒè¯MPCé²æ£’æ€§ï¼Œé‡åŒ–ç€é™†ç²¾åº¦ï¼ˆğŸ”¶1-45ã€ğŸ”¶1-83ã€ğŸ”¶1-87ï¼‰ã€‚
    
    Args:
        psi: è®­ç»ƒå¥½çš„PsiMLPç½‘ç»œï¼ˆMPCæ§åˆ¶å™¨å†…éƒ¨ä¾èµ–å…¶è®¡ç®—é«˜ç»´çŠ¶æ€zï¼Œæ–‡æ¡£II.36èŠ‚ï¼‰
        mpc_controller: DKRCMPCControllerå®ä¾‹ï¼ˆå°è£…MPCä¼˜åŒ–é€»è¾‘ï¼Œæ–‡æ¡£IIIèŠ‚ï¼‰
        x_star: ç›®æ ‡çŠ¶æ€ï¼ˆç€é™†åŒºï¼Œæ–‡æ¡£IV.DèŠ‚å®šä¹‰ï¼šxã€yå¯¹åº”ç€é™†ä½ç½®ï¼‰ï¼Œshape=[6]
        num_episodes: æµ‹è¯•å›åˆæ•°ï¼ˆæ–‡æ¡£æŒ‡å®š10æ¬¡ï¼Œç¡®ä¿ç»Ÿè®¡é²æ£’æ€§ï¼‰
        max_steps: æ¯å›åˆæœ€å¤§æ­¥æ•°ï¼ˆé¿å…æ— é™å¾ªç¯ï¼Œæ–‡æ¡£æœªæŒ‡å®šæ—¶é»˜è®¤500ï¼‰
        version: PsiMLPç‰ˆæœ¬æ ‡è¯†ï¼ˆç”¨äºåŒºåˆ†ç»“æœæ–‡ä»¶ï¼Œä¸å½±å“ç®—æ³•é€»è¾‘ï¼‰
        seed: éšæœºç§å­ï¼ˆç¡®ä¿ç»“æœå¯å¤ç°ï¼Œæ–‡æ¡£IV.DèŠ‚éšå«è¦æ±‚ï¼‰
    Returns:
        episode_scores: æ¯å›åˆå¾—åˆ†åˆ—è¡¨ï¼ˆGymå†…ç½®å¾—åˆ†ï¼Œ>200ä¸ºæˆåŠŸç€é™†ï¼Œæ–‡æ¡£IV.DèŠ‚è¯„ä¼°æ ‡å‡†ï¼‰
    """
    env = gym.make("LunarLanderContinuous-v2")
    env.seed(seed)  # å›ºå®šéšæœºç§å­ï¼Œç¡®ä¿æµ‹è¯•å¯å¤ç°ï¼ˆæ–‡æ¡£å®éªŒå¯å¤ç°æ€§éšå«è¦æ±‚ï¼‰
    device = next(psi.parameters()).device
    episode_scores: List[float] = []
    all_trajectories: List[List[Tuple[float, float]]] = []  # å­˜å‚¨æ‰€æœ‰episodeçš„x-yè½¨è¿¹ï¼ˆæ–‡æ¡£æ ¸å¿ƒä½ç½®ç»´åº¦ï¼ŒğŸ”¶1-80ï¼‰
    landing_positions: List[Tuple[float, float]] = []  # å­˜å‚¨æ‰€æœ‰episodeçš„è½åœ°ä½ç½®ï¼ˆæœ€ç»ˆx-yåæ ‡ï¼Œé‡åŒ–ç²¾åº¦æ ¸å¿ƒï¼‰
    success_count = 0  # æˆåŠŸç€é™†è®¡æ•°ï¼ˆæ–‡æ¡£IV.DèŠ‚éšå«è¯„ä¼°æ ‡å‡†ï¼šxâˆˆ[-0.5,0.5]ä¸”yâˆˆ[0,0.1]ï¼‰

    psi.eval()  # æ¨ç†æ¨¡å¼ï¼ˆç¦ç”¨æ¢¯åº¦ï¼Œæ–‡æ¡£æµ‹è¯•é˜¶æ®µè¦æ±‚ï¼ŒğŸ”¶1-28ï¼‰
    with torch.no_grad():
        for ep in trange(num_episodes):
            # åˆå§‹åŒ–ç¯å¢ƒï¼ˆæ–‡æ¡£IV.DèŠ‚ï¼šéšæœºåˆå§‹æ‰°åŠ¨ï¼ŒéªŒè¯MPCå¯¹æ‰°åŠ¨çš„é²æ£’æ€§ï¼‰
            x_prev = env.reset()  # Gymæ¥å£ï¼šè¿”å›åˆå§‹çŠ¶æ€ï¼ˆå«éšæœºä½ç½®/é€Ÿåº¦æ‰°åŠ¨ï¼‰
            x_prev = x_prev[0:6]  # å–æ–‡æ¡£å®šä¹‰çš„6ç»´çŠ¶æ€ï¼ˆx,y,Î¸,áº‹,áº,Î¸Ì‡ï¼‰ï¼Œä»…x-yç”¨äºè½¨è¿¹ä¸è½åœ°ç»Ÿè®¡ï¼ˆğŸ”¶1-80ï¼‰
            done = False
            total_score = 0.0
            step = 0
            trajectory = []  # è®°å½•å½“å‰episodeçš„x-yè½¨è¿¹ï¼ˆæ–‡æ¡£å›¾8æ ¸å¿ƒç»´åº¦ï¼Œç›´è§‚å±•ç¤ºè·¯å¾„ï¼ŒğŸ”¶1-87ï¼‰

            while not done and step < max_steps:
                # è®°å½•å½“å‰ä½ç½®ï¼ˆä»…ä¿ç•™æ–‡æ¡£å…³æ³¨çš„x-yç»´åº¦ï¼Œå¿½ç•¥å§¿æ€/é€Ÿåº¦ï¼Œèšç„¦ç€é™†ä½ç½®ï¼ŒğŸ”¶1-80ã€ğŸ”¶1-87ï¼‰
                trajectory.append((x_prev[0], x_prev[1]))

                # 1. è®¡ç®—MPCæœ€ä¼˜æ§åˆ¶è¾“å…¥ï¼ˆæ ¸å¿ƒå·®å¼‚ï¼šæ›¿æ¢LQRçš„å¢ç›ŠçŸ©é˜µè®¡ç®—ï¼Œæ–‡æ¡£IIIèŠ‚MPCé€»è¾‘ï¼‰
                # MPCæ§åˆ¶å™¨ç›´æ¥æ¥æ”¶åŸçŠ¶æ€x_prevï¼Œå†…éƒ¨è‡ªåŠ¨å®Œæˆé«˜ç»´çŠ¶æ€zè®¡ç®—ä¸ä¼˜åŒ–ï¼ˆå°è£…æ–‡æ¡£Equation 5ä¸11ï¼‰
                u_current = mpc_controller.compute_control(x_prev)  # shape=[2]ï¼ˆä¸»å¼•æ“+ä¾§å¼•æ“ï¼ŒğŸ”¶1-80ï¼‰

                # 2. æ§åˆ¶è¾“å…¥åŒé‡è£å‰ªï¼ˆç¡®ä¿åœ¨ç¯å¢ƒåŠ¨ä½œç©ºé—´å†…ï¼ŒMPCå†…éƒ¨å·²è£å‰ªï¼Œæ­¤å¤„åŒé‡ä¿é™©ç¬¦åˆæ–‡æ¡£ç‰©ç†çº¦æŸï¼ŒğŸ”¶1-82ï¼‰
                u_current = np.clip(u_current, env.action_space.low, env.action_space.high)

                # 3. ç¯å¢ƒäº¤äº’ï¼ˆæ–‡æ¡£IV.DèŠ‚ï¼šè·å–ä¸‹ä¸€çŠ¶æ€ä¸å¥–åŠ±ï¼Œå®ŒæˆçŠ¶æ€è¿­ä»£ï¼Œä¸LQRæµ‹è¯•é€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
                x_next, reward, done, _ = env.step(u_current)
                total_score += reward
                x_prev = x_next[0:6]  # æ›´æ–°çŠ¶æ€ï¼Œä¿ç•™å‰6ç»´æ ¸å¿ƒçŠ¶æ€
                step += 1

            # è®°å½•å½“å‰episodeçš„å…³é”®ç»“æœï¼ˆè½åœ°ä½ç½®+å®Œæ•´è½¨è¿¹ï¼‰
            landing_x, landing_y = x_prev[0], x_prev[1]
            landing_positions.append((landing_x, landing_y))
            trajectory.append((landing_x, landing_y))  # è¡¥å……æœ€ç»ˆè½åœ°ä½ç½®ï¼Œç¡®ä¿è½¨è¿¹å®Œæ•´ï¼ˆæ–‡æ¡£å›¾8è¦æ±‚ï¼ŒğŸ”¶1-87ï¼‰
            all_trajectories.append(trajectory)
            episode_scores.append(total_score)

            # æˆåŠŸç€é™†åˆ¤æ–­ï¼ˆæ–‡æ¡£IV.DèŠ‚éšå«è¯„ä¼°æ ‡å‡†ï¼šè½åœ°ä½ç½®åœ¨ç€é™†å¹³å°é™„è¿‘ï¼Œé‡åŒ–MPCæ§åˆ¶ç²¾åº¦ï¼‰
            if abs(landing_x) <= 0.5 and -0.1 <= landing_y <= 0.1:
                success_count += 1
            # æ‰“å°å•å›åˆç»“æœï¼ˆå®æ—¶ç›‘æ§æµ‹è¯•è¿‡ç¨‹ï¼Œç¬¦åˆæ–‡æ¡£å®éªŒæ—¥å¿—é£æ ¼ï¼‰
            print(f"æµ‹è¯•å›åˆ {ep+1:2d}/{num_episodes} | å¾—åˆ†ï¼š{total_score:5.1f} | æ­¥æ•°ï¼š{step:3d} | è½åœ°ä½ç½®ï¼š(x={landing_x:.3f}, y={landing_y:.3f})")

    env.close()  # å…³é—­ç¯å¢ƒï¼Œé‡Šæ”¾èµ„æº

    # -------------------------- è½åœ°ä½ç½®é‡åŒ–ç»Ÿè®¡ï¼ˆæ–‡æ¡£IV.DèŠ‚é‡åŒ–è¯„ä¼°å»¶ä¼¸ï¼Œä¸LQRæµ‹è¯•å®Œå…¨ä¸€è‡´ï¼‰ --------------------------
    # æå–è½åœ°ä½ç½®çš„xã€yåæ ‡æ•°ç»„ï¼ˆç”¨äºè®¡ç®—ç»Ÿè®¡é‡ï¼‰
    landing_xs = np.array([pos[0] for pos in landing_positions], dtype=np.float32)
    landing_ys = np.array([pos[1] for pos in landing_positions], dtype=np.float32)
    # 1. å‡å€¼ï¼šåæ˜ è½åœ°ä½ç½®çš„é›†ä¸­è¶‹åŠ¿ï¼Œé‡åŒ–MPCçš„ç€é™†ç²¾åº¦ï¼ˆè¶Šæ¥è¿‘x_starè¶Šä¼˜ï¼ŒğŸ”¶1-80ï¼‰
    mean_x = np.mean(landing_xs)
    mean_y = np.mean(landing_ys)
    # 2. æ ·æœ¬æ–¹å·®ï¼šåæ˜ è½åœ°ä½ç½®çš„ç¦»æ•£ç¨‹åº¦ï¼Œé‡åŒ–MPCçš„é²æ£’æ€§ï¼ˆè¶Šå°è¶Šä¼˜ï¼Œæ–‡æ¡£IV.DèŠ‚â€œå¤šå›åˆä¸€è‡´æ€§â€è¦æ±‚ï¼ŒğŸ”¶1-83ï¼‰
    var_x = np.var(landing_xs, ddof=1)  # ddof=1ï¼šæ ·æœ¬æ–¹å·®ï¼Œé€‚é…10æ¬¡æœ‰é™æµ‹è¯•å›åˆ
    var_y = np.var(landing_ys, ddof=1)
    # 3. æ ‡å‡†å·®ï¼šç›´è§‚åæ˜ ç¦»æ•£èŒƒå›´ï¼ˆç”¨äºå›¾è¡¨æ ‡æ³¨ï¼ŒğŸ”¶1-87ï¼‰
    std_x = np.sqrt(var_x)
    std_y = np.sqrt(var_y)

    # -------------------------- ç»Ÿè®¡ç»“æœæ‰“å°ï¼ˆå¯¹é½æ–‡æ¡£è¯„ä¼°æŠ¥å‘Šé£æ ¼ï¼Œä¸LQRæµ‹è¯•æ ¼å¼ç»Ÿä¸€ï¼‰ --------------------------
    x_star_np = x_star.cpu().numpy()  # ç›®æ ‡ç€é™†ä½ç½®ï¼ˆæ–‡æ¡£IV.DèŠ‚å®šä¹‰ï¼ŒğŸ”¶1-80ï¼‰
    print(f"\n=== è½åœ°ä½ç½®ç»Ÿè®¡ç»“æœï¼ˆæ–‡æ¡£IV.DèŠ‚é‡åŒ–è¯„ä¼°ï¼‰ ===")
    print(f"ç›®æ ‡ç€é™†ä½ç½®ï¼ˆx_starï¼‰ï¼š(x={x_star_np[0]:.3f}, y={x_star_np[1]:.3f})")
    print(f"å®é™…è½åœ°ä½ç½®å‡å€¼ï¼š(x={mean_x:.3f}, y={mean_y:.3f})")
    print(f"å®é™…è½åœ°ä½ç½®æ–¹å·®ï¼ˆæ ·æœ¬æ–¹å·®ï¼‰ï¼švar_x={var_x:.6f}, var_y={var_y:.6f}")
    print(f"å®é™…è½åœ°ä½ç½®æ ‡å‡†å·®ï¼šstd_x={std_x:.3f}, std_y={std_y:.3f}")
    print(f"è½åœ°ä½ç½®ç›¸å¯¹äºç›®æ ‡çš„åç§»ï¼šÎ”x={mean_x - x_star_np[0]:.3f}, Î”y={mean_y - x_star_np[1]:.3f}")

    # -------------------------- è½¨è¿¹æ±‡æ€»å›¾ç»˜åˆ¶ï¼ˆä¸¥æ ¼å¯¹é½æ–‡æ¡£å›¾8é£æ ¼ï¼Œä¸LQRæµ‹è¯•è§†è§‰ç»Ÿä¸€ï¼‰ --------------------------
    plt.figure(figsize=(10, 8))
    colors = plt.cm.tab10.colors  # å¤šè½¨è¿¹é¢œè‰²åŒºåˆ†ï¼ˆé¿å…é‡å é®æŒ¡ï¼Œæ–‡æ¡£å›¾8å¤šå›åˆå±•ç¤ºé€»è¾‘ï¼ŒğŸ”¶1-87ï¼‰

    # 1. ç»˜åˆ¶æ‰€æœ‰episodeçš„å®Œæ•´è½¨è¿¹ï¼ˆæ–‡æ¡£å›¾8æ ¸å¿ƒå†…å®¹ï¼Œç›´è§‚å±•ç¤ºMPCçš„è·¯å¾„è§„åˆ’èƒ½åŠ›ï¼‰
    for ep, trajectory in enumerate(all_trajectories):
        x_coords = [p[0] for p in trajectory]
        y_coords = [p[1] for p in trajectory]
        color = colors[ep % len(colors)]  # å¾ªç¯åˆ†é…é¢œè‰²ï¼Œé€‚é…10æ¬¡æµ‹è¯•å›åˆ
        plt.plot(x_coords, y_coords, color=color, alpha=0.7)

    # 2. æ ‡æ³¨ç›®æ ‡ç€é™†ä½ç½®ï¼ˆæ–‡æ¡£IV.DèŠ‚å®šä¹‰çš„ç€é™†åŒºï¼Œçº¢è‰²æ­£æ–¹å½¢ï¼Œä¸LQRæµ‹è¯•è§†è§‰ä¸€è‡´ï¼‰
    plt.scatter(
        x_star_np[0], x_star_np[1], 
        color="red", marker="s", s=80, edgecolor="black", 
        label=f"Target Landing Pos (x={x_star_np[0]:.1f}, y={x_star_np[1]:.1f})"
    )

    # 3. æ ‡æ³¨è½åœ°ä½ç½®å‡å€¼ï¼ˆè“è‰²åœ†å½¢ï¼Œåæ˜ é›†ä¸­è¶‹åŠ¿ï¼Œæ–‡æ¡£é‡åŒ–è¯„ä¼°å¯è§†åŒ–ï¼ŒğŸ”¶1-87ï¼‰
    plt.scatter(
        mean_x, mean_y, 
        color="blue", marker="o", s=100, edgecolor="black", 
        label=f"Landing Mean (x={mean_x:.3f}, y={mean_y:.3f})"
    )

    # 4. æ ‡æ³¨è½åœ°ä½ç½®æ–¹å·®èŒƒå›´ï¼ˆè“è‰²åŠé€æ˜çŸ©å½¢ï¼ŒÂ±1å€æ ‡å‡†å·®ï¼Œç›´è§‚åæ˜ é²æ£’æ€§ï¼ŒğŸ”¶1-83ï¼‰
    plt.gca().add_patch(
        plt.Rectangle(
            (mean_x - std_x, mean_y - std_y),  # çŸ©å½¢å·¦ä¸‹è§’ï¼ˆå‡å€¼-æ ‡å‡†å·®ï¼‰
            2 * std_x, 2 * std_y,  # çŸ©å½¢å®½ï¼ˆ2*std_xï¼‰ã€é«˜ï¼ˆ2*std_yï¼‰
            color="blue", alpha=0.2, edgecolor="blue", linestyle="--",
            label=f"Landing Std Range (Â±1Ïƒ)"
        )
    )

    # 5. æ ‡æ³¨ç€é™†å¹³å°ï¼ˆé»‘è‰²è™šçº¿ï¼Œæ–‡æ¡£IV.DèŠ‚â€œç€é™†åŒºy=0â€å®šä¹‰ï¼ŒğŸ”¶1-82ï¼‰
    plt.axhline(y=0, color="black", linestyle="--", alpha=0.8, label="Landing Pad (y=0)")

    # 6. åæ ‡è½´è®¾ç½®ï¼ˆåŒ¹é…æ–‡æ¡£çŠ¶æ€ç©ºé—´ï¼šxâˆˆ[-1.5,1.5]ï¼Œyâˆˆ[0,1.5]ï¼Œç¡®ä¿ä¸LQRæµ‹è¯•å¯¹æ¯”æ—¶å°ºåº¦ç»Ÿä¸€ï¼ŒğŸ”¶1-80ï¼‰
    plt.xlim(-1.5, 1.5)
    plt.ylim(0, 1.5)

    # 7. æ ‡ç­¾ä¸æ ‡é¢˜ï¼ˆæ–‡æ¡£å›¾8è§„èŒƒï¼Œæ˜ç¡®æ§åˆ¶å™¨ç±»å‹ï¼Œä¸LQRæµ‹è¯•åŒºåˆ†ï¼‰
    plt.xlabel("X Position (Horizontal)", fontsize=12)
    plt.ylabel("Y Position (Altitude)", fontsize=12)
    if version == "v1":
        plt.title("Lunar Lander Trajectory Summary (DKRC + MPC) with Landing Stats", fontsize=14)
    elif version == "v2":
        plt.title("Lunar Lander Trajectory Summary (RDKRC + MPC) with Landing Stats", fontsize=14)
    elif version == "v3":
        plt.title("Lunar Lander Trajectory Summary (RRDKRC + MPC) with Landing Stats", fontsize=14)

    # 8. å›¾ä¾‹ï¼ˆå³ä¾§å¤–æ‘†å¼å¸ƒå±€ï¼Œé¿å…é®æŒ¡è½¨è¿¹ï¼Œä¸LQRæµ‹è¯•æ ¼å¼ä¸€è‡´ï¼‰
    plt.legend(loc="upper right", bbox_to_anchor=(1.3, 1), fontsize=10)
    plt.grid(True, alpha=0.5)

    # 9. ä¿å­˜æ±‡æ€»å›¾ï¼ˆç¡®ä¿å®Œæ•´æ˜¾ç¤ºå›¾ä¾‹ï¼Œç¬¦åˆæ–‡æ¡£å®éªŒç»“æœä¿å­˜è¦æ±‚ï¼Œä¾¿äºåç»­å¯¹æ¯”åˆ†æï¼ŒğŸ”¶1-87ï¼‰
    plt.savefig(f"./fig/lunar_lander_trajectory_summary_{version}_mpc_with_stats.png", bbox_inches="tight", dpi=300)
    plt.close()

    # -------------------------- æµ‹è¯•æ€»æ€»ç»“ï¼ˆæ–‡æ¡£IV.DèŠ‚è¯„ä¼°æ¡†æ¶ï¼Œä¸LQRæµ‹è¯•æŒ‡æ ‡ç»Ÿä¸€ï¼‰ --------------------------
    avg_score = np.mean(episode_scores)
    std_score = np.std(episode_scores)
    print(f"\n=== æµ‹è¯•æ€»æ€»ç»“ï¼ˆæ–‡æ¡£IV.DèŠ‚è¯„ä¼°æ¡†æ¶ï¼‰ ===")
    print(f"å¹³å‡å¾—åˆ†ï¼š{avg_score:.1f}Â±{std_score:.1f} | æˆåŠŸç€é™†ï¼š{success_count}/{num_episodes} æ¬¡")
    print(f"è½åœ°ä½ç½®å‡å€¼ï¼š(x={mean_x:.3f}, y={mean_y:.3f}) | è½åœ°ä½ç½®æ ‡å‡†å·®ï¼š(x={std_x:.3f}, y={std_y:.3f})")

    return episode_scores

def train_mc_dkn(
    X_train: torch.Tensor,  # [N, T, x_dim]
    U_train: torch.Tensor,  # [N, T, u_dim]
    batch_size: int = 128,
    epochs_stage1: int = 100,
    epochs_stage2: int = 300,
    lr: float = 1e-3,
    neighbors: int = 10,
    K_steps: int = 15,
    alpha: float = 0.1,  # åµŒå…¥æµå½¢çº¦æŸæƒé‡
    beta: float = 0.4,   # æ§åˆ¶æµå½¢çº¦æŸæƒé‡
    gamma: float = 0.2,   # é€†æ˜ å°„æŸå¤±æƒé‡
    version:str = 'v1'
):
    env = gym.make("LunarLanderContinuous-v2")
    action_low = env.action_space.low
    action_high = env.action_space.high
    state_low = [-2, -2, -5, -5, -math.pi, -5]
    state_high = [2, 2, 5, 5, math.pi, 5]
    dataset = TensorDataset(X_train, U_train)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)
    model = DKN_MC(x_dim=args.x_dim, u_dim=args.control_dim,hidden_dim=128,manifold_dim=args.x_dim, state_low=state_low, state_high=state_high, 
                   action_low=action_low, action_high=action_high, device=torch.device("cuda" if torch.cuda.is_available() else "cpu")).to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
    # åˆå§‹åŒ–ç»„ä»¶
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    k_step_loss = nn.MSELoss()
    manifold_emb_loss = ManifoldEmbLoss(k=neighbors)
    manifold_ctrl_loss = ManifoldCtrlLoss()
    inv_loss = nn.MSELoss()
    # 5. åˆå§‹åŒ–æŸå¤±è®°å½•åˆ—è¡¨ï¼ˆåˆ†é˜¶æ®µå­˜å‚¨å„é¡¹æŸå¤±ï¼‰
    stage1_k_losses: List[float] = []  # é˜¶æ®µ1ï¼šä»…K-stepæŸå¤±
    # é˜¶æ®µ2ï¼šæ€»æŸå¤± + å„å­æŸå¤±
    stage2_total_losses: List[float] = []
    stage2_k_losses: List[float] = []
    stage2_emb_losses: List[float] = []
    stage2_ctrl_losses: List[float] = []
    stage2_inv_losses: List[float] = []
    # -------------------------- é˜¶æ®µ1ï¼šåŸºç¡€é¢„è®­ç»ƒï¼ˆæ— æµå½¢çº¦æŸï¼‰ --------------------------
    model.train()
    print("é˜¶æ®µ1ï¼šåŸºç¡€é¢„è®­ç»ƒï¼ˆæ— æµå½¢çº¦æŸï¼‰...")
    for epoch in range(epochs_stage1):
        total_loss = 0.0
        actual_num_batches = 0

        for batch in dataloader:
            # å–æ‰¹æ¬¡æ•°æ®
            batch_X, batch_U = batch
            # Kæ­¥é¢„æµ‹ï¼ˆk=15ï¼Œæ–‡æ¡£V.BèŠ‚ï¼‰
            x0 = batch_X[:, 0, :]  # [batch, x_dim]
            u_seq = batch_U.permute(1, 0, 2)  # [15, batch, u_dim]
            x_pred_seq = model.predict_k_steps(x0, u_seq, k=K_steps)  # [16, batch, x_dim]
            x_pred_seq = x_pred_seq.permute(1, 0, 2)  # [batch, 16, x_dim]
            
            # åŸKæ­¥æŸå¤±ï¼ˆEq.14ï¼‰
            loss_k = 0.0
            for i in range(1, K_steps):
                weight = 0.95 ** (i-1)  # gamma=0.95ï¼Œæ–‡æ¡£Eq.14
                loss_k += weight * k_step_loss(x_pred_seq[:, i, :], batch_X[:, i, :])
            
            # ä¼˜åŒ–
            optimizer.zero_grad()
            loss_k.backward()
            optimizer.step()
            total_loss += loss_k.item()
            actual_num_batches += 1
        # è®¡ç®—å½“å‰epochå¹³å‡æŸå¤±å¹¶è®°å½•
        avg_k_loss = total_loss / actual_num_batches
        stage1_k_losses.append(avg_k_loss)

        if (epoch + 1) % 20 == 0:
            print(f"Stage1 Epoch {epoch+1:4d} | K-step Loss: {avg_k_loss:.6f}")
    plot_stage1_losses(stage1_k_losses, version)
    # -------------------------- é˜¶æ®µ2ï¼šæµå½¢çº¦æŸè®­ç»ƒ --------------------------
    print("\né˜¶æ®µ2ï¼šæµå½¢çº¦æŸè®­ç»ƒ...")
    for epoch in range(epochs_stage2):
        total_total_loss = 0.0
        total_k_loss = 0.0
        total_emb_loss = 0.0
        total_ctrl_loss = 0.0
        total_inv_loss = 0.0
        actual_num_batches = 0
        
        for batch in dataloader:
            batch_X, batch_U = batch  # ç›´æ¥ä»dataloaderè·å–batch
            batch_X = batch_X.to(device)
            batch_U = batch_U.to(device)
            batch_size = batch_X.shape[0]
            
            # 1. Kæ­¥é¢„æµ‹æŸå¤±ï¼ˆåŸºç¡€ï¼‰
            x0 = batch_X[:, 0, :]
            u_seq = batch_U.permute(1, 0, 2)
            x_pred_seq = model.predict_k_steps(x0, u_seq, k=K_steps)
            x_pred_seq = x_pred_seq.permute(1, 0, 2)
            loss_k = 0.0
            for i in range(1, K_steps):
                weight = 0.95 ** (i-1)
                loss_k += weight * k_step_loss(x_pred_seq[:, i, :], batch_X[:, i, :])
            
            # 2. åµŒå…¥æµå½¢çº¦æŸæŸå¤±ï¼ˆå±€éƒ¨é‚»åŸŸä¿æŒï¼‰
            # å–æ‰¹æ¬¡å†…æ‰€æœ‰çŠ¶æ€æ ·æœ¬ï¼ˆflatä¸º[N*T, x_dim]ï¼‰
            X_batch_flat = batch_X.view(-1, model.x_dim)  # [batch*T, x_dim]
            z_batch_flat = model.embed(X_batch_flat)  # [batch*T, manifold_dim]
            loss_emb = manifold_emb_loss(z_batch_flat, X_batch_flat)
            
            # 3. æ§åˆ¶æµå½¢çº¦æŸæŸå¤±ï¼ˆçº¿æ€§æ¼”åŒ–ä¸€è‡´æ€§ï¼‰
            # å–t=0åˆ°t=T-2çš„æ—¶åºå¯¹ï¼ˆz_t, z_t1, g_phi_tï¼‰
            z_M_t = model.embed(batch_X[:, :-1, :].reshape(-1, model.x_dim))  # [batch*(T-1), manifold_dim]
            z_M_t1 = model.embed(batch_X[:, 1:, :].reshape(-1, model.x_dim))  # [batch*(T-1), manifold_dim]
            g_phi_t = model.forward_control(
                batch_X[:, :-1, :].reshape(-1, model.x_dim),
                batch_U[:, :-1, :].reshape(-1, model.u_dim)
            )  # [batch*(T-1), u_dim]
            loss_ctrl = manifold_ctrl_loss(model.A, model.B, z_M_t, z_M_t1, g_phi_t)
            
            # 4. é€†æ˜ å°„æŸå¤±
            u_flat = batch_U.view(-1, model.u_dim)  # [batch*T, u_dim]
            g_phi_flat = model.forward_control(X_batch_flat, u_flat)  # [batch*T, u_dim]
            u_recov = model.forward_inv_control(X_batch_flat, g_phi_flat)  # [batch*T, u_dim]
            loss_inv = inv_loss(u_flat, u_recov)
            
            # æ€»æŸå¤±
            loss_total = loss_k + alpha * loss_emb + beta * loss_ctrl + gamma * loss_inv
            
            # ä¼˜åŒ–
            optimizer.zero_grad()
            loss_total.backward()
            optimizer.step()
            
            # ç´¯è®¡æŸå¤±
            # ç´¯è®¡å„é¡¹æŸå¤±ä¸batchæ•°
            total_total_loss += loss_total.item()
            total_k_loss += loss_k.item()
            total_emb_loss += loss_emb.item()
            total_ctrl_loss += loss_ctrl.item()
            total_inv_loss += loss_inv.item()
            actual_num_batches += 1
        # è®¡ç®—å½“å‰epochå¹³å‡æŸå¤±å¹¶è®°å½•
        avg_total_loss = total_total_loss / actual_num_batches
        avg_k_loss = total_k_loss / actual_num_batches
        avg_emb_loss = total_emb_loss / actual_num_batches
        avg_ctrl_loss = total_ctrl_loss / actual_num_batches
        avg_inv_loss = total_inv_loss / actual_num_batches
        
        stage2_total_losses.append(avg_total_loss)
        stage2_k_losses.append(avg_k_loss)
        stage2_emb_losses.append(avg_emb_loss)
        stage2_ctrl_losses.append(avg_ctrl_loss)
        stage2_inv_losses.append(avg_inv_loss)
        # æ‰“å°è¿›åº¦ï¼ˆæ¯50è½®ï¼‰
        if (epoch + 1) % 100 == 0:
            for param_group in optimizer.param_groups:
                    param_group['lr'] *= 0.5
        if (epoch + 1) % 50 == 0:
            print(f"Stage2 Epoch {epoch+1:4d} | Total Loss: {avg_total_loss:.6f} | "
                  f"K-step: {avg_k_loss:.6f} | Emb: {avg_emb_loss:.6f} | "
                  f"Ctrl: {avg_ctrl_loss:.6f} | Inv: {avg_inv_loss:.6f}")
    # é˜¶æ®µ2ç»“æŸï¼šç»˜åˆ¶å„é¡¹æŸå¤±å¯¹æ¯”æ›²çº¿
    plot_stage2_losses(
        total_losses=stage2_total_losses,
        k_losses=stage2_k_losses,
        emb_losses=stage2_emb_losses,
        ctrl_losses=stage2_ctrl_losses,
        inv_losses=stage2_inv_losses,
        version=version
    )
    return model

def calculate_parameter(psi, x_dim, z_dim, control_dim):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    A_lander = psi.A.weight
    B_lander = psi.B.weight
    I_n = torch.eye(x_dim, device=device)
    zero_mat = torch.zeros(x_dim, z_dim, device=device)
    C = torch.cat([I_n, zero_mat], dim=1)
    Q = torch.eye(x_dim, device=device)
    Q_ = C.T @ Q @ C
    Q_ = 0.5 * (Q_ + Q_.T)
    R_ = 0.1 * torch.eye(control_dim, device=device)

    Q_ = Q_.cpu().detach().numpy()
    R_ = R_.cpu().detach().numpy()
    return A_lander, B_lander, Q_, R_

def plot_stage1_losses(loss_list: List[float], version: str) -> None:
    """ç»˜åˆ¶é˜¶æ®µ1çš„K-stepæŸå¤±æ›²çº¿ï¼ˆä»…1æ¡æ›²çº¿ï¼Œèšç„¦é¢„è®­ç»ƒæ”¶æ•›æƒ…å†µï¼‰"""
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, len(loss_list)+1), loss_list, color="#2E86AB", linewidth=2, label="K-step Loss")
    
    # å›¾è¡¨ç¾åŒ–ä¸æ ‡æ³¨
    plt.xlabel("Epoch", fontsize=12)
    plt.ylabel("Loss", fontsize=12)
    plt.title(f"Stage 1: K-step Loss Curve (Version: {version})", fontsize=14, pad=20)
    plt.yscale("log")  # å¯¹æ•°åˆ»åº¦ï¼šæ¸…æ™°å±•ç¤ºæŸå¤±ä¸‹é™è¶‹åŠ¿ï¼ˆå°¤å…¶å‰æœŸå¿«é€Ÿä¸‹é™é˜¶æ®µï¼‰
    plt.grid(True, alpha=0.3, linestyle="--")
    plt.legend(fontsize=10)
    
    # ä¿å­˜å›¾ç‰‡ï¼ˆç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œé¿å…æŠ¥é”™ï¼‰
    os.makedirs("./fig", exist_ok=True)  # è‹¥./figä¸å­˜åœ¨åˆ™åˆ›å»º
    plt.savefig(f"./fig/stage1_kstep_loss_{version}.png", dpi=300, bbox_inches="tight")
    plt.close()  # å…³é—­ç”»å¸ƒï¼Œé‡Šæ”¾å†…å­˜


def plot_stage2_losses(
    total_losses: List[float],
    k_losses: List[float],
    emb_losses: List[float],
    ctrl_losses: List[float],
    inv_losses: List[float],
    version: str
) -> None:
    """ç»˜åˆ¶é˜¶æ®µ2çš„æ‰€æœ‰æŸå¤±å¯¹æ¯”æ›²çº¿ï¼ˆæ€»æŸå¤±+4ä¸ªå­æŸå¤±ï¼Œä¾¿äºåˆ†æå„çº¦æŸæ•ˆæœï¼‰"""
    plt.figure(figsize=(12, 8))
    epochs = range(1, len(total_losses)+1)
    
    # ç»˜åˆ¶å„æŸå¤±æ›²çº¿ï¼ˆé¢œè‰²/çº¿å‹åŒºåˆ†ï¼Œä¾¿äºè¯†åˆ«ï¼‰
    plt.plot(epochs, total_losses, color="#A23B72", linewidth=3, label="Total Loss", zorder=5)  # æ€»æŸå¤±ç½®é¡¶
    plt.plot(epochs, k_losses, color="#F18F01", linestyle="--", linewidth=2, label="K-step Loss")
    plt.plot(epochs, emb_losses, color="#C73E1D", linestyle="-.", linewidth=2, label="Embedding Loss")
    plt.plot(epochs, ctrl_losses, color="#2E86AB", linestyle=":", linewidth=2, label="Control Loss")
    plt.plot(epochs, inv_losses, color="#6A994E", linestyle="--", linewidth=2, label="Inverse Loss")
    
    # å›¾è¡¨ç¾åŒ–ä¸æ ‡æ³¨
    plt.xlabel("Epoch", fontsize=12)
    plt.ylabel("Loss", fontsize=12)
    plt.title(f"Stage 2: Loss Curves Comparison (Version: {version})", fontsize=14, pad=20)
    plt.yscale("log")  # å¯¹æ•°åˆ»åº¦ï¼šé¿å…æŸç±»æŸå¤±è¿‡å¤§æ©ç›–å…¶ä»–æŸå¤±çš„å˜åŒ–
    plt.grid(True, alpha=0.3, linestyle="--")
    plt.legend(fontsize=10, loc="upper right")  # å›¾ä¾‹æ”¾å³ä¸Šè§’ï¼Œé¿å…é®æŒ¡æ›²çº¿
    
    # ä¿å­˜å›¾ç‰‡ï¼ˆç¡®ä¿ç›®å½•å­˜åœ¨ï¼‰
    os.makedirs("./fig", exist_ok=True)
    plt.savefig(f"./fig/stage2_all_losses_{version}.png", dpi=300, bbox_inches="tight")
    plt.close()

if __name__ == "__main__":  
    parse = argparse.ArgumentParser()
    parse.add_argument('--test_version', type=str, default='MCDKN', help='PsiMLPç‰ˆæœ¬ï¼ˆv1æˆ–v2ï¼‰')
    parse.add_argument('--controller_type', type=str, default='lqr', help='æ§åˆ¶å™¨ç±»å‹ï¼ˆlqræˆ–mpcï¼‰')
    parse.add_argument('--seed', type=int, default=50, help='éšæœºç§å­')
    parse.add_argument('--lr', type=float, default=1e-3, help='å­¦ä¹ ç‡')
    parse.add_argument('--epochs_stage1', type=int, default=100, help='ä¸€é˜¶æ®µè®­ç»ƒè½®æ¬¡')
    parse.add_argument('--epochs_stage2', type=int, default=500, help='äºŒé˜¶æ®µè®­ç»ƒè½®æ¬¡')
    parse.add_argument('--data_epochs', type=int, default=50, help='æ•°æ®è½®æ¬¡')
    parse.add_argument('--batch_size', type=int, default=256, help='æ‰¹é‡å¤§å°')
    parse.add_argument('--num_episodes', type=int, default=100, help='æµ‹è¯•å›åˆæ•°')
    parse.add_argument('--data_prepared', action='store_true', help='æ˜¯å¦ä½¿ç”¨é¢„ç”Ÿæˆæ•°æ®')
    parse.add_argument('--z_dim', type=int, default=12, help='é«˜ç»´çŠ¶æ€ç»´åº¦N')
    parse.add_argument('--x_dim', type=int, default=6, help='çŠ¶æ€ç»´åº¦')
    parse.add_argument('--control_dim', type=int, default=2, help='æ§åˆ¶ç»´åº¦')
    parse.add_argument('--neighbors', type=int, default=10, help='é‚»å±…æ•°')
    parse.add_argument('--K_steps', type=int, default=15, help='æ—¶åŸŸé•¿åº¦')
    # é€‰æ‹©æµ‹è¯•ç‰ˆæœ¬ï¼ˆ"v1"ä¸ºåŸºç¡€ç‰ˆï¼Œ"v2"ä¸ºæ”¹è¿›ç‰ˆï¼‰ seed history:2\33\444\22\\789\666
    # test_version = "v1"
    args = parse.parse_args()
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # å®Œæ•´DKRCæµç¨‹ï¼ˆæ–‡æ¡£IV.DèŠ‚å®éªŒæ­¥éª¤ï¼šæ•°æ®ç”Ÿæˆâ†’ç½‘ç»œè®­ç»ƒâ†’æ§åˆ¶æµ‹è¯•ï¼‰
    # æ­¥éª¤1ï¼šç”Ÿæˆæ•°æ®ï¼ˆæ–‡æ¡£IV.DèŠ‚ï¼š5æ¬¡æ¸¸æˆâ†’1876ç»„æ•°æ®ï¼ŒOrnstein-Uhlenbeckå™ªå£°ï¼‰
    print("="*50 + " æ­¥éª¤1/3ï¼šç”Ÿæˆæœˆçƒç€é™†å™¨æ•°æ® " + "="*50)
    if args.data_prepared:
        # å¦‚æœæ•°æ®å·²å‡†å¤‡å¥½ï¼Œç›´æ¥åŠ è½½ï¼ˆé¿å…é‡å¤ç”Ÿæˆï¼‰
        data = np.load(f"./data/lunar_lander_ksteps_seed{args.seed}_ep{args.data_epochs}_K{args.K_steps}.npz")
        x_prev = data['x_seq']
        u_prev = data['u_seq']
        x_next = data['x_next_seq']
        print(f"å·²åŠ è½½é¢„ç”Ÿæˆæ•°æ®ï¼š{x_prev.shape[0]}ç»„æ•°æ®")
    else:
        x_prev, u_prev, x_next = generate_lunar_lander_data_ksteps(
            num_episodes=args.data_epochs,  # æ–‡æ¡£æŒ‡å®š5æ¬¡ï¼Œå¯¹åº”1876ç»„æ•°æ®
            noise_scale=0.1,  # æ–‡æ¡£IV.DèŠ‚æŒ‡å®šå™ªå£°å¼ºåº¦
            K_steps=args.K_steps,
            seed=args.seed,
            window_step=1
        )

    print("\n" + "="*50 + " æ­¥éª¤2/3ï¼šè®­ç»ƒPsiMLPç½‘ç»œ " + "="*50)
    x_prev = torch.tensor(x_prev, dtype=torch.float32, device=device)
    u_prev = torch.tensor(u_prev, dtype=torch.float32, device=device)
    # æ­¥éª¤2ï¼šè®­ç»ƒPsiMLPç½‘ç»œï¼ˆæ–‡æ¡£II.28èŠ‚+Algorithm 1ï¼‰
    psi_lander = train_mc_dkn(
        X_train=x_prev,
        U_train=u_prev,
        batch_size=args.batch_size,
        epochs_stage1=args.epochs_stage1,
        epochs_stage2=args.epochs_stage2,
        lr=args.lr,
        neighbors=args.neighbors
    )
    # ä¿å­˜A/B/CçŸ©é˜µï¼ˆä¾¿äºåç»­åˆ†æï¼‰
    # np.savez(f"./data/lunar_lander_ABC_{args.test_version}_seed{args.seed}.npz", A=A_lander.cpu().numpy(), B=B_lander.cpu().numpy(), C=C_lander.cpu().numpy())
    # æ­¥éª¤3ï¼šLQRæ§åˆ¶æµ‹è¯•ï¼ˆæ–‡æ¡£IIIèŠ‚+IV.DèŠ‚ï¼Œç”¨è®­ç»ƒåçš„A/Bè®¡ç®—LQRå¢ç›Šï¼‰
    print("\n" + "="*50 + " æ­¥éª¤3/3ï¼šLQRæ§åˆ¶æµ‹è¯• " + "="*50)
    # ç›®æ ‡çŠ¶æ€x*ï¼šæ–‡æ¡£IV.DèŠ‚å®šä¹‰ï¼ˆx=0, y=0ï¼Œå…¶ä½™ä¸º0ï¼‰
    x_star_lander = torch.tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], device=next(psi_lander.parameters()).device)
    A_lander, B_lander, Q_, R_ = calculate_parameter(psi_lander, args.x_dim, args.z_dim, args.control_dim)
    K_lqr = solve_discrete_lqr(A_lander, B_lander)
    test_lander_lqr(psi_lander, K_lqr, x_star_lander, num_episodes=args.num_episodes, version=args.test_version, seed=args.seed)