import torch
import gym
import torch.optim as optim
import numpy as np
import tqdm
import math
import matplotlib.pyplot as plt
from typing import Tuple, List
from torch.utils.data import TensorDataset, DataLoader
from rdkrc.utils.data_utils import generate_lunar_lander_data
from rdkrc.models.psi_mlp import PsiMLP
from rdkrc.trainer.loss_functions import compute_total_loss
from rdkrc.utils.matrix_utils import compute_C_matrix, update_A_B
from rdkrc.controller.lqr_controller import solve_discrete_lqr


import torch
import gym
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Tuple
from rdkrc.models.psi_mlp import PsiMLP


def test_lander_lqr(
    psi: PsiMLP,
    K_lqr: np.ndarray,
    x_star: torch.Tensor,
    num_episodes: int = 10,
    max_steps: int = 500
) -> List[float]:
    """
    æœˆçƒç€é™†å™¨LQRæ§åˆ¶æµ‹è¯•ï¼ˆä»…ç”Ÿæˆè½¨è¿¹æ±‡æ€»å›¾ï¼‰
    ä¾æ®æ–‡æ¡£IV.DèŠ‚ï¼šé€šè¿‡10æ¬¡ç‹¬ç«‹æµ‹è¯•è®°å½•è½¨è¿¹ï¼Œæ±‡æ€»å±•ç¤ºå¤šå›åˆè·¯å¾„æ”¶æ•›æ€§ï¼ŒéªŒè¯DKRCé²æ£’æ€§ï¼ˆğŸ”¶1-83ã€ğŸ”¶1-87ï¼‰ã€‚
    
    Args:
        psi: è®­ç»ƒå¥½çš„PsiMLPç½‘ç»œï¼ˆå«uâ‚€å‚æ•°ï¼Œæ–‡æ¡£II.36èŠ‚ï¼‰
        K_lqr: LQRæ§åˆ¶å¢ç›Šï¼Œshape=[2, 256]ï¼ˆæ–‡æ¡£IIIèŠ‚ç¦»æ•£LQRæ±‚è§£ï¼‰
        x_star: ç›®æ ‡çŠ¶æ€ï¼ˆç€é™†åŒºï¼Œæ–‡æ¡£IV.DèŠ‚å®šä¹‰ï¼šxã€yå¯¹åº”ç€é™†ä½ç½®ï¼‰ï¼Œshape=[6]
        num_episodes: æµ‹è¯•å›åˆæ•°ï¼ˆæ–‡æ¡£æŒ‡å®š10æ¬¡ï¼Œç¡®ä¿ç»Ÿè®¡é²æ£’æ€§ï¼‰
        max_steps: æ¯å›åˆæœ€å¤§æ­¥æ•°ï¼ˆé¿å…æ— é™å¾ªç¯ï¼Œæ–‡æ¡£æœªæŒ‡å®šæ—¶é»˜è®¤500ï¼‰
    Returns:
        episode_scores: æ¯å›åˆå¾—åˆ†åˆ—è¡¨ï¼ˆGymå†…ç½®å¾—åˆ†ï¼Œ>200ä¸ºæˆåŠŸç€é™†ï¼Œæ–‡æ¡£IV.DèŠ‚è¯„ä¼°æ ‡å‡†ï¼‰
    """
    env = gym.make("LunarLanderContinuous-v2")
    device = next(psi.parameters()).device
    episode_scores: List[float] = []
    all_trajectories: List[List[Tuple[float, float]]] = []  # å­˜å‚¨æ‰€æœ‰episodeçš„x-yè½¨è¿¹ï¼ˆæ–‡æ¡£æ ¸å¿ƒä½ç½®ç»´åº¦ï¼‰

    psi.eval()  # æ¨ç†æ¨¡å¼ï¼ˆç¦ç”¨æ¢¯åº¦ï¼Œæ–‡æ¡£æµ‹è¯•é˜¶æ®µè¦æ±‚ï¼‰
    with torch.no_grad():
        for ep in range(num_episodes):
            # åˆå§‹åŒ–ç¯å¢ƒï¼ˆæ–‡æ¡£IV.DèŠ‚ï¼šéšæœºåˆå§‹æ‰°åŠ¨ï¼‰
            x_prev  = env.reset() 
            x_prev = x_prev[0:6]     # å–æ–‡æ¡£å®šä¹‰çš„6ç»´çŠ¶æ€ï¼ˆx,y,Î¸,áº‹,áº,Î¸Ì‡ï¼‰ï¼Œä»…x-yç”¨äºè½¨è¿¹ç»˜åˆ¶
            done = False
            total_score = 0.0
            step = 0
            trajectory = []  # è®°å½•å½“å‰episodeçš„x-yåæ ‡ï¼ˆæ–‡æ¡£å›¾8æ ¸å¿ƒç»´åº¦ï¼‰

            while not done and step < max_steps:
                # è®°å½•å½“å‰ä½ç½®ï¼ˆä»…ä¿ç•™æ–‡æ¡£å…³æ³¨çš„x-yç»´åº¦ï¼ŒğŸ”¶1-80ã€ğŸ”¶1-87ï¼‰
                trajectory.append((x_prev[0], x_prev[1]))

                # 1. è®¡ç®—é«˜ç»´çº¿æ€§çŠ¶æ€zï¼ˆæ–‡æ¡£Equation 4ï¼šz=Î¨(x)-Î¨(x*)ï¼‰
                x_prev_tensor = torch.tensor(x_prev, device=device, dtype=torch.float32).unsqueeze(0)
                z_prev = psi.compute_z(x_prev_tensor, x_star)
                z_prev_np = z_prev.cpu().detach().numpy()

                # 2. è®¡ç®—LQRæ§åˆ¶è¾“å…¥ï¼ˆæ–‡æ¡£IIIèŠ‚ï¼šv_t=-K_lqr z_tï¼Œu_t=v_t+uâ‚€ï¼‰
                v_t = -K_lqr @ z_prev_np.T  # å˜æ¢åæ§åˆ¶è¾“å…¥
                u0 = psi.forward_u0(x_prev_tensor).cpu().detach().numpy().squeeze()  # æ–‡æ¡£II.36èŠ‚uâ‚€è¡¥å¿
                u_t = v_t.squeeze() + u0
                u_t = np.clip(u_t, env.action_space.low, env.action_space.high)  # æ–‡æ¡£éšå«æ§åˆ¶çº¦æŸ

                # 3. ç¯å¢ƒäº¤äº’ï¼ˆæ–‡æ¡£IV.DèŠ‚ï¼šè·å–ä¸‹ä¸€çŠ¶æ€ä¸å¥–åŠ±ï¼‰
                x_next, reward, done, _  = env.step(u_t)
                total_score += reward
                x_prev = x_next[0:6]
                step += 1
            print("æœ€ç»ˆçŠ¶æ€:", x_prev)
            # è®°å½•æœ€ç»ˆä½ç½®ï¼ˆç¡®ä¿è½¨è¿¹å®Œæ•´è¦†ç›–â€œåˆå§‹â†’ç›®æ ‡â€è¿‡ç¨‹ï¼ŒğŸ”¶1-87ï¼‰
            trajectory.append((x_prev[0], x_prev[1]))
            all_trajectories.append(trajectory)  # æ”¶é›†å½“å‰episodeè½¨è¿¹
            episode_scores.append(total_score)
            print(f"æµ‹è¯•å›åˆ {ep+1:2d}/{num_episodes} | å¾—åˆ†ï¼š{total_score:5.1f} | æ­¥æ•°ï¼š{step:3d}")

    env.close()
    x_star = x_star.cpu().numpy()
    # -------- ç»˜åˆ¶è½¨è¿¹æ±‡æ€»å›¾ï¼ˆä¸¥æ ¼å¯¹é½æ–‡æ¡£å›¾8ï¼ŒğŸ”¶1-87ï¼‰ --------
    plt.figure(figsize=(10, 8))
    colors = plt.cm.tab10.colors  # å¤šè½¨è¿¹é¢œè‰²åŒºåˆ†ï¼ˆé¿å…é‡å é®æŒ¡ï¼Œæ–‡æ¡£å›¾8é£æ ¼ï¼‰
    # ç”»å‡ºx_starä½ç½®
    plt.scatter(x_star[0], x_star[1], color="red", marker="x", s=50, edgecolor="black", label="Start")
    for ep, trajectory in enumerate(all_trajectories):
        # æå–x-yåæ ‡ï¼ˆæ–‡æ¡£æ ¸å¿ƒä½ç½®ç»´åº¦ï¼‰
        x_coords = [p[0] for p in trajectory]
        y_coords = [p[1] for p in trajectory]
        color = colors[ep % len(colors)]  # å¾ªç¯åˆ†é…é¢œè‰²ï¼Œé€‚é…10æ¬¡å›åˆ
        # ç»˜åˆ¶è½¨è¿¹çº¿ï¼ˆæ–‡æ¡£å›¾8ï¼šä½é€æ˜åº¦å±•ç¤ºå¤šè½¨è¿¹åˆ†å¸ƒï¼‰
        plt.plot(x_coords, y_coords, color=color, alpha=0.7)

    # æ ‡æ³¨ç€é™†åŒºï¼ˆæ–‡æ¡£IV.DèŠ‚ï¼šç€é™†å¹³å°ä½ç½®ï¼Œyå¯¹åº”ç›®æ ‡é«˜åº¦ï¼‰
    plt.axhline(y=0, color="black", linestyle="--", alpha=0.8, label="Landing Pad")
    # åæ ‡è½´è®¾ç½®ï¼ˆåŒ¹é…æ–‡æ¡£çŠ¶æ€ç©ºé—´ï¼šxâˆˆ[-1.5,1.5]ï¼Œyâˆˆ[0,1.5]ï¼ŒğŸ”¶1-80ï¼‰
    plt.xlim(-1.5, 1.5)
    plt.ylim(0, 1.5)
    # æ ‡ç­¾ä¸æ ‡é¢˜ï¼ˆæ–‡æ¡£å›¾8è§„èŒƒï¼šæ˜ç¡®ä½ç½®ç»´åº¦ä¸å®éªŒå¯¹è±¡ï¼‰
    plt.xlabel("X Position (Horizontal)", fontsize=12)
    plt.ylabel("Y Position (Altitude)", fontsize=12)
    plt.title("Lunar Lander Trajectory Summary (DKRC + LQR)", fontsize=14)
    # å›¾ä¾‹ï¼ˆé¿å…é®æŒ¡è½¨è¿¹ï¼Œæ–‡æ¡£å›¾8å³ä¾§å¸ƒå±€ï¼‰
    plt.legend(loc="upper right", bbox_to_anchor=(1.25, 1), fontsize=10)
    plt.grid(True, alpha=0.5)
    # ä¿å­˜æ±‡æ€»å›¾ï¼ˆç¡®ä¿å®Œæ•´æ˜¾ç¤ºå›¾ä¾‹ï¼Œæ–‡æ¡£å®éªŒç»“æœä¿å­˜è¦æ±‚ï¼‰
    plt.savefig("lunar_lander_trajectory_summary.png", bbox_inches="tight", dpi=300)
    plt.close()

    # æµ‹è¯•ç»“æœç»Ÿè®¡ï¼ˆæ–‡æ¡£IV.DèŠ‚è¯„ä¼°æ ‡å‡†ï¼šå¹³å‡å¾—åˆ†ã€æˆåŠŸç€é™†æ¬¡æ•°ï¼‰
    avg_score = np.mean(episode_scores)
    std_score = np.std(episode_scores)
    success_count = sum(score > 200 for score in episode_scores)
    print(f"\næµ‹è¯•æ€»ç»“ï¼šå¹³å‡å¾—åˆ† {avg_score:.1f}Â±{std_score:.1f} | æˆåŠŸç€é™† {success_count}/{num_episodes} æ¬¡")
    return episode_scores


def train_psi_lander(
    x_prev: np.ndarray,
    u_prev: np.ndarray,
    x_next: np.ndarray,
    epochs: int = 500,
    batch_size: int = 128,
    lr: float = 1e-4
) -> Tuple[PsiMLP, torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    è®­ç»ƒæœˆçƒç€é™†å™¨çš„PsiMLPç½‘ç»œï¼ˆæ–‡æ¡£Algorithm 1å®Œæ•´æµç¨‹ï¼‰
    æ ¸å¿ƒä¿®æ­£ï¼šè¡¥å……\(u_0\)è°ƒç”¨ã€çº æ­£A/Båˆå§‹åŒ–ã€ç”¨å…¨éƒ¨æ•°æ®è®¡ç®—æœ€ç»ˆA/B/Cã€é€‚é…DataLoaderæ‰¹é‡é€»è¾‘ã€‚
    
    Args:
        x_prev: åŸå§‹çŠ¶æ€åºåˆ—ï¼Œshape=[total_samples,6]ï¼ˆæ–‡æ¡£IV.DèŠ‚æ•°æ®æ ¼å¼ï¼‰
        u_prev: æ§åˆ¶è¾“å…¥åºåˆ—ï¼Œshape=[total_samples,2]ï¼ˆæ–‡æ¡£IV.DèŠ‚æ§åˆ¶ç»´åº¦ï¼‰
        x_next: ä¸‹ä¸€çŠ¶æ€åºåˆ—ï¼Œshape=[total_samples,6]
        epochs: è®­ç»ƒè½®æ¬¡ï¼ˆæ–‡æ¡£II.28èŠ‚æœªæŒ‡å®šï¼Œé»˜è®¤500ï¼‰
        batch_size: æ‰¹é‡å¤§å°ï¼ˆæ–‡æ¡£II.27èŠ‚æ‰¹é‡è®­ç»ƒé€»è¾‘ï¼Œé»˜è®¤128ï¼‰
        lr: å­¦ä¹ ç‡ï¼ˆæ–‡æ¡£II.28èŠ‚ç”¨ADAMä¼˜åŒ–å™¨ï¼Œé»˜è®¤1e-4ï¼‰
    Returns:
        psi: è®­ç»ƒå¥½çš„PsiMLPç½‘ç»œï¼ˆå«\(u_0\)ï¼‰
        A_final: æ”¶æ•›åçš„KoopmançŸ©é˜µï¼Œshape=[256,256]ï¼ˆæ–‡æ¡£Equation 5ï¼‰
        B_final: æ”¶æ•›åçš„æ§åˆ¶çŸ©é˜µï¼Œshape=[256,2]ï¼ˆæ–‡æ¡£Equation 5ï¼‰
        C_final: çŠ¶æ€é‡æ„çŸ©é˜µï¼Œshape=[6,256]ï¼ˆæ–‡æ¡£Equation 9ï¼‰
    """
    # 1. è®¾å¤‡ä¸ç¯å¢ƒå‚æ•°åˆå§‹åŒ–ï¼ˆæ–‡æ¡£II.28èŠ‚æ¨èGPUï¼Œè·å–çŠ¶æ€ä¸Šä¸‹ç•Œï¼‰
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    env = gym.make("LunarLanderContinuous-v2")
    state_low = [-1.5, 0, -5, -5, -math.pi, -8]
    state_high = [1.5, 1.5, 5, 5, math.pi, 8]
    env.close()
    print(f"ä½¿ç”¨è®¾å¤‡ï¼š{device}ï¼ˆæ–‡æ¡£II.28èŠ‚æ¨èNVIDIA GPUï¼‰")

    # 2. æ•°æ®è½¬æ¢ä¸æ‰¹é‡åŠ è½½ï¼ˆæ–‡æ¡£II.27èŠ‚æ•°æ®é¢„å¤„ç†é€»è¾‘ï¼‰
    x_prev_tensor = torch.tensor(x_prev, device=device, dtype=torch.float32)
    u_prev_tensor = torch.tensor(u_prev, device=device, dtype=torch.float32)
    x_next_tensor = torch.tensor(x_next, device=device, dtype=torch.float32)
    # ç”¨DataLoaderå®ç°æ‰¹é‡é‡‡æ ·ï¼ˆæ‰“ä¹±+åˆ†æ‰¹ï¼Œé¿å…æ‰‹åŠ¨åˆ‡ç‰‡è¯¯å·®ï¼‰
    dataset = TensorDataset(x_prev_tensor, u_prev_tensor, x_next_tensor)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)

    # 3. æ ¸å¿ƒæ¨¡å—åˆå§‹åŒ–ï¼ˆä¸¥æ ¼åŒ¹é…æ–‡æ¡£å®šä¹‰ï¼‰
    # 3.1 PsiMLPï¼šè¾“å…¥6ç»´ï¼Œè¾“å‡º256ç»´ï¼ˆNâ‰«6ï¼‰ï¼Œæ§åˆ¶ç»´åº¦2ï¼Œä¼ å…¥çŠ¶æ€ä¸Šä¸‹ç•Œ
    psi = PsiMLP(
        input_dim=6,
        output_dim=256,
        control_dim=2,
        low=state_low,
        high=state_high,
        hidden_dims=[256, 256, 256, 256]  # æ–‡æ¡£II.28èŠ‚4å±‚éšè—å±‚
    ).to(device)
    # 3.2 ä¼˜åŒ–å™¨ï¼šADAMï¼ˆæ–‡æ¡£II.28èŠ‚æŒ‡å®šï¼‰
    optimizer = optim.Adam(psi.parameters(), lr=lr)
    # 3.3 ç›®æ ‡çŠ¶æ€x*ï¼šæ–‡æ¡£IV.DèŠ‚å®šä¹‰ä¸ºç€é™†åŒºï¼ˆx=10, y=4ï¼Œå…¶ä½™çŠ¶æ€ä¸º0ï¼‰
    x_star = torch.tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], device=device, dtype=torch.float32)
    # 3.4 A/Båˆå§‹åŒ–ï¼šéšæœºæ­£æ€åˆ†å¸ƒï¼ˆæ–‡æ¡£II.39èŠ‚â€œéšæœºåˆå§‹åŒ–A/Bâ€ï¼‰ï¼Œé¿å…å¯¹è§’çŸ©é˜µåç½®
    N = 256  # é«˜ç»´ç©ºé—´ç»´åº¦
    A = torch.randn(N, N, device=device)
    B = torch.randn(N, 2, device=device)
    # åˆå§‹åŒ–å½’ä¸€åŒ–ï¼ˆé¿å…æ•°å€¼æº¢å‡ºï¼Œæ–‡æ¡£æœªæ˜è¯´ä½†ä¸ºè®­ç»ƒç¨³å®šæ€§å¿…éœ€ï¼‰
    A = A / torch.norm(A, dim=0, keepdim=True)
    B = B / torch.norm(B, dim=0, keepdim=True)
    avg_loss_list: List[float] = []
    # 4. è®­ç»ƒå¾ªç¯ï¼ˆæ–‡æ¡£Algorithm 1æ­¥éª¤1-4ï¼‰
    psi.train()
    for epoch in range(epochs):
        total_epoch_loss = 0.0
        for batch in dataloader:
            x_prev_batch, u_prev_batch, x_next_batch = batch  # [B,6], [B,2], [B,6]
            
            # 4.1 è®¡ç®—é«˜ç»´çº¿æ€§çŠ¶æ€zï¼ˆæ–‡æ¡£Algorithm 1æ­¥éª¤1ï¼šz = Î¨(x) - Î¨(x*)ï¼‰
            z_prev_batch = psi.compute_z(x_prev_batch, x_star)  # [B,256]
            z_next_batch = psi.compute_z(x_next_batch, x_star)  # [B,256]
            
            # 4.2 è·å–æ§åˆ¶å›ºå®šç‚¹u0ï¼ˆæ–‡æ¡£II.36èŠ‚â€œè¾…åŠ©ç½‘ç»œå­¦ä¹ u0â€ï¼ŒåŒ¹é…æ‰¹é‡å¤§å°ï¼‰
            u0_batch = psi.forward_u0(x_prev_batch)  # [B,2]
            
            # 4.3 æ›´æ–°A/BçŸ©é˜µï¼ˆæ–‡æ¡£Algorithm 1éšå«æ­¥éª¤ï¼Œè°ƒç”¨matrix_utilsï¼‰
            A, B = update_A_B(z_prev_batch, z_next_batch, u_prev_batch, A, B)
            
            # 4.4 è®¡ç®—æ€»æŸå¤±ï¼ˆæ–‡æ¡£Algorithm 1æ­¥éª¤4ï¼šL(Î¸) = L1 + L2ï¼ŒåŠ å…¥u_prevå’Œu0ï¼‰
            total_loss, L1, L2 = compute_total_loss(
                z_prev=z_prev_batch,
                z_next=z_next_batch,
                A=A,
                B=B,
                u_prev=u_prev_batch,
                u0=u0_batch,
                lambda_L1=0.999,
                lambda_L2=0.001  
            )
            
            # 4.5 åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°
            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()
            
            total_epoch_loss += total_loss.item() * batch_size  # ç´¯ç§¯ epoch æŸå¤±
        # æ¯è¿‡20ä¸ªepoché™ä½ä¸€æ¬¡å­¦ä¹ ç‡
        if (epoch + 1) % 50 == 0:
            for param_group in optimizer.param_groups:
                param_group['lr'] *= 0.5
        # æ‰“å°epochä¿¡æ¯ï¼ˆå¹³å‡æŸå¤±ï¼Œä¾¿äºç›‘æ§æ”¶æ•›ï¼‰
        avg_epoch_loss = total_epoch_loss / len(dataset)
        avg_loss_list.append(avg_epoch_loss)
        print(f"Epoch [{epoch+1:3d}/{epochs}] | å¹³å‡æ€»æŸå¤±ï¼š{avg_epoch_loss:.4f} | L1ï¼š{L1.item():.4f} | L2ï¼š{L2.item():.4f}", end='\r', flush=True)
    plot_loss_curve(avg_loss_list)
    # 5. è®¡ç®—æœ€ç»ˆA/B/CçŸ©é˜µï¼ˆæ–‡æ¡£Algorithm 1æ­¥éª¤5ï¼Œç”¨å…¨éƒ¨æ•°æ®ç¡®ä¿æ”¶æ•›ç²¾åº¦ï¼‰
    psi.eval()
    with torch.no_grad():
        # 5.1 è®¡ç®—å…¨éƒ¨æ•°æ®çš„zï¼ˆç”¨äºA/B/Cè®¡ç®—ï¼‰
        z_prev_all = psi.compute_z(x_prev_tensor, x_star)  # [total,256]
        z_next_all = psi.compute_z(x_next_tensor, x_star)  # [total,256]
        # 5.2 æœ€ç»ˆA/Bï¼šç”¨å…¨éƒ¨æ•°æ®æ›´æ–°ä¸€æ¬¡ï¼ˆé¿å…æ‰¹é‡åå·®ï¼‰
        A_final, B_final = update_A_B(z_prev_all, z_next_all, u_prev_tensor, A, B)
        # 5.3 æœ€ç»ˆCï¼šæ–‡æ¡£Equation 9ï¼Œè¾“å…¥z_prevï¼ˆè€ŒéÎ¨(x)ï¼‰ï¼Œæ»¡è¶³CÎ¨0=0çº¦æŸ
        C_final = compute_C_matrix(x_prev_tensor, z_prev_all)  # [6,256]

    print(f"\nPsiMLPè®­ç»ƒå®Œæˆ | A_final.shape: {A_final.shape} | B_final.shape: {B_final.shape} | C_final.shape: {C_final.shape}")
    return psi, A_final, B_final, C_final

def plot_loss_curve(loss_list: List[float]) -> None:
    """
    ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿ï¼ˆä¾¿äºç›‘æ§è®­ç»ƒè¿‡ç¨‹ï¼‰
    
    Args:
        loss_list: æ¯ä¸ªepochçš„å¹³å‡æŸå¤±åˆ—è¡¨
    """
    plt.figure(figsize=(10, 6))
    plt.plot(loss_list, label='Average Loss per Epoch')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training Loss Curve')
    plt.yscale('log')  # å¯¹æ•°åˆ»åº¦ä¾¿äºè§‚å¯Ÿæ”¶æ•›è¶‹åŠ¿
    plt.grid(True)
    plt.legend()
    plt.savefig('training_loss_curve.png')

if __name__ == "__main__":
    # å®Œæ•´DKRCæµç¨‹ï¼ˆæ–‡æ¡£IV.DèŠ‚å®éªŒæ­¥éª¤ï¼šæ•°æ®ç”Ÿæˆâ†’ç½‘ç»œè®­ç»ƒâ†’æ§åˆ¶æµ‹è¯•ï¼‰
    # æ­¥éª¤1ï¼šç”Ÿæˆæ•°æ®ï¼ˆæ–‡æ¡£IV.DèŠ‚ï¼š5æ¬¡æ¸¸æˆâ†’1876ç»„æ•°æ®ï¼ŒOrnstein-Uhlenbeckå™ªå£°ï¼‰
    print("="*50 + " æ­¥éª¤1/3ï¼šç”Ÿæˆæœˆçƒç€é™†å™¨æ•°æ®ï¼ˆæ–‡æ¡£IV.DèŠ‚ï¼‰ " + "="*50)
    x_prev, u_prev, x_next = generate_lunar_lander_data(
        num_episodes=10,  # æ–‡æ¡£æŒ‡å®š5æ¬¡ï¼Œå¯¹åº”1876ç»„æ•°æ®
        noise_scale=0.1  # æ–‡æ¡£IV.DèŠ‚æŒ‡å®šå™ªå£°å¼ºåº¦
    )
     
    # æ­¥éª¤2ï¼šè®­ç»ƒPsiMLPç½‘ç»œï¼ˆæ–‡æ¡£II.28èŠ‚+Algorithm 1ï¼‰
    print("\n" + "="*50 + " æ­¥éª¤2/3ï¼šè®­ç»ƒPsiMLPç½‘ç»œï¼ˆæ–‡æ¡£Algorithm 1ï¼‰ " + "="*50)
    psi_lander, A_lander, B_lander, C_lander = train_psi_lander(
        x_prev=x_prev,
        u_prev=u_prev,
        x_next=x_next,
        epochs=50,  # è¶³å¤Ÿè½®æ¬¡ç¡®ä¿æ”¶æ•›
        batch_size=256,
        lr=1e-5
    )

    # æ­¥éª¤3ï¼šLQRæ§åˆ¶æµ‹è¯•ï¼ˆæ–‡æ¡£IIIèŠ‚+IV.DèŠ‚ï¼Œç”¨è®­ç»ƒåçš„A/Bè®¡ç®—LQRå¢ç›Šï¼‰
    print("\n" + "="*50 + " æ­¥éª¤3/3ï¼šLQRæ§åˆ¶æµ‹è¯•ï¼ˆæ–‡æ¡£IIIèŠ‚ï¼‰ " + "="*50)
    # ç›®æ ‡çŠ¶æ€x*ï¼šæ–‡æ¡£IV.DèŠ‚å®šä¹‰ï¼ˆx=0, y=0ï¼Œå…¶ä½™ä¸º0ï¼‰
    x_star_lander = torch.tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], device=next(psi_lander.parameters()).device)
    # æ±‚è§£LQRå¢ç›Šï¼ˆæ–‡æ¡£IIIèŠ‚ç¦»æ•£é»å¡ææ–¹ç¨‹ï¼‰
    K_lqr = solve_discrete_lqr(A_lander, B_lander)
    # æµ‹è¯•æ§åˆ¶æ•ˆæœï¼ˆæ–‡æ¡£IV.DèŠ‚10æ¬¡æµ‹è¯•ï¼‰
    test_lander_lqr(psi_lander, K_lqr, x_star_lander, num_episodes=10)