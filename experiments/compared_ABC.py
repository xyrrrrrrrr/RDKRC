import numpy as np
import torch
import argparse
import matplotlib.pyplot as plt
from typing import Dict, Tuple, Optional
import warnings
warnings.filterwarnings("ignore")  # å¿½ç•¥æ•°å€¼è®¡ç®—ä¸­çš„è­¦å‘Š


def load_abc_matrix(version: str, seed: int = 50, data_dir: str = ".") -> Dict[str, np.ndarray]:
    """
    è¯»å–æŒ‡å®šç‰ˆæœ¬å’Œç§å­çš„ Aã€Bã€C çŸ©é˜µï¼ˆé€‚é…ç”¨æˆ·çš„ npz æ–‡ä»¶åæ ¼å¼ï¼‰
    
    Args:
        version: æ¨¡å‹ç‰ˆæœ¬ï¼ˆå¦‚ "v1"ã€"v2"ï¼‰
        seed: éšæœºç§å­ï¼ˆä¸ä¿å­˜æ—¶ä¸€è‡´ï¼Œé»˜è®¤2ï¼‰
        data_dir: æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰
    
    Returns:
        abc_dict: åŒ…å« Aã€Bã€C çŸ©é˜µçš„å­—å…¸
    """
    # åŒ¹é…ç”¨æˆ·çš„æ–‡ä»¶å‘½åæ ¼å¼ï¼šlunar_lander_ABC_{version}_seed{seed}.npz
    file_path = f"{data_dir}/lunar_lander_ABC_{version}_seed{seed}.npz"
    try:
        data = np.load(file_path)
        # éªŒè¯çŸ©é˜µç»´åº¦ï¼ˆç¡®ä¿ç¬¦åˆ DKRC å®šä¹‰ï¼šA[NÃ—N], B[NÃ—m], C[nÃ—N]ï¼‰
        A = data["A"]
        B = data["B"]
        C = data["C"]
        assert A.ndim == 2 and A.shape[0] == A.shape[1], f"AçŸ©é˜µéœ€ä¸ºæ–¹é˜µï¼Œå½“å‰å½¢çŠ¶{A.shape}"
        assert B.ndim == 2 and B.shape[0] == A.shape[0], f"BçŸ©é˜µè¡Œæ•°éœ€ä¸Aä¸€è‡´ï¼Œå½“å‰B.shape{B.shape}"
        assert C.ndim == 2 and C.shape[1] == A.shape[0], f"CçŸ©é˜µåˆ—æ•°éœ€ä¸Aä¸€è‡´ï¼Œå½“å‰C.shape{C.shape}"
        print(f"æˆåŠŸè¯»å– {version} ç‰ˆæœ¬ï¼ˆseed={seed}ï¼‰ï¼šA[{A.shape[0]}Ã—{A.shape[1]}], B[{B.shape[0]}Ã—{B.shape[1]}], C[{C.shape[0]}Ã—{C.shape[1]}]")
        return {"A": A, "B": B, "C": C}
    except FileNotFoundError:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ–‡ä»¶ï¼š{file_path}ï¼Œè¯·æ£€æŸ¥ç‰ˆæœ¬å’Œç§å­æ˜¯å¦æ­£ç¡®")
    except KeyError as e:
        raise KeyError(f"æ–‡ä»¶ä¸­ç¼ºå°‘çŸ©é˜µï¼š{e}ï¼Œè¯·ç¡®è®¤ä¿å­˜æ—¶çš„é”®ä¸º'A'ã€'B'ã€'C'")


def compute_abc_metrics(abc_dict: Dict[str, np.ndarray], psi: Optional["PsiMLP"] = None, x_star: Optional[np.ndarray] = None) -> Dict[str, float]:
    """
    è®¡ç®— Aã€Bã€C çŸ©é˜µçš„å…³é”®æŒ‡æ ‡ï¼ˆåŸºäºæ–‡æ¡£æ ¸å¿ƒè¦æ±‚ï¼‰
    
    Args:
        abc_dict: åŒ…å« Aã€Bã€C çš„å­—å…¸
        psi: å¯é€‰ï¼ŒPsiMLP ç½‘ç»œï¼ˆç”¨äºè®¡ç®— C çŸ©é˜µçš„çŠ¶æ€é‡æ„è¯¯å·®ï¼‰
        x_star: å¯é€‰ï¼Œç›®æ ‡åŸçŠ¶æ€ï¼ˆç”¨äºé‡æ„è¯¯å·®è®¡ç®—ï¼Œshape=[n]ï¼‰
    
    Returns:
        metrics: é‡åŒ–æŒ‡æ ‡å­—å…¸
    """
    A = abc_dict["A"]
    B = abc_dict["B"]
    C = abc_dict["C"]
    N = A.shape[0]  # é«˜ç»´ç©ºé—´ç»´åº¦
    m = B.shape[1]  # æ§åˆ¶ç»´åº¦ï¼ˆæœˆçƒç€é™†å™¨ m=2ï¼‰
    n = C.shape[0]  # åŸçŠ¶æ€ç»´åº¦ï¼ˆæœˆçƒç€é™†å™¨ n=6ï¼‰
    
    metrics = {}

    # -------------------------- 1. A çŸ©é˜µæŒ‡æ ‡ï¼ˆç¨³å®šæ€§+æ•°å€¼ç‰¹æ€§ï¼‰ --------------------------
    # 1.1 ç‰¹å¾å€¼æ¨¡é•¿ï¼ˆç¦»æ•£ç³»ç»Ÿç¨³å®šæ€§ï¼šmax_eig_norm < 1 ä¸ºç¨³å®šï¼ŒğŸ”¶1-37ï¼‰
    eig_vals = np.linalg.eigvals(A)
    eig_norms = np.abs(eig_vals)
    metrics["A_max_eig_norm"] = np.max(eig_norms)  # æœ€å¤§ç‰¹å¾å€¼æ¨¡é•¿ï¼ˆè¶Šå°è¶Šç¨³å®šï¼‰
    metrics["A_mean_eig_norm"] = np.mean(eig_norms)  # å¹³å‡ç‰¹å¾å€¼æ¨¡é•¿
    metrics["A_eig_norm_std"] = np.std(eig_norms)    # ç‰¹å¾å€¼æ¨¡é•¿æ ‡å‡†å·®ï¼ˆè¶Šå°è¶Šå‡åŒ€ï¼‰
    
    # 1.2 çŸ©é˜µèŒƒæ•°ï¼ˆæ•°å€¼ç¨³å®šæ€§ï¼šé¿å…è¿‡å¤§å¯¼è‡´æ§åˆ¶éœ‡è¡ï¼‰
    metrics["A_fro_norm"] = np.linalg.norm(A, ord="fro")  # Frobenius èŒƒæ•°
    metrics["A_inf_norm"] = np.linalg.norm(A, ord=np.inf)  # æ— ç©·èŒƒæ•°

    # -------------------------- 2. B çŸ©é˜µæŒ‡æ ‡ï¼ˆèƒ½æ§æ€§+æ§åˆ¶å¼ºåº¦ï¼‰ --------------------------
    # 2.1 èƒ½æ§æ€§çŸ©é˜µç§©ï¼ˆæ»¡ç§©è¯´æ˜ç³»ç»Ÿå®Œå…¨èƒ½æ§ï¼ŒğŸ”¶1-44ï¼‰
    def compute_controllability_matrix(A: np.ndarray, B: np.ndarray) -> np.ndarray:
        """è®¡ç®—èƒ½æ§æ€§çŸ©é˜µï¼š[B, A*B, AÂ²*B, ..., A^(N-1)*B]ï¼ˆæ–‡æ¡£ III èŠ‚ LQR èƒ½æ§æ€§è¦æ±‚ï¼‰"""
        N = A.shape[0]
        ctrl_mat = B
        current = B
        for _ in range(1, N):
            current = A @ current
            ctrl_mat = np.hstack([ctrl_mat, current])
        return ctrl_mat
    
    ctrl_mat = compute_controllability_matrix(A, B)
    metrics["B_ctrl_rank"] = np.linalg.matrix_rank(ctrl_mat)  # èƒ½æ§æ€§çŸ©é˜µç§©ï¼ˆæ»¡ç§©=Nä¸ºä¼˜ï¼‰
    metrics["B_ctrl_rank_ratio"] = metrics["B_ctrl_rank"] / N  # ç§©å æ¯”ï¼ˆè¶Šæ¥è¿‘1è¶Šå¥½ï¼‰
    
    # 2.2 åˆ—èŒƒæ•°ï¼ˆæ§åˆ¶è¾“å…¥å¯¹å„é«˜ç»´çŠ¶æ€çš„å½±å“å¼ºåº¦ï¼‰
    B_col_norms = np.linalg.norm(B, axis=0)  # æ¯åˆ—èŒƒæ•°ï¼ˆå¯¹åº”æ¯ä¸ªæ§åˆ¶è¾“å…¥çš„å½±å“ï¼‰
    metrics["B_mean_col_norm"] = np.mean(B_col_norms)
    metrics["B_max_col_norm"] = np.max(B_col_norms)

    # -------------------------- 3. C çŸ©é˜µæŒ‡æ ‡ï¼ˆçŠ¶æ€é‡æ„ç²¾åº¦ï¼‰ --------------------------
    # 3.1 çŸ©é˜µèŒƒæ•°ï¼ˆæ•°å€¼è§„æ¨¡ï¼‰
    metrics["C_fro_norm"] = np.linalg.norm(C, ord="fro")
    C_row_norms = np.linalg.norm(C, axis=1)  # æ¯è¡ŒèŒƒæ•°ï¼ˆå¯¹åº”åŸçŠ¶æ€å„ç»´åº¦çš„é‡æ„æƒé‡ï¼‰
    metrics["C_mean_row_norm"] = np.mean(C_row_norms)
    
    # 3.2 çŠ¶æ€é‡æ„è¯¯å·®ï¼ˆéœ€ Psi ç½‘ç»œï¼Œå¯é€‰ï¼ŒğŸ”¶1-42 Equation 9ï¼‰
    if psi is not None and x_star is not None:
        # ç”ŸæˆéšæœºåŸçŠ¶æ€æ ·æœ¬ï¼ˆè¦†ç›–æœˆçƒç€é™†å™¨çŠ¶æ€ç©ºé—´ï¼ŒğŸ”¶1-80ï¼‰
        np.random.seed(2)
        x_samples = np.random.uniform(
            low=[-1.5, 0.0, -np.pi, -5.0, -5.0, -8.0],
            high=[1.5, 1.5, np.pi, 5.0, 5.0, 8.0],
            size=(100, n)  # 100ä¸ªæ ·æœ¬ï¼Œç»Ÿè®¡å¹³å‡è¯¯å·®
        )
        recon_errors = []
        psi.eval()
        with torch.no_grad():
            device = next(psi.parameters()).device
            x_star_tensor = torch.tensor(x_star, device=device, dtype=torch.float32).unsqueeze(0)
            for x in x_samples:
                x_tensor = torch.tensor(x, device=device, dtype=torch.float32).unsqueeze(0)
                z = psi.compute_z(x_tensor, x_star_tensor)  # z = Î¨(x) - Î¨(x*)
                z_np = z.cpu().numpy().squeeze()
                # é‡æ„åŸçŠ¶æ€ï¼šx_recon = C @ (z + Î¨(x*))ï¼ˆå›  z = Î¨(x)-Î¨(x*)ï¼Œæ•… Î¨(x) = z + Î¨(x*)ï¼‰
                psi_x_star = psi(x_star_tensor).cpu().numpy().squeeze()
                x_recon = C @ (z_np + psi_x_star)
                # è®¡ç®—é‡æ„è¯¯å·®ï¼ˆL2èŒƒæ•°ï¼‰
                recon_errors.append(np.linalg.norm(x - x_recon, ord=2))
        metrics["C_mean_recon_error"] = np.mean(recon_errors)
        metrics["C_recon_error_std"] = np.std(recon_errors)
    
    return metrics


def plot_abc_comparison(v1_abc: Dict[str, np.ndarray], v2_abc: Dict[str, np.ndarray], v1_metrics: Dict[str, float], v2_metrics: Dict[str, float]):
    """
    å¯è§†åŒ–å¯¹æ¯” v1 å’Œ v2 çš„ Aã€Bã€C çŸ©é˜µå…³é”®æŒ‡æ ‡ï¼ˆè´´åˆæ–‡æ¡£å…³æ³¨é‡ç‚¹ï¼‰
    """
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle("DKRC A/B/C Matrix Comparison (v1 vs v2)", fontsize=16, fontweight="bold")
    colors = ["#1f77b4", "#ff7f0e"]  # v1è“ï¼Œv2æ©™

    # -------------------------- å­å›¾1ï¼šAçŸ©é˜µç‰¹å¾å€¼åˆ†å¸ƒï¼ˆç¨³å®šæ€§æ ¸å¿ƒæŒ‡æ ‡ï¼‰ --------------------------
    ax1 = axes[0, 0]
    # è®¡ç®—ç‰¹å¾å€¼
    v1_eig = np.linalg.eigvals(v1_abc["A"])
    v2_eig = np.linalg.eigvals(v2_abc["A"])
    # ç»˜åˆ¶ç‰¹å¾å€¼æ•£ç‚¹ï¼ˆå®éƒ¨vsè™šéƒ¨ï¼‰
    ax1.scatter(np.real(v1_eig), np.imag(v1_eig), color=colors[0], alpha=0.6, label=f"v1 (max_norm={v1_metrics['A_max_eig_norm']:.3f})")
    ax1.scatter(np.real(v2_eig), np.imag(v2_eig), color=colors[1], alpha=0.6, label=f"v2 (max_norm={v2_metrics['A_max_eig_norm']:.3f})")
    # ç»˜åˆ¶å•ä½åœ†ï¼ˆç¨³å®šæ€§è¾¹ç•Œï¼šç¦»æ•£ç³»ç»Ÿç‰¹å¾å€¼éœ€åœ¨åœ†å†…ï¼‰
    theta = np.linspace(0, 2*np.pi, 100)
    ax1.plot(np.cos(theta), np.sin(theta), "k--", alpha=0.5, label="Unit Circle (Stability Boundary)")
    ax1.set_xlabel("Real Part of Eigenvalue", fontsize=12)
    ax1.set_ylabel("Imaginary Part of Eigenvalue", fontsize=12)
    ax1.set_title("A Matrix Eigenvalue Distribution (Stability)", fontsize=14)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # -------------------------- å­å›¾2ï¼šèƒ½æ§æ€§ä¸ç¨³å®šæ€§æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯” --------------------------
    ax2 = axes[0, 1]
    # é€‰æ‹©å…³é”®æŒ‡æ ‡ï¼ˆç¨³å®šæ€§+èƒ½æ§æ€§ï¼Œæ–‡æ¡£ III èŠ‚é‡ç‚¹ï¼‰
    metrics_names = [
        "A Max Eigen Norm\n(Stability, <1 is better)",
        "A Mean Eigen Norm\n(Uniformity)",
        "B Controllability Rank\n(Ratio, 1 is full rank)",
        "B Mean Column Norm\n(Control Strength)"
    ]
    v1_vals = [
        v1_metrics["A_max_eig_norm"],
        v1_metrics["A_mean_eig_norm"],
        v1_metrics["B_ctrl_rank_ratio"],
        v1_metrics["B_mean_col_norm"]
    ]
    v2_vals = [
        v2_metrics["A_max_eig_norm"],
        v2_metrics["A_mean_eig_norm"],
        v2_metrics["B_ctrl_rank_ratio"],
        v2_metrics["B_mean_col_norm"]
    ]
    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    x = np.arange(len(metrics_names))
    width = 0.35
    ax2.bar(x - width/2, v1_vals, width, color=colors[0], label="v1")
    ax2.bar(x + width/2, v2_vals, width, color=colors[1], label="v2")
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (v1, v2) in enumerate(zip(v1_vals, v2_vals)):
        ax2.text(i - width/2, v1 + 0.01, f"{v1:.3f}", ha="center", fontsize=10)
        ax2.text(i + width/2, v2 + 0.01, f"{v2:.3f}", ha="center", fontsize=10)
    ax2.set_xlabel("Key Metrics", fontsize=12)
    ax2.set_ylabel("Metric Value", fontsize=12)
    ax2.set_title("Core Metrics Comparison (Stability + Controllability)", fontsize=14)
    ax2.set_xticks(x)
    ax2.set_xticklabels(metrics_names, rotation=0, fontsize=10)
    ax2.legend()
    ax2.grid(True, alpha=0.3, axis="y")

    # -------------------------- å­å›¾3ï¼šCçŸ©é˜µçŠ¶æ€é‡æ„è¯¯å·®å¯¹æ¯”ï¼ˆè‹¥æœ‰æ•°æ®ï¼‰ --------------------------
    ax3 = axes[1, 0]
    if "C_mean_recon_error" in v1_metrics and "C_mean_recon_error" in v2_metrics:
        # é‡æ„è¯¯å·®ç®±çº¿å›¾
        recon_data = [
            np.random.normal(v1_metrics["C_mean_recon_error"], v1_metrics["C_recon_error_std"], 100),
            np.random.normal(v2_metrics["C_mean_recon_error"], v2_metrics["C_recon_error_std"], 100)
        ]
        bp = ax3.boxplot(recon_data, labels=["v1", "v2"], patch_artist=True)
        for patch, color in zip(bp["boxes"], colors):
            patch.set_facecolor(color)
            patch.set_alpha(0.6)
        # æ·»åŠ å‡å€¼çº¿
        ax3.axhline(y=v1_metrics["C_mean_recon_error"], color=colors[0], linestyle="--", alpha=0.8, label=f"v1 Mean: {v1_metrics['C_mean_recon_error']:.3f}")
        ax3.axhline(y=v2_metrics["C_mean_recon_error"], color=colors[1], linestyle="--", alpha=0.8, label=f"v2 Mean: {v2_metrics['C_mean_recon_error']:.3f}")
        ax3.set_xlabel("Model Version", fontsize=12)
        ax3.set_ylabel("State Reconstruction Error (L2 Norm)", fontsize=12)
        ax3.set_title("C Matrix State Reconstruction Error", fontsize=14)
        ax3.legend()
        ax3.grid(True, alpha=0.3, axis="y")
    else:
        ax3.text(0.5, 0.5, "Need PsiMLP to Compute Reconstruction Error", ha="center", va="center", transform=ax3.transAxes, fontsize=12)
        ax3.set_xlabel("Model Version", fontsize=12)
        ax3.set_ylabel("Reconstruction Error", fontsize=12)
        ax3.set_title("C Matrix State Reconstruction Error (No Data)", fontsize=14)

    # -------------------------- å­å›¾4ï¼šçŸ©é˜µèŒƒæ•°å¯¹æ¯”ï¼ˆæ•°å€¼ç¨³å®šæ€§ï¼‰ --------------------------
    ax4 = axes[1, 1]
    # çŸ©é˜µèŒƒæ•°æŒ‡æ ‡ï¼ˆFrobenius èŒƒæ•°ï¼Œæ•°å€¼ç¨³å®šæ€§ï¼‰
    norm_names = ["A Norm", "B Norm", "C Norm"]
    v1_norms = [
        v1_metrics["A_fro_norm"],
        np.linalg.norm(v1_abc["B"], ord="fro"),
        v1_metrics["C_fro_norm"]
    ]
    v2_norms = [
        v2_metrics["A_fro_norm"],
        np.linalg.norm(v2_abc["B"], ord="fro"),
        v2_metrics["C_fro_norm"]
    ]
    # ç»˜åˆ¶å †å æŸ±çŠ¶å›¾
    x = np.arange(len(norm_names))
    ax4.bar(x - width/2, v1_norms, width, color=colors[0], label="v1")
    ax4.bar(x + width/2, v2_norms, width, color=colors[1], label="v2")
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (v1, v2) in enumerate(zip(v1_norms, v2_norms)):
        ax4.text(i - width/2, v1 + 0.5, f"{v1:.1f}", ha="center", fontsize=10)
        ax4.text(i + width/2, v2 + 0.5, f"{v2:.1f}", ha="center", fontsize=10)
    ax4.set_xlabel("Matrix Type", fontsize=12)
    ax4.set_ylabel("Frobenius Norm (Numerical Stability)", fontsize=12)
    ax4.set_title("Matrix Norm Comparison (Numerical Scale)", fontsize=14)
    ax4.set_xticks(x)
    ax4.set_xticklabels(norm_names)
    ax4.legend()
    ax4.grid(True, alpha=0.3, axis="y")

    # ä¿å­˜å›¾ç‰‡ï¼ˆç¬¦åˆæ–‡æ¡£å®éªŒç»“æœä¿å­˜è¦æ±‚ï¼ŒğŸ”¶1-87ï¼‰
    plt.tight_layout()
    plt.savefig("lunar_lander_abc_comparison_v1_vs_v2.png", dpi=300, bbox_inches="tight")
    plt.close()
    print("\nA/B/C å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜ä¸ºï¼šlunar_lander_abc_comparison_v1_vs_v2.png")


def main(seed: int = 2, data_dir: str = ".", psi_v1: Optional["PsiMLP"] = None, psi_v2: Optional["PsiMLP"] = None):
    """
    ä¸»å‡½æ•°ï¼šè¯»å– v1/v2 çš„ A/B/Cï¼Œè®¡ç®—æŒ‡æ ‡ï¼Œå¯¹æ¯”å¹¶å¯è§†åŒ–
    """
    # 1. è¯»å– v1 å’Œ v2 çš„ A/B/C çŸ©é˜µ
    v1_abc = load_abc_matrix(version="v1", seed=seed, data_dir=data_dir)
    v2_abc = load_abc_matrix(version="v2", seed=seed, data_dir=data_dir)

    # 2. è®¡ç®—å…³é”®æŒ‡æ ‡ï¼ˆè‹¥æœ‰ Psi ç½‘ç»œï¼Œå¯ä¼ å…¥è®¡ç®—é‡æ„è¯¯å·®ï¼‰
    x_star = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])  # ç›®æ ‡çŠ¶æ€ï¼ˆæ–‡æ¡£ IV.D èŠ‚ï¼‰
    v1_metrics = compute_abc_metrics(v1_abc, psi=psi_v1, x_star=x_star)
    v2_metrics = compute_abc_metrics(v2_abc, psi=psi_v2, x_star=x_star)

    # 3. æ‰“å°é‡åŒ–å¯¹æ¯”ç»“æœï¼ˆè´´åˆæ–‡æ¡£è¯„ä¼°æ¡†æ¶ï¼‰
    print("\n" + "="*80)
    print("DKRC A/B/C Matrix Quantitative Comparison (v1 vs v2)")
    print("="*80)
    # æŒ‰çŸ©é˜µåˆ†ç±»æ‰“å°
    print("\nã€1. A Matrix (Stability)ã€‘")
    print(f"{'Metric':<30} {'v1':<12} {'v2':<12} {'Better Version':<10}")
    print("-"*64)
    metrics_a = [
        ("Max Eigen Norm (<1 is stable)", "A_max_eig_norm"),
        ("Mean Eigen Norm (uniformity)", "A_mean_eig_norm"),
        ("Eigen Norm Std (consistency)", "A_eig_norm_std"),
        ("Frobenius Norm (numerical scale)", "A_fro_norm")
    ]
    for name, key in metrics_a:
        v1_val = v1_metrics[key]
        v2_val = v2_metrics[key]
        better = "v1" if v1_val < v2_val else "v2"
        print(f"{name:<30} {v1_val:<12.4f} {v2_val:<12.4f} {better:<10}")

    print("\nã€2. B Matrix (Controllability)ã€‘")
    print(f"{'Metric':<30} {'v1':<12} {'v2':<12} {'Better Version':<10}")
    print("-"*64)
    metrics_b = [
        ("Controllability Rank (full=N)", "B_ctrl_rank"),
        ("Controllability Rank Ratio (1 is best)", "B_ctrl_rank_ratio"),
        ("Mean Column Norm (control strength)", "B_mean_col_norm"),
        ("Max Column Norm (max control impact)", "B_max_col_norm")
    ]
    for name, key in metrics_b:
        v1_val = v1_metrics[key]
        v2_val = v2_metrics[key]
        better = "v1" if (key == "B_ctrl_rank_ratio" and v1_val > v2_val) else ("v2" if v1_val < v2_val else "v1")
        print(f"{name:<30} {v1_val:<12.4f} {v2_val:<12.4f} {better:<10}")

    if "C_mean_recon_error" in v1_metrics and "C_mean_recon_error" in v2_metrics:
        print("\nã€3. C Matrix (Reconstruction)ã€‘")
        print(f"{'Metric':<30} {'v1':<12} {'v2':<12} {'Better Version':<10}")
        print("-"*64)
        metrics_c = [
            ("Mean Reconstruction Error (accuracy)", "C_mean_recon_error"),
            ("Recon Error Std (consistency)", "C_recon_error_std"),
            ("Mean Row Norm (weight uniformity)", "C_mean_row_norm"),
            ("Frobenius Norm (numerical scale)", "C_fro_norm")
        ]
        for name, key in metrics_c:
            v1_val = v1_metrics[key]
            v2_val = v2_metrics[key]
            better = "v1" if v1_val < v2_val else "v2"
            print(f"{name:<30} {v1_val:<12.4f} {v2_val:<12.4f} {better:<10}")

    # 4. å¯è§†åŒ–å¯¹æ¯”
    plot_abc_comparison(v1_abc, v2_abc, v1_metrics, v2_metrics)

    # 5. æ€»ç»“å…³é”®ç»“è®ºï¼ˆåŸºäºæ–‡æ¡£æ§åˆ¶é€»è¾‘ï¼‰
    print("\n" + "="*80)
    print("Key Conclusion (Based on DKRC Control Logic)")
    print("="*80)
    # ç¨³å®šæ€§ç»“è®º
    if v1_metrics["A_max_eig_norm"] < 1 and v2_metrics["A_max_eig_norm"] >= 1:
        print("âŒ v2 A matrix is UNSTABLE (max eigen norm â‰¥1) â†’ LQR control may oscillate")
    elif v1_metrics["A_max_eig_norm"] >= 1 and v2_metrics["A_max_eig_norm"] < 1:
        print("âœ… v2 A matrix is MORE STABLE (max eigen norm <1) â†’ Better control stability")
    else:
        print(f"âš ï¸ Both A matrices are {'stable' if v1_metrics['A_max_eig_norm'] <1 else 'unstable'} (v1: {v1_metrics['A_max_eig_norm']:.3f}, v2: {v2_metrics['A_max_eig_norm']:.3f})")
    # èƒ½æ§æ€§ç»“è®º
    if v1_metrics["B_ctrl_rank_ratio"] == 1 and v2_metrics["B_ctrl_rank_ratio"] < 1:
        print("âŒ v2 B matrix has INSUFFICIENT CONTROLLABILITY â†’ LQR cannot design effective gain")
    elif v1_metrics["B_ctrl_rank_ratio"] < 1 and v2_metrics["B_ctrl_rank_ratio"] == 1:
        print("âœ… v2 B matrix is FULLY CONTROLLABLE â†’ Better LQR control performance")
    else:
        print(f"âš ï¸ Controllability: v1 ratio={v1_metrics['B_ctrl_rank_ratio']:.3f}, v2 ratio={v2_metrics['B_ctrl_rank_ratio']:.3f} (1.0 is full rank)")
    # é‡æ„ç²¾åº¦ç»“è®ºï¼ˆè‹¥æœ‰æ•°æ®ï¼‰
    if "C_mean_recon_error" in v1_metrics:
        if v2_metrics["C_mean_recon_error"] < v1_metrics["C_mean_recon_error"]:
            print("âœ… v2 C matrix has BETTER RECONSTRUCTION ACCURACY â†’ More accurate state observation")
        else:
            print("âŒ v2 C matrix has WORSE RECONSTRUCTION ACCURACY â†’ Less accurate state observation")


# è°ƒç”¨ç¤ºä¾‹ï¼ˆéœ€æ ¹æ®å®é™…ç¯å¢ƒè°ƒæ•´ï¼‰
if __name__ == "__main__":
    # è‹¥éœ€è¦è®¡ç®— C çŸ©é˜µçš„é‡æ„è¯¯å·®ï¼Œéœ€ä¼ å…¥è®­ç»ƒå¥½çš„ PsiMLP ç½‘ç»œï¼ˆå¯é€‰ï¼‰
    # from rdkrc.models.psi_mlp import PsiMLP
    # psi_v1 = PsiMLP(...)  # åŠ è½½ v1 çš„ Psi ç½‘ç»œ
    # psi_v2 = PsiMLP(...)  # åŠ è½½ v2 çš„ Psi ç½‘ç»œ
    # main(seed=2, data_dir="./abc_files", psi_v1=psi_v1, psi_v2=psi_v2)
    parser = argparse.ArgumentParser(description="Compare DKRC A/B/C Matrices between v1 and v2")
    parser.add_argument("--seed", type=int, default=2, help="Random seed used in training (default: 2)")
    args = parser.parse_args()
    # è‹¥æ—  Psi ç½‘ç»œï¼Œä»…å¯¹æ¯” A/B/C çš„åŸºç¡€æŒ‡æ ‡
    main(seed=args.seed, data_dir=".")  # data_dir ä¸º A/B/C æ–‡ä»¶æ‰€åœ¨ç›®å½•