import numpy as np
import torch
import argparse
import matplotlib.pyplot as plt
from typing import Dict, Tuple, Optional
import warnings
warnings.filterwarnings("ignore")  # å¿½ç•¥æ•°å€¼è®¡ç®—ä¸­çš„è­¦å‘Š


def load_abc_matrix(version: str, seed: int = 50, data_dir: str = "data") -> Dict[str, np.ndarray]:
    """
    è¯»å–æŒ‡å®šç‰ˆæœ¬å’Œç§å­çš„ Aã€Bã€C çŸ©é˜µï¼ˆé€‚é…ç”¨æˆ·çš„ npz æ–‡ä»¶åæ ¼å¼ï¼‰
    
    Args:
        version: æ¨¡å‹ç‰ˆæœ¬ï¼ˆå¦‚ "v1"ã€"v2"ã€"v3"ï¼‰
        seed: éšæœºç§å­ï¼ˆä¸ä¿å­˜æ—¶ä¸€è‡´ï¼Œé»˜è®¤2ï¼‰
        data_dir: æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰
    
    Returns:
        abc_dict: åŒ…å« Aã€Bã€C çŸ©é˜µçš„å­—å…¸
    """
    # åŒ¹é…ç”¨æˆ·çš„æ–‡ä»¶å‘½åæ ¼å¼ï¼šlunar_lander_ABC_{version}_seed{seed}.npz
    file_path = f"{data_dir}/lunar_lander_ABC_{version}_seed{seed}.npz"
    try:
        data = np.load(file_path)
        # éªŒè¯çŸ©é˜µç»´åº¦ï¼ˆç¡®ä¿ç¬¦åˆ DKRC å®šä¹‰ï¼šA[NÃ—N], B[NÃ—m], C[nÃ—N]ï¼‰
        A = data["A"]
        B = data["B"]
        C = data["C"]
        assert A.ndim == 2 and A.shape[0] == A.shape[1], f"AçŸ©é˜µéœ€ä¸ºæ–¹é˜µï¼Œå½“å‰å½¢çŠ¶{A.shape}"
        assert B.ndim == 2 and B.shape[0] == A.shape[0], f"BçŸ©é˜µè¡Œæ•°éœ€ä¸Aä¸€è‡´ï¼Œå½“å‰B.shape{B.shape}"
        assert C.ndim == 2 and C.shape[1] == A.shape[0], f"CçŸ©é˜µåˆ—æ•°éœ€ä¸Aä¸€è‡´ï¼Œå½“å‰C.shape{C.shape}"
        print(f"æˆåŠŸè¯»å– {version} ç‰ˆæœ¬ï¼ˆseed={seed}ï¼‰ï¼šA[{A.shape[0]}Ã—{A.shape[1]}], B[{B.shape[0]}Ã—{B.shape[1]}], C[{C.shape[0]}Ã—{C.shape[1]}]")
        return {"A": A, "B": B, "C": C}
    except FileNotFoundError:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ–‡ä»¶ï¼š{file_path}ï¼Œè¯·æ£€æŸ¥ç‰ˆæœ¬å’Œç§å­æ˜¯å¦æ­£ç¡®")
    except KeyError as e:
        raise KeyError(f"æ–‡ä»¶ä¸­ç¼ºå°‘çŸ©é˜µï¼š{e}ï¼Œè¯·ç¡®è®¤ä¿å­˜æ—¶çš„é”®ä¸º'A'ã€'B'ã€'C'")


def compute_abc_metrics(abc_dict: Dict[str, np.ndarray], psi: Optional["PsiMLP"] = None, x_star: Optional[np.ndarray] = None) -> Dict[str, float]:
    """
    è®¡ç®— Aã€Bã€C çŸ©é˜µçš„å…³é”®æŒ‡æ ‡ï¼ˆåŸºäºæ–‡æ¡£æ ¸å¿ƒè¦æ±‚ï¼‰
    
    Args:
        abc_dict: åŒ…å« Aã€Bã€C çš„å­—å…¸
        psi: å¯é€‰ï¼ŒPsiMLP ç½‘ç»œï¼ˆç”¨äºè®¡ç®— C çŸ©é˜µçš„çŠ¶æ€é‡æ„è¯¯å·®ï¼‰
        x_star: å¯é€‰ï¼Œç›®æ ‡åŸçŠ¶æ€ï¼ˆç”¨äºé‡æ„è¯¯å·®è®¡ç®—ï¼Œshape=[n]ï¼‰
    
    Returns:
        metrics: é‡åŒ–æŒ‡æ ‡å­—å…¸
    """
    A = abc_dict["A"]
    B = abc_dict["B"]
    C = abc_dict["C"]
    N = A.shape[0]  # é«˜ç»´ç©ºé—´ç»´åº¦
    m = B.shape[1]  # æ§åˆ¶ç»´åº¦ï¼ˆæœˆçƒç€é™†å™¨ m=2ï¼‰
    n = C.shape[0]  # åŸçŠ¶æ€ç»´åº¦ï¼ˆæœˆçƒç€é™†å™¨ n=6ï¼‰
    
    metrics = {}

    # -------------------------- 1. A çŸ©é˜µæŒ‡æ ‡ï¼ˆç¨³å®šæ€§+æ•°å€¼ç‰¹æ€§ï¼‰ --------------------------
    # 1.1 ç‰¹å¾å€¼æ¨¡é•¿ï¼ˆç¦»æ•£ç³»ç»Ÿç¨³å®šæ€§ï¼šmax_eig_norm < 1 ä¸ºç¨³å®šï¼ŒğŸ”¶1-37ï¼‰
    eig_vals = np.linalg.eigvals(A)
    eig_norms = np.abs(eig_vals)
    metrics["A_max_eig_norm"] = np.max(eig_norms)  # æœ€å¤§ç‰¹å¾å€¼æ¨¡é•¿ï¼ˆè¶Šå°è¶Šç¨³å®šï¼‰
    metrics["A_mean_eig_norm"] = np.mean(eig_norms)  # å¹³å‡ç‰¹å¾å€¼æ¨¡é•¿
    metrics["A_eig_norm_std"] = np.std(eig_norms)    # ç‰¹å¾å€¼æ¨¡é•¿æ ‡å‡†å·®ï¼ˆè¶Šå°è¶Šå‡åŒ€ï¼‰
    
    # 1.2 çŸ©é˜µèŒƒæ•°ï¼ˆæ•°å€¼ç¨³å®šæ€§ï¼šé¿å…è¿‡å¤§å¯¼è‡´æ§åˆ¶éœ‡è¡ï¼‰
    metrics["A_fro_norm"] = np.linalg.norm(A, ord="fro")  # Frobenius èŒƒæ•°
    metrics["A_inf_norm"] = np.linalg.norm(A, ord=np.inf)  # æ— ç©·èŒƒæ•°

    # -------------------------- 2. B çŸ©é˜µæŒ‡æ ‡ï¼ˆèƒ½æ§æ€§+æ§åˆ¶å¼ºåº¦ï¼‰ --------------------------
    # 2.1 èƒ½æ§æ€§çŸ©é˜µç§©ï¼ˆæ»¡ç§©è¯´æ˜ç³»ç»Ÿå®Œå…¨èƒ½æ§ï¼ŒğŸ”¶1-44ï¼‰
    def compute_controllability_matrix(A: np.ndarray, B: np.ndarray) -> np.ndarray:
        """è®¡ç®—èƒ½æ§æ€§çŸ©é˜µï¼š[B, A*B, AÂ²*B, ..., A^(N-1)*B]ï¼ˆæ–‡æ¡£ III èŠ‚ LQR èƒ½æ§æ€§è¦æ±‚ï¼‰"""
        N = A.shape[0]
        ctrl_mat = B
        current = B
        for _ in range(1, N):
            current = A @ current
            ctrl_mat = np.hstack([ctrl_mat, current])
        return ctrl_mat
    
    ctrl_mat = compute_controllability_matrix(A, B)
    metrics["B_ctrl_rank"] = np.linalg.matrix_rank(ctrl_mat)  # èƒ½æ§æ€§çŸ©é˜µç§©ï¼ˆæ»¡ç§©=Nä¸ºä¼˜ï¼‰
    metrics["B_ctrl_rank_ratio"] = metrics["B_ctrl_rank"] / N  # ç§©å æ¯”ï¼ˆè¶Šæ¥è¿‘1è¶Šå¥½ï¼‰
    
    # 2.2 åˆ—èŒƒæ•°ï¼ˆæ§åˆ¶è¾“å…¥å¯¹å„é«˜ç»´çŠ¶æ€çš„å½±å“å¼ºåº¦ï¼‰
    B_col_norms = np.linalg.norm(B, axis=0)  # æ¯åˆ—èŒƒæ•°ï¼ˆå¯¹åº”æ¯ä¸ªæ§åˆ¶è¾“å…¥çš„å½±å“ï¼‰
    metrics["B_mean_col_norm"] = np.mean(B_col_norms)
    metrics["B_max_col_norm"] = np.max(B_col_norms)

    # -------------------------- 3. C çŸ©é˜µæŒ‡æ ‡ï¼ˆçŠ¶æ€é‡æ„ç²¾åº¦ï¼‰ --------------------------
    # 3.1 çŸ©é˜µèŒƒæ•°ï¼ˆæ•°å€¼è§„æ¨¡ï¼‰
    metrics["C_fro_norm"] = np.linalg.norm(C, ord="fro")
    C_row_norms = np.linalg.norm(C, axis=1)  # æ¯è¡ŒèŒƒæ•°ï¼ˆå¯¹åº”åŸçŠ¶æ€å„ç»´åº¦çš„é‡æ„æƒé‡ï¼‰
    metrics["C_mean_row_norm"] = np.mean(C_row_norms)
    
    # 3.2 çŠ¶æ€é‡æ„è¯¯å·®ï¼ˆéœ€ Psi ç½‘ç»œï¼Œå¯é€‰ï¼ŒğŸ”¶1-42 Equation 9ï¼‰
    if psi is not None and x_star is not None:
        # ç”ŸæˆéšæœºåŸçŠ¶æ€æ ·æœ¬ï¼ˆè¦†ç›–æœˆçƒç€é™†å™¨çŠ¶æ€ç©ºé—´ï¼ŒğŸ”¶1-80ï¼‰
        np.random.seed(2)
        x_samples = np.random.uniform(
            low=[-1.5, 0.0, -np.pi, -5.0, -5.0, -8.0],
            high=[1.5, 1.5, np.pi, 5.0, 5.0, 8.0],
            size=(100, n)  # 100ä¸ªæ ·æœ¬ï¼Œç»Ÿè®¡å¹³å‡è¯¯å·®
        )
        recon_errors = []
        psi.eval()
        with torch.no_grad():
            device = next(psi.parameters()).device
            x_star_tensor = torch.tensor(x_star, device=device, dtype=torch.float32).unsqueeze(0)
            for x in x_samples:
                x_tensor = torch.tensor(x, device=device, dtype=torch.float32).unsqueeze(0)
                z = psi.compute_z(x_tensor, x_star_tensor)  # z = Î¨(x) - Î¨(x*)
                z_np = z.cpu().numpy().squeeze()
                # é‡æ„åŸçŠ¶æ€ï¼šx_recon = C @ (z + Î¨(x*))ï¼ˆå›  z = Î¨(x)-Î¨(x*)ï¼Œæ•… Î¨(x) = z + Î¨(x*)ï¼‰
                psi_x_star = psi(x_star_tensor).cpu().numpy().squeeze()
                x_recon = C @ (z_np + psi_x_star)
                # è®¡ç®—é‡æ„è¯¯å·®ï¼ˆL2èŒƒæ•°ï¼‰
                recon_errors.append(np.linalg.norm(x - x_recon, ord=2))
        metrics["C_mean_recon_error"] = np.mean(recon_errors)
        metrics["C_recon_error_std"] = np.std(recon_errors)
    
    return metrics


def plot_abc_comparison(ver1_abc: Dict[str, np.ndarray], ver2_abc: Dict[str, np.ndarray], 
                        ver1_metrics: Dict[str, float], ver2_metrics: Dict[str, float],
                        ver1_name: str, ver2_name: str):
    """
    å¯è§†åŒ–å¯¹æ¯”ä¸¤ä¸ªæŒ‡å®šç‰ˆæœ¬çš„ Aã€Bã€C çŸ©é˜µå…³é”®æŒ‡æ ‡ï¼ˆè´´åˆæ–‡æ¡£å…³æ³¨é‡ç‚¹ï¼‰
    """
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    # åŠ¨æ€è®¾ç½®æ ‡é¢˜ï¼ˆæ˜¾ç¤ºç”¨æˆ·æŒ‡å®šçš„ä¸¤ä¸ªç‰ˆæœ¬ï¼‰
    fig.suptitle(f"DKRC A/B/C Matrix Comparison ({ver1_name} vs {ver2_name})", fontsize=16, fontweight="bold")
    colors = ["#1f77b4", "#ff7f0e"]  # ç¬¬ä¸€ä¸ªç‰ˆæœ¬è“ï¼Œç¬¬äºŒä¸ªç‰ˆæœ¬æ©™

    # -------------------------- å­å›¾1ï¼šAçŸ©é˜µç‰¹å¾å€¼åˆ†å¸ƒï¼ˆç¨³å®šæ€§æ ¸å¿ƒæŒ‡æ ‡ï¼‰ --------------------------
    ax1 = axes[0, 0]
    # è®¡ç®—ç‰¹å¾å€¼
    ver1_eig = np.linalg.eigvals(ver1_abc["A"])
    ver2_eig = np.linalg.eigvals(ver2_abc["A"])
    # ç»˜åˆ¶ç‰¹å¾å€¼æ•£ç‚¹ï¼ˆå®éƒ¨vsè™šéƒ¨ï¼‰
    ax1.scatter(np.real(ver1_eig), np.imag(ver1_eig), color=colors[0], alpha=0.6, 
                label=f"{ver1_name} (max_norm={ver1_metrics['A_max_eig_norm']:.3f})")
    ax1.scatter(np.real(ver2_eig), np.imag(ver2_eig), color=colors[1], alpha=0.6, 
                label=f"{ver2_name} (max_norm={ver2_metrics['A_max_eig_norm']:.3f})")
    # ç»˜åˆ¶å•ä½åœ†ï¼ˆç¨³å®šæ€§è¾¹ç•Œï¼šç¦»æ•£ç³»ç»Ÿç‰¹å¾å€¼éœ€åœ¨åœ†å†…ï¼‰
    theta = np.linspace(0, 2*np.pi, 100)
    ax1.plot(np.cos(theta), np.sin(theta), "k--", alpha=0.5, label="Unit Circle (Stability Boundary)")
    ax1.set_xlabel("Real Part of Eigenvalue", fontsize=12)
    ax1.set_ylabel("Imaginary Part of Eigenvalue", fontsize=12)
    ax1.set_title("A Matrix Eigenvalue Distribution (Stability)", fontsize=14)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # -------------------------- å­å›¾2ï¼šèƒ½æ§æ€§ä¸ç¨³å®šæ€§æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯” --------------------------
    ax2 = axes[0, 1]
    # é€‰æ‹©å…³é”®æŒ‡æ ‡ï¼ˆç¨³å®šæ€§+èƒ½æ§æ€§ï¼Œæ–‡æ¡£ III èŠ‚é‡ç‚¹ï¼‰
    metrics_names = [
        "A Max Eigen Norm\n(Stability, <1 is better)",
        "A Mean Eigen Norm\n(Uniformity)",
        "B Controllability Rank\n(Ratio, 1 is full rank)",
        "B Mean Column Norm\n(Control Strength)"
    ]
    ver1_vals = [
        ver1_metrics["A_max_eig_norm"],
        ver1_metrics["A_mean_eig_norm"],
        ver1_metrics["B_ctrl_rank_ratio"],
        ver1_metrics["B_mean_col_norm"]
    ]
    ver2_vals = [
        ver2_metrics["A_max_eig_norm"],
        ver2_metrics["A_mean_eig_norm"],
        ver2_metrics["B_ctrl_rank_ratio"],
        ver2_metrics["B_mean_col_norm"]
    ]
    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    x = np.arange(len(metrics_names))
    width = 0.35
    ax2.bar(x - width/2, ver1_vals, width, color=colors[0], label=ver1_name)
    ax2.bar(x + width/2, ver2_vals, width, color=colors[1], label=ver2_name)
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (v1, v2) in enumerate(zip(ver1_vals, ver2_vals)):
        ax2.text(i - width/2, v1 + 0.01, f"{v1:.3f}", ha="center", fontsize=10)
        ax2.text(i + width/2, v2 + 0.01, f"{v2:.3f}", ha="center", fontsize=10)
    ax2.set_xlabel("Key Metrics", fontsize=12)
    ax2.set_ylabel("Metric Value", fontsize=12)
    ax2.set_title("Core Metrics Comparison (Stability + Controllability)", fontsize=14)
    ax2.set_xticks(x)
    ax2.set_xticklabels(metrics_names, rotation=0, fontsize=10)
    ax2.legend()
    ax2.grid(True, alpha=0.3, axis="y")

    # -------------------------- å­å›¾3ï¼šCçŸ©é˜µçŠ¶æ€é‡æ„è¯¯å·®å¯¹æ¯”ï¼ˆè‹¥æœ‰æ•°æ®ï¼‰ --------------------------
    ax3 = axes[1, 0]
    if "C_mean_recon_error" in ver1_metrics and "C_mean_recon_error" in ver2_metrics:
        # é‡æ„è¯¯å·®ç®±çº¿å›¾
        recon_data = [
            np.random.normal(ver1_metrics["C_mean_recon_error"], ver1_metrics["C_recon_error_std"], 100),
            np.random.normal(ver2_metrics["C_mean_recon_error"], ver2_metrics["C_recon_error_std"], 100)
        ]
        bp = ax3.boxplot(recon_data, labels=[ver1_name, ver2_name], patch_artist=True)
        for patch, color in zip(bp["boxes"], colors):
            patch.set_facecolor(color)
            patch.set_alpha(0.6)
        # æ·»åŠ å‡å€¼çº¿
        ax3.axhline(y=ver1_metrics["C_mean_recon_error"], color=colors[0], linestyle="--", alpha=0.8, 
                    label=f"{ver1_name} Mean: {ver1_metrics['C_mean_recon_error']:.3f}")
        ax3.axhline(y=ver2_metrics["C_mean_recon_error"], color=colors[1], linestyle="--", alpha=0.8, 
                    label=f"{ver2_name} Mean: {ver2_metrics['C_mean_recon_error']:.3f}")
        ax3.set_xlabel("Model Version", fontsize=12)
        ax3.set_ylabel("State Reconstruction Error (L2 Norm)", fontsize=12)
        ax3.set_title("C Matrix State Reconstruction Error", fontsize=14)
        ax3.legend()
        ax3.grid(True, alpha=0.3, axis="y")
    else:
        ax3.text(0.5, 0.5, "Need PsiMLP to Compute Reconstruction Error", ha="center", va="center", 
                 transform=ax3.transAxes, fontsize=12)
        ax3.set_xlabel("Model Version", fontsize=12)
        ax3.set_ylabel("Reconstruction Error", fontsize=12)
        ax3.set_title("C Matrix State Reconstruction Error (No Data)", fontsize=14)

    # -------------------------- å­å›¾4ï¼šçŸ©é˜µèŒƒæ•°å¯¹æ¯”ï¼ˆæ•°å€¼ç¨³å®šæ€§ï¼‰ --------------------------
    ax4 = axes[1, 1]
    # çŸ©é˜µèŒƒæ•°æŒ‡æ ‡ï¼ˆFrobenius èŒƒæ•°ï¼Œæ•°å€¼ç¨³å®šæ€§ï¼‰
    norm_names = ["A Norm", "B Norm", "C Norm"]
    ver1_norms = [
        ver1_metrics["A_fro_norm"],
        np.linalg.norm(ver1_abc["B"], ord="fro"),
        ver1_metrics["C_fro_norm"]
    ]
    ver2_norms = [
        ver2_metrics["A_fro_norm"],
        np.linalg.norm(ver2_abc["B"], ord="fro"),
        ver2_metrics["C_fro_norm"]
    ]
    # ç»˜åˆ¶å †å æŸ±çŠ¶å›¾
    x = np.arange(len(norm_names))
    ax4.bar(x - width/2, ver1_norms, width, color=colors[0], label=ver1_name)
    ax4.bar(x + width/2, ver2_norms, width, color=colors[1], label=ver2_name)
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (v1, v2) in enumerate(zip(ver1_norms, ver2_norms)):
        ax4.text(i - width/2, v1 + 0.5, f"{v1:.1f}", ha="center", fontsize=10)
        ax4.text(i + width/2, v2 + 0.5, f"{v2:.1f}", ha="center", fontsize=10)
    ax4.set_xlabel("Matrix Type", fontsize=12)
    ax4.set_ylabel("Frobenius Norm (Numerical Stability)", fontsize=12)
    ax4.set_title("Matrix Norm Comparison (Numerical Scale)", fontsize=14)
    ax4.set_xticks(x)
    ax4.set_xticklabels(norm_names)
    ax4.legend()
    ax4.grid(True, alpha=0.3, axis="y")

    # åŠ¨æ€å‘½åä¿å­˜å›¾ç‰‡ï¼ˆåŒ…å«ä¸¤ä¸ªç‰ˆæœ¬ï¼Œé¿å…è¦†ç›–ï¼‰
    plt.tight_layout()
    save_path = f"./fig/lunar_lander_abc_comparison_{ver1_name}_vs_{ver2_name}.png"
    plt.savefig(save_path, dpi=300, bbox_inches="tight")
    plt.close()
    print(f"\nA/B/C å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜ä¸ºï¼š{save_path}")


def main(ver1_name: str, ver2_name: str, seed: int = 2, data_dir: str = ".", 
         psi_ver1: Optional["PsiMLP"] = None, psi_ver2: Optional["PsiMLP"] = None):
    """
    ä¸»å‡½æ•°ï¼šè¯»å–ç”¨æˆ·æŒ‡å®šçš„ä¸¤ä¸ªç‰ˆæœ¬çš„ A/B/Cï¼Œè®¡ç®—æŒ‡æ ‡ï¼Œå¯¹æ¯”å¹¶å¯è§†åŒ–
    """
    # 1. è¯»å–ä¸¤ä¸ªæŒ‡å®šç‰ˆæœ¬çš„ A/B/C çŸ©é˜µ
    ver1_abc = load_abc_matrix(version=ver1_name, seed=seed, data_dir=data_dir)
    ver2_abc = load_abc_matrix(version=ver2_name, seed=seed, data_dir=data_dir)

    # 2. è®¡ç®—å…³é”®æŒ‡æ ‡ï¼ˆè‹¥æœ‰ Psi ç½‘ç»œï¼Œå¯ä¼ å…¥è®¡ç®—é‡æ„è¯¯å·®ï¼‰
    x_star = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])  # ç›®æ ‡çŠ¶æ€ï¼ˆæ–‡æ¡£ IV.D èŠ‚ï¼‰
    ver1_metrics = compute_abc_metrics(ver1_abc, psi=psi_ver1, x_star=x_star)
    ver2_metrics = compute_abc_metrics(ver2_abc, psi=psi_ver2, x_star=x_star)

    # 3. æ‰“å°é‡åŒ–å¯¹æ¯”ç»“æœï¼ˆåŠ¨æ€æ˜¾ç¤ºç‰ˆæœ¬åï¼‰
    print("\n" + "="*80)
    print(f"DKRC A/B/C Matrix Quantitative Comparison ({ver1_name} vs {ver2_name})")
    print("="*80)
    # æŒ‰çŸ©é˜µåˆ†ç±»æ‰“å°
    print(f"\nã€1. A Matrix (Stability)ã€‘")
    print(f"{'Metric':<30} {ver1_name:<12} {ver2_name:<12} {'Better Version':<10}")
    print("-"*64)
    metrics_a = [
        ("Max Eigen Norm (<1 is stable)", "A_max_eig_norm"),
        ("Mean Eigen Norm (uniformity)", "A_mean_eig_norm"),
        ("Eigen Norm Std (consistency)", "A_eig_norm_std"),
        ("Frobenius Norm (numerical scale)", "A_fro_norm")
    ]
    for name, key in metrics_a:
        ver1_val = ver1_metrics[key]
        ver2_val = ver2_metrics[key]
        better = ver1_name if ver1_val < ver2_val else ver2_name
        print(f"{name:<30} {ver1_val:<12.4f} {ver2_val:<12.4f} {better:<10}")

    print(f"\nã€2. B Matrix (Controllability)ã€‘")
    print(f"{'Metric':<30} {ver1_name:<12} {ver2_name:<12} {'Better Version':<10}")
    print("-"*64)
    metrics_b = [
        ("Controllability Rank (full=N)", "B_ctrl_rank"),
        ("Controllability Rank Ratio (1 is best)", "B_ctrl_rank_ratio"),
        ("Mean Column Norm (control strength)", "B_mean_col_norm"),
        ("Max Column Norm (max control impact)", "B_max_col_norm")
    ]
    for name, key in metrics_b:
        ver1_val = ver1_metrics[key]
        ver2_val = ver2_metrics[key]
        # èƒ½æ§æ€§ç§©å æ¯”è¶Šå¤§è¶Šå¥½ï¼Œå…¶ä»–æŒ‡æ ‡è¶Šå°è¶Šå¥½
        better = ver1_name if (key == "B_ctrl_rank_ratio" and ver1_val > ver2_val) else (ver2_name if ver1_val < ver2_val else ver1_name)
        print(f"{name:<30} {ver1_val:<12.4f} {ver2_val:<12.4f} {better:<10}")

    if "C_mean_recon_error" in ver1_metrics and "C_mean_recon_error" in ver2_metrics:
        print(f"\nã€3. C Matrix (Reconstruction)ã€‘")
        print(f"{'Metric':<30} {ver1_name:<12} {ver2_name:<12} {'Better Version':<10}")
        print("-"*64)
        metrics_c = [
            ("Mean Reconstruction Error (accuracy)", "C_mean_recon_error"),
            ("Recon Error Std (consistency)", "C_recon_error_std"),
            ("Mean Row Norm (weight uniformity)", "C_mean_row_norm"),
            ("Frobenius Norm (numerical scale)", "C_fro_norm")
        ]
        for name, key in metrics_c:
            ver1_val = ver1_metrics[key]
            ver2_val = ver2_metrics[key]
            better = ver1_name if ver1_val < ver2_val else ver2_name
            print(f"{name:<30} {ver1_val:<12.4f} {ver2_val:<12.4f} {better:<10}")

    # 4. å¯è§†åŒ–å¯¹æ¯”ï¼ˆä¼ å…¥ç‰ˆæœ¬åï¼ŒåŠ¨æ€ç”Ÿæˆå›¾è¡¨ï¼‰
    plot_abc_comparison(ver1_abc, ver2_abc, ver1_metrics, ver2_metrics, ver1_name, ver2_name)

    # 5. æ€»ç»“å…³é”®ç»“è®ºï¼ˆåŠ¨æ€é€‚é…ç‰ˆæœ¬åï¼‰
    print("\n" + "="*80)
    print(f"Key Conclusion (Based on DKRC Control Logic)")
    print("="*80)
    # ç¨³å®šæ€§ç»“è®º
    if ver1_metrics["A_max_eig_norm"] < 1 and ver2_metrics["A_max_eig_norm"] >= 1:
        print(f"âŒ {ver2_name} A matrix is UNSTABLE (max eigen norm â‰¥1) â†’ LQR control may oscillate")
    elif ver1_metrics["A_max_eig_norm"] >= 1 and ver2_metrics["A_max_eig_norm"] < 1:
        print(f"âœ… {ver2_name} A matrix is MORE STABLE (max eigen norm <1) â†’ Better control stability")
    else:
        stable_flag = "stable" if ver1_metrics["A_max_eig_norm"] <1 else "unstable"
        print(f"âš ï¸ Both A matrices are {stable_flag} ({ver1_name}: {ver1_metrics['A_max_eig_norm']:.3f}, {ver2_name}: {ver2_metrics['A_max_eig_norm']:.3f})")
    # èƒ½æ§æ€§ç»“è®º
    if ver1_metrics["B_ctrl_rank_ratio"] == 1 and ver2_metrics["B_ctrl_rank_ratio"] < 1:
        print(f"âŒ {ver2_name} B matrix has INSUFFICIENT CONTROLLABILITY â†’ LQR cannot design effective gain")
    elif ver1_metrics["B_ctrl_rank_ratio"] < 1 and ver2_metrics["B_ctrl_rank_ratio"] == 1:
        print(f"âœ… {ver2_name} B matrix is FULLY CONTROLLABLE â†’ Better LQR control performance")
    else:
        print(f"âš ï¸ Controllability: {ver1_name} ratio={ver1_metrics['B_ctrl_rank_ratio']:.3f}, {ver2_name} ratio={ver2_metrics['B_ctrl_rank_ratio']:.3f} (1.0 is full rank)")
    # é‡æ„ç²¾åº¦ç»“è®ºï¼ˆè‹¥æœ‰æ•°æ®ï¼‰
    if "C_mean_recon_error" in ver1_metrics:
        if ver2_metrics["C_mean_recon_error"] < ver1_metrics["C_mean_recon_error"]:
            print(f"âœ… {ver2_name} C matrix has BETTER RECONSTRUCTION ACCURACY â†’ More accurate state observation")
        else:
            print(f"âŒ {ver2_name} C matrix has WORSE RECONSTRUCTION ACCURACY â†’ Less accurate state observation")


# è°ƒç”¨ç¤ºä¾‹ï¼ˆæ”¯æŒå‘½ä»¤è¡ŒæŒ‡å®šä»»æ„ä¸¤ä¸ªç‰ˆæœ¬ï¼‰
if __name__ == "__main__":
    # æ–°å¢å‘½ä»¤è¡Œå‚æ•°ï¼š--version1 å’Œ --version2ï¼Œæ”¯æŒç”¨æˆ·æŒ‡å®šå¯¹æ¯”ç‰ˆæœ¬
    parser = argparse.ArgumentParser(description="Compare DKRC A/B/C Matrices between Two Versions")
    parser.add_argument("--ver1", type=str, default="v1", help="First version to compare (e.g., v1, v2)")
    parser.add_argument("--ver2", type=str, default="v2", help="Second version to compare (e.g., v2, v3)")
    parser.add_argument("--seed", type=int, default=2, help="Random seed used in training (default: 2)")
    parser.add_argument("--data_dir", type=str, default="data", help="Directory of A/B/C npz files (default: current dir)")
    args = parser.parse_args()

    # è‹¥éœ€è¦è®¡ç®— C çŸ©é˜µçš„é‡æ„è¯¯å·®ï¼Œéœ€ä¼ å…¥å¯¹åº”ç‰ˆæœ¬çš„ PsiMLP ç½‘ç»œï¼ˆå¯é€‰ï¼‰
    # from rdkrc.models.psi_mlp import PsiMLP
    # psi_ver1 = PsiMLP(...)  # åŠ è½½ç¬¬ä¸€ä¸ªç‰ˆæœ¬çš„ Psi ç½‘ç»œ
    # psi_ver2 = PsiMLP(...)  # åŠ è½½ç¬¬äºŒä¸ªç‰ˆæœ¬çš„ Psi ç½‘ç»œ
    # main(ver1_name=args.version1, ver2_name=args.version2, seed=args.seed, data_dir=args.data_dir, psi_ver1=psi_ver1, psi_ver2=psi_ver2)

    # è‹¥æ—  Psi ç½‘ç»œï¼Œä»…å¯¹æ¯” A/B/C çš„åŸºç¡€æŒ‡æ ‡
    main(ver1_name=args.ver1, ver2_name=args.ver2, seed=args.seed, data_dir=args.data_dir)