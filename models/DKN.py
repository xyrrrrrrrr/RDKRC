import torch
import torch.nn as nn
import numpy as np
from typing import List, Optional, Union, Tuple


class KoopmanOperator(nn.Module):
    # å‚æ•°åŒ– Koopman çº¿æ€§ç®—å­, å¯¹åµŒåˆçŠ¶æ€è¿›è¡Œè®­ç»ƒ
    def __init__(self, cat_dim: int, control_embed_dim: int, device: torch.device):
        super().__init__()
        # A: çŠ¶æ€è½¬ç§»çŸ©é˜µï¼ˆz_dim â†’ z_dimï¼‰ï¼Œå¯¹åº”æ–‡æ¡£IV.BèŠ‚â€œçº¿æ€§çŠ¶æ€è½¬ç§»â€
        self.A = nn.Linear(cat_dim, cat_dim, device=device, bias=False)
        # B: æ§åˆ¶å¢ç›ŠçŸ©é˜µï¼ˆæ§åˆ¶åµŒå…¥ç»´åº¦ â†’ z_dimï¼‰ï¼Œå¯¹åº”æ–‡æ¡£IV.AèŠ‚â€œæ§åˆ¶åµŒå…¥åˆ°zç©ºé—´â€
        self.B = nn.Linear(control_embed_dim, cat_dim, device=device, bias=False)
        # åˆå§‹åŒ–ï¼šAç”¨å•ä½çŸ©é˜µï¼ˆåˆå§‹è¿‘ä¼¼æ’ç­‰è½¬ç§»ï¼‰ï¼ŒBç”¨å°æƒé‡ï¼ˆåˆå§‹æ§åˆ¶å½±å“å¼±ï¼‰
        nn.init.eye_(self.A.weight)
        nn.init.normal_(self.B.weight, mean=0.0, std=0.01)

    def forward(self, z_prev: torch.Tensor, g_u: torch.Tensor) -> torch.Tensor:
        """
        åµŒå…¥ç©ºé—´çº¿æ€§åŠ¨åŠ›å­¦è®¡ç®—ï¼šz_next = A z_prev + B g_u
        input: z_prev (B, z_dim), g_u (B, control_embed_dim)
        output: z_next (B, z_dim)
        """
        return self.A(z_prev) + self.B(g_u)
    

class StateEmbedding(nn.Module):
    # å®ç°è®ºæ–‡ä¸­çš„çŠ¶æ€ç¼–ç 
    def __init__(self, x_dim: int, z_dim: int, hidden_dim:int, device: torch.device):
        super().__init__()
        self.Linear1 = nn.Linear(x_dim, hidden_dim)
        self.Linear2 = nn.Linear(hidden_dim, z_dim)
        self.activation = nn.Tanh()
        self.x_dim = x_dim
        self.z_dim = z_dim
        self.cat_dim = x_dim + z_dim

    def forward(self, x):
        # result = torch.cat([x, u], dim=1)
        result = self.Linear1(x)
        result = self.activation(result)
        result = self.Linear2(result)
        if len(x.shape) > 3:
            result = torch.cat([x, result], dim=3)
        elif len(x.shape) > 2:
            result = torch.cat([x, result], dim=2)
        elif len(x.shape) > 1:
            result = torch.cat([x, result], dim=1)
        else:
            result = torch.cat([x, result], dim=0)
        return result


import torch
import torch.nn as nn
import torch.nn.functional as F


class ControlEmbeddingVAE(nn.Module):
    """
    åŸºäºVAEï¼ˆå˜åˆ†è‡ªç¼–ç å™¨ï¼‰ç»“æ„å®ç°è®ºæ–‡ä¸­çš„æ§åˆ¶ç¼–ç åŠŸèƒ½
    æ ¸å¿ƒæ”¹è¿›ï¼šå¼•å…¥å˜åˆ†æ¨æ–­ï¼Œç¼–ç å™¨è¾“å‡º latent åˆ†å¸ƒçš„å‡å€¼å’Œå¯¹æ•°æ–¹å·®ï¼Œé€šè¿‡é‡å‚æ•°åŒ–é‡‡æ ·è·å– latent å˜é‡ï¼Œè§£ç å™¨é‡å»ºè¾“å…¥çš„çŠ¶æ€-æ§åˆ¶å¯¹
    """
    def __init__(self, x_dim: int, control_dim: int, hidden_dim: int, device: torch.device):
        super().__init__()
        self.device = device
        
        # 1. ç¡®å®šVAEè¾“å…¥ç»´åº¦ï¼ˆæ˜¯å¦æ‹¼æ¥çŠ¶æ€xå’Œæ§åˆ¶uï¼‰
        self.cat = x_dim != 0  # å½“x_dim=0æ—¶ï¼Œä»…ç”¨æ§åˆ¶uä½œä¸ºè¾“å…¥ï¼›å¦åˆ™æ‹¼æ¥xå’Œu
        self.input_dim = control_dim if not self.cat else (x_dim + control_dim)
        
        # 2. VAEç¼–ç å™¨ï¼šè¾“å…¥ï¼ˆx+u æˆ– uï¼‰â†’ è¾“å‡º latent åˆ†å¸ƒçš„å‡å€¼(mu)å’Œå¯¹æ•°æ–¹å·®(log_var)
        self.encoder = nn.Sequential(
            nn.Linear(self.input_dim, hidden_dim),  # å…±äº«ç‰¹å¾æå–å±‚
            nn.Tanh(),
        )
        self.fc_mu = nn.Linear(hidden_dim, control_dim)  # è¾“å‡ºlatentå‡å€¼
        self.fc_log_var = nn.Linear(hidden_dim, control_dim)  # è¾“å‡ºlatentå¯¹æ•°æ–¹å·®ï¼ˆé¿å…æ–¹å·®ä¸ºè´Ÿï¼‰
        
        # 3. VAEè§£ç å™¨ï¼šè¾“å…¥ latent å˜é‡ â†’ é‡å»ºåŸå§‹è¾“å…¥ï¼ˆx+u æˆ– uï¼‰
        self.decoder = nn.Sequential(
            nn.Linear(control_dim, hidden_dim),  # latentç‰¹å¾æ˜ å°„å±‚
            nn.Tanh(),
            nn.Linear(hidden_dim, self.input_dim)  # è¾“å‡ºç»´åº¦=è¾“å…¥ç»´åº¦ï¼Œç”¨äºé‡å»º
        )

    def reparameterize(self, mu: torch.Tensor, log_var: torch.Tensor) -> torch.Tensor:
        """
        VAEæ ¸å¿ƒé‡å‚æ•°åŒ–æŠ€å·§ï¼šä»N(mu, stdÂ²)ä¸­é‡‡æ ·latentå˜é‡ï¼Œç¡®ä¿æ¢¯åº¦å¯åå‘ä¼ æ’­
        Args:
            mu: latentåˆ†å¸ƒçš„å‡å€¼ï¼Œshape=(batch_size, latent_dim)
            log_var: latentåˆ†å¸ƒçš„å¯¹æ•°æ–¹å·®ï¼Œshape=(batch_size, latent_dim)
        Returns:
            latent: é‡‡æ ·åçš„latentå˜é‡ï¼Œshape=(batch_size, latent_dim)
        """
        std = torch.exp(0.5 * log_var)  # æ ‡å‡†å·® = å¯¹æ•°æ–¹å·®çš„æŒ‡æ•°å¼€å¹³æ–¹
        eps = torch.randn_like(std, device=self.device)  # ä»æ ‡å‡†æ­£æ€åˆ†å¸ƒN(0,1)é‡‡æ ·eps
        return mu + eps * std  # é‡å‚æ•°åŒ–ï¼šmu + eps*std ~ N(mu, stdÂ²)

    def encode(self, x: torch.Tensor, u: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
        """
        ç¼–ç å™¨å‰å‘ä¼ æ’­ï¼šå¤„ç†è¾“å…¥ï¼ˆx+u æˆ– uï¼‰â†’ è¾“å‡ºlatentåˆ†å¸ƒçš„muå’Œlog_var
        Args:
            x: ç³»ç»ŸçŠ¶æ€ï¼Œshape=(batch_size, x_dim)ï¼›è‹¥x_dim=0ï¼Œå¯ä¼ å…¥None
            u: æ§åˆ¶è¾“å…¥ï¼Œshape=(batch_size, control_dim)
        Returns:
            mu: latentå‡å€¼ï¼Œshape=(batch_size, latent_dim)
            log_var: latentå¯¹æ•°æ–¹å·®ï¼Œshape=(batch_size, latent_dim)
        """
        # æ‹¼æ¥è¾“å…¥ï¼ˆè‹¥éœ€è¦ï¼‰
        if self.cat:
            input_data = torch.cat([x, u], dim=1)  # shape=(batch_size, x_dim+control_dim)
        else:
            input_data = u  # shape=(batch_size, control_dim)
        
        # æå–ç‰¹å¾å¹¶è¾“å‡ºåˆ†å¸ƒå‚æ•°
        feat = self.encoder(input_data)
        mu = self.fc_mu(feat)
        log_var = self.fc_log_var(feat)
        return mu, log_var

    def decode(self, latent: torch.Tensor) -> torch.Tensor:
        """
        è§£ç å™¨å‰å‘ä¼ æ’­ï¼šä»latentå˜é‡é‡å»ºåŸå§‹è¾“å…¥ï¼ˆx+u æˆ– uï¼‰
        Args:
            latent: é‡‡æ ·åçš„latentå˜é‡ï¼Œshape=(batch_size, latent_dim)
        Returns:
            recon_data: é‡å»ºçš„è¾“å…¥æ•°æ®ï¼Œshape=(batch_size, input_dim)
        """
        recon_data = self.decoder(latent)
        return recon_data

    def forward(self, x: torch.Tensor, u: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        VAEå®Œæ•´å‰å‘ä¼ æ’­ï¼šç¼–ç â†’é‡å‚æ•°åŒ–â†’è§£ç 
        Args:
            x: ç³»ç»ŸçŠ¶æ€ï¼Œshape=(batch_size, x_dim)ï¼›è‹¥x_dim=0ï¼Œå¯ä¼ å…¥None
            u: æ§åˆ¶è¾“å…¥ï¼Œshape=(batch_size, control_dim)
        Returns:
            latent: é‡‡æ ·åçš„latentå˜é‡ï¼ˆæ§åˆ¶ç¼–ç ç»“æœï¼‰ï¼Œshape=(batch_size, latent_dim)
            recon_data: é‡å»ºçš„è¾“å…¥æ•°æ®ï¼Œshape=(batch_size, input_dim)
            mu: latentåˆ†å¸ƒå‡å€¼ï¼Œshape=(batch_size, latent_dim)
            log_var: latentåˆ†å¸ƒå¯¹æ•°æ–¹å·®ï¼Œshape=(batch_size, latent_dim)
        """
        # 1. ç¼–ç ï¼šè·å–latentåˆ†å¸ƒå‚æ•°
        mu, log_var = self.encode(x, u)
        # 2. é‡å‚æ•°åŒ–ï¼šé‡‡æ ·latentå˜é‡
        latent = self.reparameterize(mu, log_var)
        # 3. è§£ç ï¼šé‡å»ºåŸå§‹è¾“å…¥
        recon_data = self.decode(latent)
        if self.cat:
            input_data = torch.cat([x, u], dim=1)  # shape=(batch_size, x_dim+control_dim)
        else:
            input_data = u  # shape=(batch_size, control_dim)
        loss = self.vae_loss(recon_data, input_data, mu, log_var )
        
        return latent, recon_data, mu, log_var, loss


    # ç¤ºä¾‹ï¼šVAEè®­ç»ƒæ—¶çš„æŸå¤±è®¡ç®—ï¼ˆéœ€ç»“åˆé‡å»ºæŸå¤±å’ŒKLæ•£åº¦ï¼‰
    def vae_loss(self, recon_data: torch.Tensor, input_data: torch.Tensor, mu: torch.Tensor, log_var: torch.Tensor) -> torch.Tensor:
        """
        VAEæŸå¤±å‡½æ•°ï¼šé‡å»ºæŸå¤±ï¼ˆMSEï¼‰ + KLæ•£åº¦ï¼ˆæ­£åˆ™åŒ–latentåˆ†å¸ƒæ¥è¿‘æ ‡å‡†æ­£æ€ï¼‰
        Args:
            recon_data: è§£ç å™¨è¾“å‡ºçš„é‡å»ºæ•°æ®ï¼Œshape=(batch_size, input_dim)
            input_data: åŸå§‹è¾“å…¥æ•°æ®ï¼ˆx+u æˆ– uï¼‰ï¼Œshape=(batch_size, input_dim)
            mu: latentåˆ†å¸ƒå‡å€¼ï¼Œshape=(batch_size, latent_dim)
            log_var: latentåˆ†å¸ƒå¯¹æ•°æ–¹å·®ï¼Œshape=(batch_size, latent_dim)
        Returns:
            total_loss: VAEæ€»æŸå¤±ï¼ˆé‡å»ºæŸå¤± + KLæ•£åº¦ï¼‰
        """
        # 1. é‡å»ºæŸå¤±ï¼šMSEï¼ˆåŒ¹é…åŸå§‹è¾“å…¥å’Œé‡å»ºç»“æœï¼‰
        recon_loss = F.mse_loss(recon_data, input_data, reduction="mean")
        # 2. KLæ•£åº¦ï¼šæ­£åˆ™åŒ–latentåˆ†å¸ƒæ¥è¿‘N(0,1)ï¼ˆå…¬å¼æ¨å¯¼è‡ªå˜åˆ†æ¨æ–­ï¼‰
        kl_loss = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())
        # 3. æ€»æŸå¤±ï¼ˆå¯é€šè¿‡è¶…å‚æ•°å¹³è¡¡ä¸¤è€…æƒé‡ï¼Œæ­¤å¤„é»˜è®¤1:1ï¼‰
        total_loss = recon_loss + kl_loss
        return total_loss



class ControlEmbedding(nn.Module):
    # å®ç°è®ºæ–‡ä¸­çš„æ§åˆ¶ç¼–ç 
    def __init__(self, x_dim: int, control_dim: int, hidden_dim:int, device: torch.device):
        super().__init__()
        if x_dim == 0:
            self.cat = False
            embed_dim = control_dim
        else:
            self.cat = True
            embed_dim = x_dim + control_dim
        self.Linear1 = nn.Linear(embed_dim, hidden_dim)
        self.Linear2 = nn.Linear(hidden_dim, control_dim)
        # self.Linear3 = nn.Linear(embed_dim, hidden_dim)
        self.Linear3 = nn.Linear(control_dim, hidden_dim)
        self.Linear4 = nn.Linear(hidden_dim, control_dim)
        self.activation = nn.Tanh()

    def encoder(self, x, u):
        result = torch.cat([x, u], dim=1)
        result = self.Linear1(result)
        result = self.activation(result)
        return self.Linear2(result)
    
    def decoder(self, latent):
        result = self.Linear3(latent)
        result = self.activation(result)
        return self.Linear4(result)
    
    def forward(self, x, u):
        control_embed = self.encoder(x, u)
        control_decode = self.decoder(control_embed)

        return control_embed, control_decode, u  


class KStepsPredictor(nn.Module):
    def __init__(self, x_dim: int, control_dim: int, z_dim: int, hidden_dim: int, low: Union[List[float], np.ndarray], high: Union[List[float], np.ndarray], K_steps:int, device: torch.device):
        super().__init__()
        self.StateEmbedding = StateEmbedding(x_dim, z_dim, hidden_dim, device)
        self.ControlEmbedding = ControlEmbedding(x_dim, control_dim, hidden_dim, device)
        # self.ControlEmbedding = ControlEmbeddingVAE(x_dim, control_dim, hidden_dim, device)
        self.cat_dim = x_dim + z_dim
        self.KoopmanOperator = KoopmanOperator(self.cat_dim, control_dim, device)
        self.K_steps = K_steps
        self.device = device
        self.low = torch.tensor(low, device=device)
        self.high = torch.tensor(high, device=device)

    def normalize_x(self, x: torch.Tensor) -> torch.Tensor:
        """çŠ¶æ€å½’ä¸€åŒ–ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰"""
        x_clamped = torch.clamp(x, self.low, self.high)
        x_norm = (x_clamped - self.low) / (self.high - self.low + 1e-8)
        return x_norm

    def forward(self, x_init, u_series):
        """
        Kæ­¥é¢„æµ‹å‰å‘ä¼ æ’­ï¼ˆğŸ”¶1-54è‡³ğŸ”¶1-61èŠ‚é€»è¾‘ï¼‰
        Args:
            x_init: åˆå§‹çŠ¶æ€ï¼ˆå½¢çŠ¶ï¼šB Ã— x_dimï¼ŒBä¸ºæ‰¹é‡å¤§å°ï¼‰
            u_series: Kæ­¥æ§åˆ¶è¾“å…¥åºåˆ—ï¼ˆå½¢çŠ¶ï¼šB Ã— K_steps Ã— control_dimï¼‰
        Returns:
            x_pred_series: é¢„æµ‹Kæ­¥çŠ¶æ€åºåˆ—ï¼ˆå½¢çŠ¶ï¼šB Ã— K_steps Ã— x_dimï¼‰
        """
        z_pred_series = []  # å­˜å‚¨æ¯æ­¥é¢„æµ‹çš„åŸå§‹çŠ¶æ€ï¼Œæœ€ç»ˆè¾“å‡º
        u_decode_series = []
        # 1. åˆå§‹çŠ¶æ€åµŒå…¥ï¼šæŒ‰ğŸ”¶1-47èŠ‚Equation 9ï¼Œz = [åŸå§‹çŠ¶æ€x; ç½‘ç»œç¼–ç ç‰¹å¾]
        z_prev = self.StateEmbedding(x_init)[:, 0, :]
        # 2. é€’æ¨æ‰§è¡ŒKæ­¥é¢„æµ‹ï¼ˆéµå¾ªğŸ”¶1-55èŠ‚Equation 13çš„çº¿æ€§åŠ¨åŠ›å­¦ï¼‰
        u_series = u_series.permute(1, 0, 2) 
        for step in range(self.K_steps):
            # 2.1 ä»å½“å‰åµŒå…¥å‘é‡z_prevæå–åŸå§‹çŠ¶æ€x_prevï¼ˆğŸ”¶1-48èŠ‚Equation 10ï¼šx = CÂ·zï¼ŒC=[I_n, 0]ï¼‰
            # æ³¨ï¼šStateEmbeddingè¾“å‡ºçš„zå‰x_dimç»´ä¸ºåŸå§‹çŠ¶æ€ï¼Œéœ€ä¾èµ–å…¶x_dimå±æ€§è®°å½•åŸå§‹çŠ¶æ€ç»´åº¦
            x_prev = z_prev[:, :self.StateEmbedding.x_dim]
            # 2.2 è·å–å½“å‰æ­¥çš„æ§åˆ¶è¾“å…¥u_stepï¼ˆä»Kæ­¥æ§åˆ¶åºåˆ—ä¸­æˆªå–å¯¹åº”æ—¶é—´æ­¥ï¼‰
            u_step = u_series[step, :, :]  # ç»´åº¦ï¼šB Ã— control_dim
            # 2.3 è®¡ç®—æ§åˆ¶åµŒå…¥g_u(x_prev, u_step)ï¼ˆğŸ”¶1-51èŠ‚DKACé€»è¾‘ï¼Œå»ºæ¨¡çŠ¶æ€ä¾èµ–çš„éçº¿æ€§æ§åˆ¶é¡¹ï¼‰
            g_u_step, u_step_decode, _ = self.ControlEmbedding(self.normalize_x(x_prev), u_step)  # ç»´åº¦ï¼šB Ã— control_dim
            # 2.4 ç”¨Koopmanç®—å­é¢„æµ‹ä¸‹ä¸€æ­¥åµŒå…¥å‘é‡z_nextï¼ˆğŸ”¶1-55èŠ‚çº¿æ€§åŠ¨åŠ›å­¦ï¼šz_{t+1}=AÂ·z_t + BÂ·g_uï¼‰
            z_next = self.KoopmanOperator(z_prev, g_u_step)  # ç»´åº¦ï¼šB Ã— (x_dim+z_dim)ï¼ˆcat_dimï¼‰
            # 2.6 å­˜å‚¨é¢„æµ‹ç»“æœï¼Œå¹¶æ›´æ–°z_prevä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥
            z_pred_series.append(z_next)
            # u_decode_series.append(u_step_decode[:, self.StateEmbedding.x_dim:])
            u_decode_series.append(u_step_decode)
            z_prev = z_next  # æ»šåŠ¨æ›´æ–°ï¼šå½“å‰z_nextä½œä¸ºä¸‹ä¸€æ­¥çš„z_prev
        # 3. æ•´ç†é¢„æµ‹ç»“æœç»´åº¦ï¼šä»åˆ—è¡¨ï¼ˆK_steps Ã— B Ã— x_dimï¼‰è½¬ä¸ºå¼ é‡ï¼ˆB Ã— K_steps Ã— x_dimï¼‰
        z_pred_series = torch.stack(z_pred_series, dim=1)
        u_decode_series = torch.stack(u_decode_series, dim=1)

        return z_pred_series, u_decode_series
    
    def decode_control(self, control_embed):
        return self.ControlEmbedding.decoder(control_embed)

